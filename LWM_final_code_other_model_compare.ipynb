{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeacb7fd",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ec90d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "#LWMì„ í•˜ê¸°ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°€ì ¸ì˜¤ê¸°\n",
    "import DeepMIMOv3\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "plt . rcParams [ 'figure.figsize' ]  =  [ 12 ,  8 ]  # ê¸°ë³¸ í”Œë¡¯ í¬ê¸° ì„¤ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e17e0b",
   "metadata": {},
   "source": [
    "## GPUì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "47baa533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# GPU ì„¤ì •\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a6fcece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8\n",
      "90100\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)                   # ì„¤ì¹˜ëœ CUDA ë²„ì „ (ì˜ˆ: '11.7')\n",
    "print(torch.backends.cudnn.version())       # cuDNN ë²„ì „ (ì˜ˆ: 8200)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())  # True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9e064d",
   "metadata": {},
   "source": [
    "# DeepMIMOv3 ë‹¤ìš´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "23623e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install DeepMIMOv3 umap-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19540670",
   "metadata": {},
   "source": [
    "## íŒŒë¼ë¯¸í„° ìˆ˜ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce5ac681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'OFDM': {'RX_filter': 0,\n",
      "          'bandwidth': 0.05,\n",
      "          'selected_subcarriers': array([0]),\n",
      "          'subcarriers': 512},\n",
      " 'OFDM_channels': 1,\n",
      " 'active_BS': array([1]),\n",
      " 'bs_antenna': {'FoV': array([360, 180]),\n",
      "                'radiation_pattern': 'isotropic',\n",
      "                'rotation': array([0, 0, 0]),\n",
      "                'shape': array([8, 4]),\n",
      "                'spacing': 0.5},\n",
      " 'dataset_folder': './Raytracing_scenarios',\n",
      " 'dynamic_scenario_scenes': array([1]),\n",
      " 'enable_BS2BS': 1,\n",
      " 'enable_doppler': 0,\n",
      " 'enable_dual_polar': 0,\n",
      " 'num_paths': 5,\n",
      " 'scenario': 'O1_60',\n",
      " 'ue_antenna': {'FoV': array([360, 180]),\n",
      "                'radiation_pattern': 'isotropic',\n",
      "                'rotation': array([0, 0, 0]),\n",
      "                'shape': array([4, 2]),\n",
      "                'spacing': 0.5},\n",
      " 'user_rows': array([1]),\n",
      " 'user_subsampling': 1}\n"
     ]
    }
   ],
   "source": [
    "## Load and print the default parameters\n",
    "# bandwith: 0.05GHz(50MHz ëŒ€ì—­í­ ì‚¬ìš©)\n",
    "parameters = DeepMIMOv3.default_params()\n",
    "pprint(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1f0642c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change parameters for the setup\n",
    "# Scenario O1_60 extracted at the dataset_folder\n",
    "#LWM ë™ì  ì‹œë‚˜ë¦¬ì˜¤ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "#ìì‹ ì˜ LWM íŒŒì¼ ìœ„ì¹˜ ê²½ë¡œ ì‘ì„±\n",
    "# parameters['dataset_folder'] = r'/content/drive/MyDrive/Colab Notebooks/LWM'\n",
    "scene = 15 # ì¥ë©´ ìˆ˜\n",
    "parameters['dataset_folder'] = r'C:\\Users\\dlghd\\ì¡¸ì—…í”„ë¡œì íŠ¸\\LWM'\n",
    "\n",
    "# scnario = 02_dyn_3p5 <- ë‹¤ìš´ë°›ì€ íŒŒì¼(ë™ì ì‹œë‚˜ë¦¬ì˜¤)\n",
    "parameters['scenario'] = 'O2_dyn_3p5'\n",
    "parameters['dynamic_scenario_scenes'] = np.arange(scene) #scene 0~9\n",
    "\n",
    "# ê° ì‚¬ìš©ì-ê¸°ì§€êµ­ ì±„ë„ì— ëŒ€í•´ ìµœëŒ€ 10ê°œ ë©€í‹°íŒ¨ìŠ¤ ê²½ë¡œ ì‚¬ìš©\n",
    "parameters['num_paths'] = 10\n",
    "\n",
    "# User rows 1-100\n",
    "parameters['user_rows'] = np.arange(100)\n",
    "# User ì¶•ì†Œí•˜ê¸°\n",
    "parameters['user_subsampling'] = 0.01\n",
    "\n",
    "# Activate only the first basestation\n",
    "parameters['active_BS'] = np.array([1])\n",
    "\n",
    "parameters['activate_OFDM'] = 1\n",
    "\n",
    "parameters['OFDM']['bandwidth'] = 0.05 # 50 MHz\n",
    "parameters['OFDM']['subcarriers'] = 512 # OFDM with 512 subcarriers\n",
    "parameters['OFDM']['selected_subcarriers'] = np.arange(0, 64, 1)\n",
    "#parameters['OFDM']['subcarriers_limit'] = 64 # Keep only first 64 subcarriers\n",
    "\n",
    "parameters['ue_antenna']['shape'] = np.array([1, 1]) # Single antenna\n",
    "parameters['bs_antenna']['shape'] = np.array([1, 32]) # ULA of 32 elements\n",
    "#parameters['bs_antenna']['rotation'] = np.array([0, 30, 90]) # ULA of 32 elements\n",
    "#parameters['ue_antenna']['rotation'] = np.array([[0, 30], [30, 60], [60, 90]]) # ULA of 32 elements\n",
    "#parameters['ue_antenna']['radiation_pattern'] = 'isotropic'\n",
    "#parameters['bs_antenna']['radiation_pattern'] = 'halfwave-dipole'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "30aa4ae2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_folder': 'C:\\\\Users\\\\dlghd\\\\ì¡¸ì—…í”„ë¡œì íŠ¸\\\\LWM', 'scenario': 'O2_dyn_3p5', 'dynamic_scenario_scenes': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]), 'num_paths': 10, 'active_BS': array([1]), 'user_rows': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
      "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
      "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]), 'user_subsampling': 0.01, 'bs_antenna': {'shape': array([ 1, 32]), 'spacing': 0.5, 'rotation': array([0, 0, 0]), 'FoV': array([360, 180]), 'radiation_pattern': 'isotropic'}, 'ue_antenna': {'shape': array([1, 1]), 'spacing': 0.5, 'rotation': array([0, 0, 0]), 'FoV': array([360, 180]), 'radiation_pattern': 'isotropic'}, 'enable_doppler': 0, 'enable_dual_polar': 0, 'enable_BS2BS': 1, 'OFDM_channels': 1, 'OFDM': {'subcarriers': 512, 'selected_subcarriers': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]), 'bandwidth': 0.05, 'RX_filter': 0}, 'activate_OFDM': 1}\n"
     ]
    }
   ],
   "source": [
    "print(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3326b22d",
   "metadata": {},
   "source": [
    "## dataset êµ¬ì¶•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfe26bf-722b-4800-b03f-42bbf9d3cc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dataset êµ¬ì¶• (chunked onâ€‘theâ€‘fly generation)\n",
    "import time, gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 0~999 ì”¬ ì¸ë±ìŠ¤, í•œ ë²ˆì— 50ê°œì”© ì²˜ë¦¬\n",
    "scene_indices = np.arange(scene)\n",
    "chunk_size   = 5\n",
    "all_data     = []\n",
    "\n",
    "# ì”¬ ë¬¶ìŒ(chunk)ë§ˆë‹¤ generate_data í˜¸ì¶œ\n",
    "for i in tqdm(range(0, len(scene_indices), chunk_size)):\n",
    "    chunk = scene_indices[i : i+chunk_size].tolist()\n",
    "    parameters['dynamic_scenario_scenes'] = chunk\n",
    "\n",
    "    start = time.time()\n",
    "    data_chunk = DeepMIMOv3.generate_data(parameters)\n",
    "    print(f\"Scenes {chunk[0]}â€“{chunk[-1]} generation time: {time.time() - start:.2f}s\")\n",
    "\n",
    "    # ë°”ë¡œ all_dataì— í•©ì¹˜ê±°ë‚˜, ë””ìŠ¤í¬ì— ì €ì¥í•´ë„ OK\n",
    "    all_data.extend(data_chunk)\n",
    "\n",
    "    # ë©”ëª¨ë¦¬ í•´ì œ\n",
    "    del data_chunk\n",
    "    gc.collect()\n",
    "\n",
    "# ë§ˆì§€ë§‰ì— í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ í•©ì¹œ ë°ì´í„°ì…‹\n",
    "dataset = all_data\n",
    "\n",
    "\n",
    "print(parameters['user_rows'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9ee486e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_folder': 'C:\\\\Users\\\\dlghd\\\\ì¡¸ì—…í”„ë¡œì íŠ¸\\\\LWM', 'scenario': 'O2_dyn_3p5', 'dynamic_scenario_scenes': [10, 11, 12, 13, 14], 'num_paths': 10, 'active_BS': array([1]), 'user_rows': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
      "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
      "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]), 'user_subsampling': 0.01, 'bs_antenna': {'shape': array([ 1, 32]), 'spacing': 0.5, 'rotation': array([0, 0, 0]), 'FoV': array([360, 180]), 'radiation_pattern': 'isotropic'}, 'ue_antenna': {'shape': array([1, 1]), 'spacing': 0.5, 'rotation': array([0, 0, 0]), 'FoV': array([360, 180]), 'radiation_pattern': 'isotropic'}, 'enable_doppler': 0, 'enable_dual_polar': 0, 'enable_BS2BS': 1, 'OFDM_channels': 1, 'OFDM': {'subcarriers': 512, 'selected_subcarriers': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]), 'bandwidth': 0.05, 'RX_filter': 0}, 'activate_OFDM': 1}\n"
     ]
    }
   ],
   "source": [
    "print(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4e72d4",
   "metadata": {},
   "source": [
    "# ì‚¬ìš©ì ì ‘ê·¼ ë°ì´í„°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "57828d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['paths', 'LoS', 'location', 'distance', 'pathloss', 'channel'])\n"
     ]
    }
   ],
   "source": [
    "user_data = dataset[0][0]['user']\n",
    "print(user_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5a3b0c",
   "metadata": {},
   "source": [
    "# ì‚¬ìš©ì ì±„ë„ ì •ë³´ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "23b2884b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(727, 1, 32, 64)\n"
     ]
    }
   ],
   "source": [
    "# subcarries = ë‚˜ëˆˆ ê°ê°ì˜ ì£¼íŒŒìˆ˜ ì±„ë„\n",
    "# Channel = H <- ì±„ë„ ë²¡í„°\n",
    "# ì±„ë„ í˜•íƒœ\n",
    "# (user, UE antenna, Bs antenna, subcarrier)\n",
    "channel = dataset[0][0]['user']['channel']\n",
    "print(channel.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bf443dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 8.57045598e-06+5.5781261e-06j  8.89099283e-06+5.0515800e-06j\n",
      "    9.17921989e-06+4.5066768e-06j ... -1.02173499e-05-4.1711201e-07j\n",
      "   -1.02239183e-05+1.9928974e-07j -1.01933329e-05+8.1496728e-07j]\n",
      "  [ 1.02161603e-05+4.4529790e-07j  1.02244285e-05-1.7108337e-07j\n",
      "    1.01955429e-05-7.8684292e-07j ... -9.00999748e-06+4.8361312e-06j\n",
      "   -8.70222630e-06+5.3702393e-06j -8.36283198e-06+5.8848323e-06j]\n",
      "  [ 9.02330430e-06-4.8112561e-06j  8.71700831e-06-5.3462113e-06j\n",
      "    8.37903553e-06-5.8617388e-06j ... -5.29921817e-06+8.7456565e-06j\n",
      "   -4.76262221e-06+9.0490685e-06j -4.20871947e-06+9.3195977e-06j]\n",
      "  ...\n",
      "  [-7.00710962e-06-7.4477266e-06j -7.44313866e-06-7.0119827e-06j\n",
      "   -7.85211978e-06-6.5507575e-06j ...  9.82847632e-06+2.8229874e-06j\n",
      "    9.98071755e-06+2.2256456e-06j  1.00966881e-05+1.6202162e-06j]\n",
      "  [-9.82065103e-06-2.8500913e-06j -9.97453935e-06-2.2531719e-06j\n",
      "   -1.00921798e-05-1.6480645e-06j ...  9.89848286e-06-2.5667589e-06j\n",
      "    9.72583803e-06-3.1585257e-06j  9.51785023e-06-3.7388147e-06j]\n",
      "  [-9.90552599e-06+2.5394413e-06j -9.73451461e-06+3.1316822e-06j\n",
      "   -9.52812843e-06+3.7125428e-06j ...  7.21819652e-06-7.2433313e-06j\n",
      "    6.76863647e-06-7.6651013e-06j  6.29447914e-06-8.0590162e-06j]]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][0]['user']['channel'][100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b079846",
   "metadata": {},
   "source": [
    "# ì‚¬ìš©ì ìœ„ì¹˜ ì •ë³´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "84337e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(727, 3)\n",
      "[[-71.03330231 -15.57629967   1.        ]\n",
      " [-68.63330078 -15.57629967   1.        ]\n",
      " [-52.83330154 -15.57629967   1.        ]\n",
      " [-31.23329926 -15.57629967   1.        ]]\n"
     ]
    }
   ],
   "source": [
    "location = dataset[0][0]['user']['location']\n",
    "print(location.shape)      # (ì‚¬ìš©ì ìˆ˜, 3)\n",
    "print(location[0:4])         # ì²« ë²ˆì§¸ ì‚¬ìš©ìì˜ (x, y, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e9a9b6",
   "metadata": {},
   "source": [
    "# ê²½ë¡œì •ë³´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "79cde8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "727\n",
      "{'num_paths': 2, 'DoD_phi': array([-160.941, -160.941], dtype=float32), 'DoD_theta': array([93.6525, 94.7439], dtype=float32), 'DoA_phi': array([19.0585, 19.0585], dtype=float32), 'DoA_theta': array([86.3475, 94.7439], dtype=float32), 'phase': array([ 143.357, -137.611], dtype=float32), 'ToA': array([2.61886e-07, 2.62253e-07], dtype=float32), 'LoS': array([1., 0.], dtype=float32), 'power': array([7.5363324e-09, 3.2098095e-09], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "paths = dataset[0][0]['user']['paths']\n",
    "#ì‚¬ìš©ì ìˆ˜\n",
    "print(len(paths))\n",
    "# ì²« ë²ˆì§¸ ì‚¬ìš©ì ê²½ë¡œ ì •ë³´\n",
    "print(paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2242869",
   "metadata": {},
   "source": [
    "# ê¸°ì§€êµ­ ì •ë³´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2900e481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['paths', 'LoS', 'location', 'distance', 'pathloss', 'channel'])\n"
     ]
    }
   ],
   "source": [
    "bs_data = dataset[0][0]['basestation']\n",
    "print(bs_data.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c063ea95",
   "metadata": {},
   "source": [
    "# Scene ë° ì‚¬ìš©ì ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a20df92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scene 0: 727 users\n"
     ]
    }
   ],
   "source": [
    "for i, scene in enumerate(dataset[0]):\n",
    "    user_locs = scene['user']['location']\n",
    "    print(f\"Scene {i}: {len(user_locs)} users\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38f71e1",
   "metadata": {},
   "source": [
    "# ì±„ë„ ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cbbee52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "727"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[0][0]['user']['channel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2d474195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_paths': 2, 'DoD_phi': array([-160.941, -160.941], dtype=float32), 'DoD_theta': array([93.6525, 94.7439], dtype=float32), 'DoA_phi': array([19.0585, 19.0585], dtype=float32), 'DoA_theta': array([86.3475, 94.7439], dtype=float32), 'phase': array([ 143.357, -137.611], dtype=float32), 'ToA': array([2.61886e-07, 2.62253e-07], dtype=float32), 'LoS': array([1., 0.], dtype=float32), 'power': array([7.5363324e-09, 3.2098095e-09], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][0]['user']['paths'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "73df9912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 64)\n"
     ]
    }
   ],
   "source": [
    "scene = dataset[0][0] # scene 0\n",
    "ue_idx = 0 # ì²« ë²ˆì§¸ ì‚¬ìš©ì\n",
    "channel = scene['user']['channel'][ue_idx]\n",
    "print(channel.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373ffb59",
   "metadata": {},
   "source": [
    "# channel CIR mat ì •ë³´ ê°€ì ¸ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ec4461cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'CIR_array_full'])\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "\n",
    "file_path = r'C:\\Users\\dlghd\\ì¡¸ì—…í”„ë¡œì íŠ¸\\LWM\\O2_dyn_3p5\\scene_0\\O2_dyn_3p5.1.CIR.mat'\n",
    "mat_data = sio.loadmat(file_path)\n",
    "\n",
    "# íŒŒì¼ ì•ˆì˜ key í™•ì¸\n",
    "print(mat_data.keys())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "662cb441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'MATLAB 5.0 MAT-file, Platform: PCWIN64, Created on: Wed Jun 30 11:33:01 2021'\n"
     ]
    }
   ],
   "source": [
    "# ì¼ë°˜ì ìœ¼ë¡œ CIR keyëŠ” 'CIR' ë˜ëŠ” 'cir' ê°™ì€ ì´ë¦„ì¼ ê°€ëŠ¥ì„± ë†’ìŒ\n",
    "H_cir = mat_data['__header__']  \n",
    "print(H_cir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f3d7c7",
   "metadata": {},
   "source": [
    "# Time-Prediction ì‹œì‘\n",
    "## Time Series í˜•íƒœë¡œ ë³€í™˜\n",
    "### ë‹¨ì¼ì‚¬ìš©ì ì±„ë„ ì˜ˆì¸¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4f36971f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0ì´ ì¡´ì¬í•˜ëŠ” ì±„ë„ ê°œìˆ˜ 0\n"
     ]
    }
   ],
   "source": [
    "# print(dataset[0][0]['user']['channel'][150][0][3])\n",
    "\n",
    "count = 0\n",
    "for h in dataset[0][0]['user']['channel'][100][0]:\n",
    "#     h = h.squeeze(0)\n",
    "    h_real = h.real\n",
    "    h_imag = h.imag\n",
    "    if np.sum(np.abs(h_real)) ==0:\n",
    "        count+=1\n",
    "    elif np.sum(np.abs(h_imag)) == 0:\n",
    "        count+=1\n",
    "\n",
    "print(\"0ì´ ì¡´ì¬í•˜ëŠ” ì±„ë„ ê°œìˆ˜\",count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7575de2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antenna #3 subcarriers: [ 5.3233252e-06-8.73100362e-06j  4.7875683e-06-9.03589535e-06j\n",
      "  4.2344141e-06-9.30795068e-06j  3.6658719e-06-9.54618190e-06j\n",
      "  3.0840083e-06-9.74972318e-06j  2.4909377e-06-9.91783418e-06j\n",
      "  1.8888149e-06-1.00499046e-05j  1.2798286e-06-1.01454543e-05j\n",
      "  6.6619128e-07-1.02041367e-05j  5.0133124e-08-1.02257372e-05j\n",
      " -5.6610725e-07-1.02101776e-05j -1.1802904e-06-1.01575160e-05j\n",
      " -1.7901845e-06-1.00679417e-05j -2.3935731e-06-9.94178117e-06j\n",
      " -2.9882635e-06-9.77949367e-06j -3.5720950e-06-9.58166765e-06j\n",
      " -4.1429457e-06-9.34902255e-06j -4.6987411e-06-9.08240327e-06j\n",
      " -5.2374617e-06-8.78277933e-06j -5.7571492e-06-8.45123941e-06j\n",
      " -6.2559161e-06-8.08898767e-06j -6.7319493e-06-7.69734197e-06j\n",
      " -7.1835188e-06-7.27772431e-06j -7.6089841e-06-6.83165945e-06j\n",
      " -8.0067985e-06-6.36076902e-06j -8.3755176e-06-5.86676424e-06j\n",
      " -8.7137996e-06-5.35144000e-06j -9.0204167e-06-4.81666848e-06j\n",
      " -9.2942537e-06-4.26439374e-06j -9.5343166e-06-3.69662257e-06j\n",
      " -9.7397324e-06-3.11541817e-06j -9.9097542e-06-2.52289237e-06j\n",
      " -1.0043765e-05-1.92119842e-06j -1.0141277e-05-1.31252318e-06j\n",
      " -1.0201937e-05-6.99078271e-07j -1.0225523e-05-8.30929494e-08j\n",
      " -1.0211949e-05+5.33194338e-07j -1.0161268e-05+1.14754403e-06j\n",
      " -1.0073660e-05+1.75772368e-06j -9.9494455e-06+2.36151573e-06j\n",
      " -9.7890743e-06+2.95672635e-06j -9.5931318e-06+3.54119220e-06j\n",
      " -9.3623275e-06+4.11278961e-06j -9.0975009e-06+4.66944175e-06j\n",
      " -8.7996150e-06+5.20912499e-06j -8.4697522e-06+5.72987892e-06j\n",
      " -8.1091102e-06+6.22981088e-06j -7.7190007e-06+6.70710369e-06j\n",
      " -7.3008405e-06+7.16002387e-06j -6.8561499e-06+7.58692431e-06j\n",
      " -6.3865441e-06+7.98625479e-06j -5.8937303e-06+8.35656374e-06j\n",
      " -5.3794988e-06+8.69650557e-06j -4.8457186e-06+9.00484429e-06j\n",
      " -4.2943293e-06+9.28046029e-06j -3.7273348e-06+9.52235223e-06j\n",
      " -3.1467955e-06+9.72963971e-06j -2.5548209e-06+9.90157059e-06j\n",
      " -1.9535621e-06+1.00375200e-05j -1.3452043e-06+1.01369933e-05j\n",
      " -7.3195804e-07+1.01996302e-05j -1.1605191e-07+1.02252015e-05j\n",
      "  5.0027592e-07+1.02136155e-05j  1.1147858e-06+1.01649139e-05j]\n",
      "0+0jì¸ ì„œë¸Œìºë¦¬ì–´ ê°œìˆ˜: 0\n",
      "ì™„ì „ 0+0j ì•ˆí…Œë‚˜ í¬íŠ¸ ê°œìˆ˜: 0\n",
      "0ì´ ì•„ë‹Œ ì„œë¸Œìºë¦¬ì–´ ê°œìˆ˜: 2048\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1) (user, ue_port, bs_ant, subc) â†’ (bs_ant, subc) ë¡œ squeeze\n",
    "H = dataset[0][0]['user']['channel'][100, 0]   # shape: (32, 64), complex\n",
    "\n",
    "# 2) BS ì•ˆí…Œë‚˜ ì¸ë±ìŠ¤ 3ì˜ ì„œë¸Œìºë¦¬ì–´ ë²¡í„° (64,)\n",
    "print(\"Antenna #3 subcarriers:\", H[3])\n",
    "\n",
    "# 3) ì „ì²´ ì„œë¸Œìºë¦¬ì–´(32Ã—64) ì¤‘ ê°’ì´ ì •í™•íˆ 0ì¸ ìš”ì†Œ ê°œìˆ˜\n",
    "zero_elements = np.sum(H == 0)\n",
    "print(\"0+0jì¸ ì„œë¸Œìºë¦¬ì–´ ê°œìˆ˜:\", zero_elements)\n",
    "\n",
    "# 4) ì„œë¸Œìºë¦¬ì–´ ì „ë¶€ê°€ 0ì¸ ì•ˆí…Œë‚˜ í¬íŠ¸(í–‰) ê°œìˆ˜\n",
    "zero_ports = np.sum(np.all(H == 0, axis=1))\n",
    "print(\"ì™„ì „ 0+0j ì•ˆí…Œë‚˜ í¬íŠ¸ ê°œìˆ˜:\", zero_ports)\n",
    "\n",
    "# 5) ë§Œì•½ â€œê°’ì´ í•˜ë‚˜ë„ 0ì´ ì•„ë‹Œâ€ ì„œë¸Œìºë¦¬ì–´ ìš”ì†Œ ê°œìˆ˜ë¥¼ ë³´ê³  ì‹¶ë‹¤ë©´\n",
    "nonzero_elements = np.sum(np.abs(H) > 0)\n",
    "print(\"0ì´ ì•„ë‹Œ ì„œë¸Œìºë¦¬ì–´ ê°œìˆ˜:\", nonzero_elements)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20a73af",
   "metadata": {},
   "source": [
    "## ê²°ì¸¡ì¹˜ ì œê±° ë° dataload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "267c0446-af32-420e-a812-ea8f16a3b75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# â¶ IterableDataset: ëª¨ë“  ìœ ì €Â·ì„œë¸Œìºë¦¬ì–´ë¥¼ ìŠ¤íŠ¸ë¦¬ë°\n",
    "import torch\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class ChannelSeqDataset(IterableDataset):\n",
    "    \"\"\"\n",
    "    â€¢ seq_lenÂ ê°œì˜ ê³¼ê±° ì±„ë„ ë²¡í„°(realâ€¯64â€¯+â€¯imagâ€¯64â€¯â†’â€¯128) â†’ ë‹¤ìŒ ì‹œì  ë²¡í„° ì˜ˆì¸¡\n",
    "    â€¢ ë²¡í„°ëŠ” í‰ê· ì „ë ¥ 1 ë¡œ powerâ€‘normalize í›„ ë°˜í™˜\n",
    "    \"\"\"\n",
    "    def __init__(self, scenes, seq_len: int = 5, eps: float = 1e-9):\n",
    "        super().__init__()\n",
    "        self.scenes   = scenes\n",
    "        self.seq_len  = seq_len\n",
    "        self.eps      = eps                        # 0Â division ë°©ì§€ìš© ì‹ í˜¸ì„¸ê¸°ì˜ í¬ê¸° \n",
    "        ch0           = scenes[0][0]['user']['channel']\n",
    "        self.U        = ch0.shape[0]               # ì‚¬ìš©ì ìˆ˜\n",
    "        self.A        = ch0.shape[2]               # ì•ˆí…Œë‚˜ 32\n",
    "        self.S        = ch0.shape[3]               # ì„œë¸Œìºë¦¬ì–´ 64\n",
    "        self.vec_len  = 2 * self.A                 # 64 real + imag\n",
    "        0\n",
    "    def _vec(self, scene, u: int, sc: int) -> torch.Tensor:\n",
    "        \"\"\"(32,) complex â†’ (64,) float32  +  powerÂ norm\"\"\"\n",
    "        h = scene[0]['user']['channel'][u, 0, :, sc]          # (32,)\n",
    "        v = np.concatenate([h.real, h.imag]).astype(np.float32)\n",
    "        p = np.mean(v * v) + self.eps                         # í‰ê·  ì „ë ¥: ì±„ë„ ë²¡í„° hì˜ ê° ì„±ë¶„ì˜ ì§„í­ ì œê³±ì„ í•©ì‚°\n",
    "        v /= np.sqrt(p)                                       # ì •ê·œí™”\n",
    "        return torch.from_numpy(v)                            # (64,)\n",
    "\n",
    "    def __iter__(self):\n",
    "        T = len(self.scenes)\n",
    "        for t in range(self.seq_len, T):  # íƒ€ê¹ƒ ì‹œì \n",
    "            past_scenes = self.scenes[t - self.seq_len : t]\n",
    "            tgt_scene   = self.scenes[t]\n",
    "            for u in range(self.U):\n",
    "                for s in range(self.S):\n",
    "                    seq = torch.stack([self._vec(ps, u, s) for ps in past_scenes])\n",
    "                    if not torch.any(seq):        # ì „ë¶€ 0ì´ë©´ skip\n",
    "                        continue\n",
    "                    target = self._vec(tgt_scene, u, s)\n",
    "                    if not torch.any(target):     # targetì´ 0ì´ë©´ skip\n",
    "                        continue\n",
    "                    yield seq, target             # â† ì—¬ê¸°ì„œ masked_pos ì œê±°\n",
    "                # shapes: (5,64) / (1,) / (64,)\n",
    "    \n",
    "    def __len__(self):\n",
    "         return (len(self.scenes) - self.seq_len) * self.U * self.S\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# â· í•™ìŠµÂ·ê²€ì¦ DataLoader train : val = 6 : 4\n",
    "seq_len      = 5\n",
    "split_ratio  = 0.6\n",
    "split_idx    = int(len(dataset) * split_ratio)\n",
    "\n",
    "train_ds = ChannelSeqDataset(dataset[:split_idx], seq_len=seq_len)\n",
    "val_ds   = ChannelSeqDataset(dataset[split_idx:], seq_len=seq_len)\n",
    "\n",
    "# train_ds ìˆœíšŒí•˜ë©´ì„œ feature/target min, max ê³„ì‚°\n",
    "\n",
    "\n",
    "batch_size   = 32\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c982d28d-40ee-40c0-8a04-2bbd9aa05f4c",
   "metadata": {},
   "source": [
    "## LWM ì½”ë“œì™€ ë‹¤ë¦„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6f9dc1d8-db2c-4816-b754-6e85e4cd350f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data      import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# 1) NumPy ë°°ì—´ë¡œ ì¶”ì¶œ\n",
    "X_list, y_list = [], []\n",
    "for seq, tgt in ChannelSeqDataset(dataset, seq_len=seq_len):\n",
    "    X_list.append(seq.numpy())\n",
    "    y_list.append(tgt.numpy())\n",
    "\n",
    "X = np.stack(X_list, axis=0)  # (N, L, D)\n",
    "y = np.stack(y_list, axis=0)  # (N, D)\n",
    "\n",
    "# 2) Train/Val split\n",
    "split_idx = int(len(X) * split_ratio)\n",
    "X_tr, X_va = X[:split_idx], X[split_idx:]\n",
    "y_tr, y_va = y[:split_idx], y[split_idx:]\n",
    "\n",
    "# 3) ìŠ¤ì¼€ì¼ëŸ¬ ì¤€ë¹„ ë° fit (0â€“1 ì‚¬ì´ë¡œ ìŠ¤ì¼€ì¼ë§)\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "Ntr, L, D = X_tr.shape\n",
    "\n",
    "scaler_x.fit(X_tr.reshape(-1, D))\n",
    "scaler_y.fit(y_tr)\n",
    "\n",
    "# 4) Transform í›„ ì›ë˜ shape ë³µì›\n",
    "X_tr_s = scaler_x.transform(X_tr.reshape(-1, D)).reshape(Ntr, L, D)\n",
    "\n",
    "Nva = X_va.shape[0]\n",
    "X_va_s = scaler_x.transform(X_va.reshape(-1, D)).reshape(Nva, L, D)\n",
    "\n",
    "y_tr_s = scaler_y.transform(y_tr)\n",
    "y_va_s = scaler_y.transform(y_va)\n",
    "\n",
    "# 5) Dataset & DataLoader\n",
    "train_ds    = TensorDataset(\n",
    "    torch.from_numpy(X_tr_s).float(),\n",
    "    torch.from_numpy(y_tr_s).float()\n",
    ")\n",
    "val_ds      = TensorDataset(\n",
    "    torch.from_numpy(X_va_s).float(),\n",
    "    torch.from_numpy(y_va_s).float()\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 6) ì²« ë°°ì¹˜ ì–¸íŒ¨í‚¹\n",
    "seqs, tgts = next(iter(train_loader))  # seqs: (B, L, D), tgts: (B, D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a95b39ac-9ca8-441b-8e2f-c4ccd4e2ab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import torch\n",
    "# from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "# from sklearn.preprocessing import MinMaxScaler          # ë˜ëŠ” StandardScaler\n",
    "\n",
    "\n",
    "# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# # 0)  ì›ë³¸ scene ë¦¬ìŠ¤íŠ¸\n",
    "# #     all_data = [...]  ë¡œ ëª¨ì•„ ë‘” ê²°ê³¼ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
    "# raw_scenes = all_data                  # (T,) list  â†âœ±  variable ì´ë¦„ë§Œ ë³€ê²½\n",
    "\n",
    "# seq_len   = 5                          # ê³¼ê±° í”„ë ˆì„ ìˆ˜\n",
    "# eps       = 1e-9                       # 0-division ë°©ì§€\n",
    "\n",
    "# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# # 1)  (X, Y) ì‹œí€€ìŠ¤ ì¶”ì¶œ\n",
    "# Xs_list, Ys_list = [], []\n",
    "\n",
    "# T = len(raw_scenes)\n",
    "# assert T >= seq_len + 1, \"scenes ê°œìˆ˜ê°€ seq_len ë³´ë‹¤ ë§ì•„ì•¼ í•©ë‹ˆë‹¤.\"\n",
    "\n",
    "# # ì•ˆí…Œë‚˜(A)Â·ì„œë¸Œìºë¦¬ì–´(S)Â·ì‚¬ìš©ì(U) í¬ê¸°ëŠ” í•œ ë²ˆë§Œ ì½ì–´ë„ ë¨\n",
    "# sample_ch = raw_scenes[0][0]['user']['channel']     # (U, 1, A, S)\n",
    "# U, _, A, S = sample_ch.shape\n",
    "# feat_dim   = 2 * A                                 # real+imag  â†’ 64\n",
    "\n",
    "# for t in range(seq_len, T):                        # íƒ€ê¹ƒ ì‹œì \n",
    "#     past_scenes = raw_scenes[t - seq_len : t]\n",
    "#     tgt_scene   = raw_scenes[t]\n",
    "\n",
    "#     for u in range(U):\n",
    "#         for sc in range(S):\n",
    "#             # â”€â”€ ì…ë ¥ ì‹œí€€ìŠ¤ (seq_len, feat_dim) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#             seq = []\n",
    "#             for ps in past_scenes:\n",
    "#                 h = ps[0]['user']['channel'][u, 0, :, sc]   # (A,) complex\n",
    "#                 v = np.concatenate([h.real, h.imag]).astype(np.float32)\n",
    "#                 # (ì„ íƒ) power-normalize\n",
    "#                 pwr = np.mean(v * v) + eps\n",
    "#                 v  /= np.sqrt(pwr)\n",
    "#                 seq.append(v)\n",
    "#             seq = np.stack(seq, axis=0)                     # (seq_len, 64)\n",
    "\n",
    "#             # â”€â”€ íƒ€ê¹ƒ ë²¡í„° (feat_dim,) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#             h_tgt = tgt_scene[0]['user']['channel'][u, 0, :, sc]\n",
    "#             y     = np.concatenate([h_tgt.real, h_tgt.imag]).astype(np.float32)\n",
    "#             pwr   = np.mean(y * y) + eps\n",
    "#             y    /= np.sqrt(pwr)                            # ë™ì¼ ì •ê·œí™”\n",
    "\n",
    "#             Xs_list.append(seq)\n",
    "#             Ys_list.append(y)\n",
    "\n",
    "# print(f\"ì´ ìƒ˜í”Œ ìˆ˜: {len(Xs_list):,}\")\n",
    "\n",
    "# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# # 2)  numpy ë°°ì—´ë¡œ ë³€í™˜\n",
    "# Xs = np.stack(Xs_list, axis=0).astype(np.float32)     # (N, seq_len, 64)\n",
    "# Ys = np.stack(Ys_list, axis=0).astype(np.float32)     # (N, 64)\n",
    "\n",
    "# N, seq_len, feat_dim = Xs.shape\n",
    "# print(\"Xs:\", Xs.shape, \"Ys:\", Ys.shape)\n",
    "\n",
    "# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# # 3)  ìŠ¤ì¼€ì¼ë§ (ì„ íƒ) â€” ì…ë ¥ë§Œ ìŠ¤ì¼€ì¼ë§ ê¶Œì¥\n",
    "# scaler_x = MinMaxScaler().fit(Xs.reshape(-1, feat_dim))\n",
    "# Xs_s     = scaler_x.transform(Xs.reshape(-1, feat_dim)).reshape(Xs.shape)\n",
    "\n",
    "# # yë„ ìŠ¤ì¼€ì¼ë§í•˜ë ¤ë©´ â†“ ë‘ ì¤„ í™œì„±í™”\n",
    "# scaler_y = MinMaxScaler().fit(Ys)\n",
    "# Ys_s     = scaler_y.transform(Ys)\n",
    "# # ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ì›ìŠ¤ì¼€ì¼ ìœ ì§€\n",
    "# # scaler_y = None\n",
    "# # Ys_s     = Ys\n",
    "\n",
    "# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# # 4)  TensorDataset / DataLoader\n",
    "# tensor_ds = TensorDataset(torch.from_numpy(Xs_s), torch.from_numpy(Ys_s))\n",
    "\n",
    "# train_len         = int(0.6 * len(tensor_ds))\n",
    "# train_ds, val_ds  = random_split(tensor_ds, [train_len, len(tensor_ds) - train_len])\n",
    "\n",
    "# train_loader = DataLoader(train_ds, batch_size=32, shuffle=True,  drop_last=True)\n",
    "# val_loader   = DataLoader(val_ds,   batch_size=32, shuffle=False, drop_last=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0aaadd66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200563"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds) #4x727x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "90f5b39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133709"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_ds) #1x727x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fe8a8a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x00000232921051F0>\n",
      "batch_size: 32\n",
      "dataset: <torch.utils.data.dataset.TensorDataset object at 0x00000232F9908200>\n",
      "total samples: 200563\n",
      "total batches: 6268\n",
      "seqs.shape: torch.Size([32, 5, 64])\n",
      "tgts.shape: torch.Size([32, 64])\n"
     ]
    }
   ],
   "source": [
    "# 1) DataLoader ì„¤ì • í™•ì¸\n",
    "print(train_loader)                # DataLoader ì •ë³´ ì „ì²´\n",
    "print(\"batch_size:\", train_loader.batch_size)\n",
    "print(\"dataset:\",   train_loader.dataset)\n",
    "\n",
    "# ì´ ìƒ˜í”Œ ìˆ˜\n",
    "print(\"total samples:\", len(train_loader.dataset))\n",
    "# â†’ (len(scenes) - seq_len) * U * S ì™€ ë™ì¼í•œ ê°’\n",
    "\n",
    "# ì´ ë°°ì¹˜ ìˆ˜\n",
    "print(\"total batches:\", len(train_loader))\n",
    "# â†’ ceil(total_samples / batch_size)\n",
    "\n",
    "\n",
    "# 3) ì²« ë²ˆì§¸ ë°°ì¹˜ ë‚´ìš© í™•ì¸\n",
    "first_batch = next(iter(train_loader))\n",
    "seqs, tgts = first_batch\n",
    "print(\"seqs.shape:\",   seqs.shape)    # (B, seq_len, vec_len)\n",
    "print(\"tgts.shape:\",   tgts.shape)    # (B, vec_len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3348886",
   "metadata": {},
   "source": [
    "## ì´ë¡ ì  input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ff85e07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â†’ total samples (input_size): 200563\n",
      "â†’ batch size: 32\n",
      "â†’ total batches: 6268\n",
      "â†’ train samples: 200563\n",
      "â†’ val   samples: 133709\n"
     ]
    }
   ],
   "source": [
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# input_size ê³„ì‚° ë° ì¶œë ¥ (ìˆ˜ì •ëœ ë²„ì „)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# 1) ì „ì²´ ìƒ˜í”Œ ìˆ˜\n",
    "input_size = len(train_ds)\n",
    "\n",
    "# 2) ë°°ì¹˜ í¬ê¸°ì™€ ë°°ì¹˜ ìˆ˜\n",
    "batch_size = 32   # ì´ë¯¸ ì„¤ì •ëœ ê°’\n",
    "n_batches  = len(train_loader)\n",
    "\n",
    "print(f\"â†’ total samples (input_size): {input_size}\")\n",
    "print(f\"â†’ batch size: {batch_size}\")\n",
    "print(f\"â†’ total batches: {n_batches}\")\n",
    "\n",
    "# 3) train/val ë¶„í•  ë¹„ìœ¨ í™•ì¸ (ì„ íƒ)\n",
    "print(f\"â†’ train samples: {len(train_ds)}\")\n",
    "print(f\"â†’ val   samples: {len(val_ds)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf6bac8",
   "metadata": {},
   "source": [
    "# ì•„ë˜ ì½”ë“œ êµ¬ì¡°\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ input_ids  (B, seq_len, element_length)  â”€â”                 â”‚\n",
    "â”‚ masked_pos (B, num_mask)                  â”œâ”€>  LWM backbone â”‚\n",
    "â”‚                                           â”‚    (12-ì¸µ íŠ¸ëœìŠ¤í¬ë¨¸)  \n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚\n",
    "            logits_lm  (B, num_mask, element_length)  â”‚   enc_output (B, seq_len, d_model)\n",
    "                                                      â–¼\n",
    "                        â”Œâ”€[í’€ë§]â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â†â”€â”€ feat (B, d_model)\n",
    "                        â”‚ ì²« í† í°(0ë²ˆ) ì„ íƒ    â”‚\n",
    "                        â”‚   or í‰ê· /ìµœëŒ€ í’€ë§ â”‚\n",
    "                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                      â–¼\n",
    "                       FC í—¤ë“œ  (d_model â†’ hidden_dim â†’ out_dim)\n",
    "                                      â–¼\n",
    "                                out (B, out_dim)\n",
    "\n",
    "# ì‹œê°ì ë¹„ìœ \n",
    "\n",
    "[íŒ¨ì¹˜ í”„ë¡œì í„°]â”€â”€â–¶[Transformer Ã—12]â”€â”€â–¶[LayerNorm]â”€â”€â”\n",
    "                                                  â”œâ”€â–¶ 64-ì°¨ ë²¡í„° (CLS ë˜ëŠ” í’€ë§) â”€â–¶ MLP â”€â–¶ out                                                \n",
    "[Positional Embedding]â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5beb3297-472f-45b8-a464-1650fca7c8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LWM ëª¨ë¸ê³¼ ê°™ì´ transformer ecoder ì¸µ ìˆ˜ 12ê°œë¡œ \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 1) GRUWithHead â€” GRU ë°±ë³¸ + FC-í—¤ë“œ\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "class GRUWithHead(nn.Module):\n",
    "    def __init__(self,\n",
    "                 feat_dim: int,\n",
    "                 hidden_size: int = 256,\n",
    "                 num_layers: int = 12,\n",
    "                 bidirectional: bool = False,\n",
    "                 dropout: float = 0.2,\n",
    "                 hidden_dim: int = 256,\n",
    "                 out_dim: int    = 64,\n",
    "                 freeze_backbone: bool = False):\n",
    "        super().__init__()\n",
    "        self.backbone = nn.GRU(\n",
    "            input_size   = feat_dim,\n",
    "            hidden_size  = hidden_size,\n",
    "            num_layers   = num_layers,\n",
    "            batch_first  = True,\n",
    "            bidirectional= bidirectional,\n",
    "            dropout      = dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "        if freeze_backbone:\n",
    "            for p in self.backbone.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        gru_out_dim = hidden_size * (2 if bidirectional else 1)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(gru_out_dim, hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.backbone(x)         # (B, seq_len, H)\n",
    "        feat   = out[:, -1, :]            # ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í…\n",
    "        return self.head(feat)            # (B, out_dim)\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 2) TransformerWithHead â€” ì†Œí˜• Transformer ë°±ë³¸ + FC-í—¤ë“œ\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "class TransformerWithHead(nn.Module):\n",
    "    def __init__(self,\n",
    "                 feat_dim: int,\n",
    "                 n_heads: int   = 4,\n",
    "                 dim_ff: int    = 256,\n",
    "                 n_layers: int  = 12, # layerì¸µ lwmê³¼ ê°™ì´ 12ê°œë¡œ ì„¤ì •\n",
    "                 # dropout: float = 0.1, # dropout ì œê±° \n",
    "                 hidden_dim: int = 256,\n",
    "                 out_dim: int    = 64,\n",
    "                 freeze_backbone: bool = False):\n",
    "        super().__init__()\n",
    "        layer = TransformerEncoderLayer(\n",
    "            d_model = feat_dim,\n",
    "            nhead   = n_heads,\n",
    "            dim_feedforward = dim_ff,\n",
    "            dropout = dropout\n",
    "        )\n",
    "        self.backbone = TransformerEncoder(layer, num_layers=n_layers)\n",
    "        if freeze_backbone:\n",
    "            for p in self.backbone.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(feat_dim, hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.Dropout(dropout), dropout ì œê±°\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z    = self.backbone(x.transpose(0,1))  # (T, B, F)\n",
    "        feat = z[-1]                             # ë§ˆì§€ë§‰ í† í°\n",
    "        return self.head(feat)                  # (B, out_dim)\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 3) NoPrediction â€” ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í… ê·¸ëŒ€ë¡œ ë¦¬í„´\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 6) SequentialRNN â€” RNN ë°±ë³¸ + Linear\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 7) SequentialLSTM â€” LSTM ë°±ë³¸ + Linear\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "class SequentialLSTM(nn.Module):\n",
    "    def __init__(self, feat_dim, hidden=128):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(feat_dim, hidden, batch_first=True)\n",
    "        self.head = nn.Linear(hidden, feat_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.head(out[:, -1])  # (B, feat_dim)\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 8) ParallelTransformer â€” ë³‘ë ¬ Transformer ë°±ë³¸ + Linear í—¤ë“œ\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "class ParallelTransformer(nn.Module):\n",
    "    def __init__(self, feat_dim, heads: int = 4, dim_ff: int = 256, layers: int = 2):\n",
    "        super().__init__()\n",
    "        layer = TransformerEncoderLayer(\n",
    "            d_model = feat_dim,\n",
    "            nhead   = heads,\n",
    "            dim_feedforward = dim_ff\n",
    "        )\n",
    "        self.enc  = TransformerEncoder(layer, num_layers=layers)\n",
    "        self.head = nn.Linear(feat_dim, feat_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, seq_len, feat_dim)\n",
    "        z    = self.enc(x.transpose(0,1))  # (T, B, F)\n",
    "        feat = z[-1]                        # ë§ˆì§€ë§‰ í† í°\n",
    "        return self.head(feat)             # (B, feat_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3cec5b",
   "metadata": {},
   "source": [
    "## input_size\n",
    "-input_size = (scene - seq_len) * U * S -> (10-5)+69040*64 = 22092800  \n",
    "-batch_size = 32  \n",
    "-ë°°ì¹˜ ìˆ˜ = input_size / batch_size = 690400ë°°ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "727c7474-1953-4357-a817-9eb458e4522a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŸ¢ gru initialized with {'feat_dim': 64, 'hidden_size': 128, 'num_layers': 2, 'bidirectional': False, 'dropout': 0.2, 'hidden_dim': 256, 'out_dim': 64, 'freeze_backbone': False}\n",
      "ğŸŸ¢ gru initialized with {'feat_dim': 64, 'hidden_size': 128, 'num_layers': 2, 'bidirectional': False, 'dropout': 0.2, 'hidden_dim': 256, 'out_dim': 64, 'freeze_backbone': False}\n"
     ]
    }
   ],
   "source": [
    "# ë°±ë³¸ ë™ê²° Falseê°’\n",
    "from torch.optim import Adam\n",
    "\n",
    "batch_size, seq_len, D = X_tr_s.shape  # D = 64\n",
    "hidden_dim = 256\n",
    "\n",
    "# â”€â”€ 2) ëª¨ë¸ ì¹´íƒˆë¡œê·¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "MODEL_CATALOG = {\n",
    "    \"gru\":                  GRUWithHead,\n",
    "    \"transformer\":          TransformerWithHead,\n",
    "    \"nopred\":               NoPrediction,\n",
    "    \"pad\":                  SequentialPAD,\n",
    "    \"pvec\":                 SequentialPVEC,\n",
    "    \"seqrnn\":               SequentialRNN,\n",
    "    \"seqlstm\":              SequentialLSTM,\n",
    "    \"parallel_transformer\": ParallelTransformer,\n",
    "}\n",
    "# â”€â”€ 2.1) ëª¨ë¸ë³„ íŒŒë¼ë¯¸í„° ë§µ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "MODEL_PARAMS = {\n",
    "    \"gru\": {\n",
    "        \"feat_dim\":        feat_dim,\n",
    "        \"hidden_size\":     128,\n",
    "        \"num_layers\":      12,\n",
    "        \"bidirectional\":   False,\n",
    "        # \"dropout\":         0.2,\n",
    "        \"hidden_dim\":      hidden_dim,\n",
    "        \"out_dim\":         out_dim,\n",
    "        \"freeze_backbone\": False,\n",
    "    },\n",
    "    \"transformer\": {\n",
    "        \"feat_dim\":        feat_dim,\n",
    "        \"n_heads\":         4,\n",
    "        \"dim_ff\":          256,\n",
    "        \"n_layers\":        12,\n",
    "        # \"dropout\":         0.1,\n",
    "        \"hidden_dim\":      hidden_dim,\n",
    "        \"out_dim\":         out_dim,\n",
    "        \"freeze_backbone\": False,\n",
    "    },\n",
    "    \"nopred\": {},\n",
    "    \"pad\":    {\"eps\": 1e-6},\n",
    "    \"pvec\":   {},\n",
    "    \"seqrnn\": {\"feat_dim\": feat_dim, \"hidden\": 128},\n",
    "    \"seqlstm\":{\"feat_dim\": feat_dim, \"hidden\": 128},\n",
    "    \"parallel_transformer\": {\n",
    "        \"feat_dim\": feat_dim,\n",
    "        \"heads\":    4,\n",
    "        \"dim_ff\":   256,\n",
    "        \"layers\":   2,\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# â”€â”€ 3) ì‹¤í—˜í•  ëª¨ë¸ ì„ íƒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "model_name = \"gru\"  # ì›í•˜ëŠ” ëª¨ë¸ ì´ë¦„\n",
    "ModelCls   = MODEL_CATALOG[model_name]\n",
    "\n",
    "# â”€â”€ 3) ì‹¤í—˜í•  ëª¨ë¸ ì„ íƒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "model_name = \"gru\"  # ì›í•˜ëŠ” ëª¨ë¸ ì´ë¦„\n",
    "ModelCls   = MODEL_CATALOG[model_name]\n",
    "args       = MODEL_PARAMS[model_name]   # â˜… ì—¬ê¸°ê°€ ìˆ˜ì •ëœ ë¶€ë¶„\n",
    "\n",
    "# â”€â”€ 4) ì¸ìŠ¤í„´ìŠ¤í™” & ì˜µí‹°ë§ˆì´ì € â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "model     = ModelCls(**args).to(device)\n",
    "print(f\"ğŸŸ¢ {model_name} initialized with\", args)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "\n",
    "\n",
    "# â”€â”€ 5) ì¸ìŠ¤í„´ìŠ¤í™” & ì˜µí‹°ë§ˆì´ì € â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "model     = ModelCls(**args).to(device)\n",
    "print(f\"ğŸŸ¢ {model_name} initialized with\", args)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b37383cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torch.optim import Adam\n",
    "\n",
    "# # â”€â”€ 0) ë””ë°”ì´ìŠ¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(\"device =\", device)\n",
    "\n",
    "# # â”€â”€ 1) train_loaderì—ì„œ ì‹œí€€ìŠ¤ ê¸¸ì´ì™€ í”¼ì²˜ ì°¨ì› ì¶”ì¶œ â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# first_batch = next(iter(train_loader))\n",
    "# seqs, _     = first_batch            # (B, seq_len, feat_dim), (B, feat_dim)\n",
    "# _, seq_len, feat_dim = seqs.shape\n",
    "# out_dim     = feat_dim\n",
    "# hidden_dim  = 256\n",
    "\n",
    "# print(f\"seq_len = {seq_len}, feat_dim = {feat_dim}\")\n",
    "\n",
    "# # â”€â”€ 2) ëª¨ë¸ ì¹´íƒˆë¡œê·¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# MODEL_CATALOG = {\n",
    "#     \"gru\":                  GRUWithHead,\n",
    "#     \"transformer\":          TransformerWithHead,\n",
    "#     \"nopred\":               NoPrediction,\n",
    "#     \"pad\":                  SequentialPAD,\n",
    "#     \"pvec\":                 SequentialPVEC,\n",
    "#     \"seqrnn\":               SequentialRNN,\n",
    "#     \"seqlstm\":              SequentialLSTM,\n",
    "#     \"parallel_transformer\": ParallelTransformer,\n",
    "# }\n",
    "# # â”€â”€ 2.1) ëª¨ë¸ë³„ íŒŒë¼ë¯¸í„° ë§µ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# MODEL_PARAMS = {\n",
    "#     \"gru\": {\n",
    "#         \"feat_dim\":        feat_dim,\n",
    "#         \"hidden_size\":     128,\n",
    "#         \"num_layers\":      2,\n",
    "#         \"bidirectional\":   False,\n",
    "#         \"dropout\":         0.2,\n",
    "#         \"hidden_dim\":      hidden_dim,\n",
    "#         \"out_dim\":         out_dim,\n",
    "#         \"freeze_backbone\": False,\n",
    "#     },\n",
    "#     \"transformer\": {\n",
    "#         \"feat_dim\":        feat_dim,\n",
    "#         \"n_heads\":         4,\n",
    "#         \"dim_ff\":          256,\n",
    "#         \"n_layers\":        2,\n",
    "#         \"dropout\":         0.1,\n",
    "#         \"hidden_dim\":      hidden_dim,\n",
    "#         \"out_dim\":         out_dim,\n",
    "#         \"freeze_backbone\": False,\n",
    "#     },\n",
    "#     \"nopred\": {},\n",
    "#     \"pad\":    {\"eps\": 1e-6},\n",
    "#     \"pvec\":   {},\n",
    "#     \"seqrnn\": {\"feat_dim\": feat_dim, \"hidden\": 128},\n",
    "#     \"seqlstm\":{\"feat_dim\": feat_dim, \"hidden\": 128},\n",
    "#     \"parallel_transformer\": {\n",
    "#         \"feat_dim\": feat_dim,\n",
    "#         \"heads\":    4,\n",
    "#         \"dim_ff\":   256,\n",
    "#         \"layers\":   2,\n",
    "#     },\n",
    "# }\n",
    "\n",
    "\n",
    "# # â”€â”€ 3) ì‹¤í—˜í•  ëª¨ë¸ ì„ íƒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# model_name = \"gru\"  # ì›í•˜ëŠ” ëª¨ë¸ ì´ë¦„\n",
    "# ModelCls   = MODEL_CATALOG[model_name]\n",
    "\n",
    "# # â”€â”€ 3) ì‹¤í—˜í•  ëª¨ë¸ ì„ íƒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# model_name = \"gru\"  # ì›í•˜ëŠ” ëª¨ë¸ ì´ë¦„\n",
    "# ModelCls   = MODEL_CATALOG[model_name]\n",
    "# args       = MODEL_PARAMS[model_name]   # â˜… ì—¬ê¸°ê°€ ìˆ˜ì •ëœ ë¶€ë¶„\n",
    "\n",
    "# # â”€â”€ 4) ì¸ìŠ¤í„´ìŠ¤í™” & ì˜µí‹°ë§ˆì´ì € â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# model     = ModelCls(**args).to(device)\n",
    "# print(f\"ğŸŸ¢ {model_name} initialized with\", args)\n",
    "\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "\n",
    "\n",
    "# # â”€â”€ 5) ì¸ìŠ¤í„´ìŠ¤í™” & ì˜µí‹°ë§ˆì´ì € â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# model     = ModelCls(**args).to(device)\n",
    "# print(f\"ğŸŸ¢ {model_name} initialized with\", args)\n",
    "\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7f7e4ba2-a72d-48fc-89c8-acb7a92f984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def call_model(model: nn.Module, x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    ëª¨ë“  ëª¨ë¸ì„ í•œ ì¤„ë¡œ í˜¸ì¶œí•˜ê¸° ìœ„í•œ í—¬í¼.\n",
    "    Â· ëª¨ë“  ëª¨ë¸ì˜ forward(x) í˜•íƒœë¡œ í†µì¼ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    return model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3e8931ae-5238-415b-bea6-26c65ab15b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install umap-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a6a78d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(xb)               # call_model ëŒ€ì‹  ì§ì ‘ í˜¸ì¶œ\n",
    "        loss = criterion(pred, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running += loss.item() * xb.size(0)\n",
    "    return running / len(loader.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    tot_rmse = tot_nmse = tot_n = 0.0\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        pred = model(xb)               # ë™ì¼í•˜ê²Œ ì§ì ‘ í˜¸ì¶œ\n",
    "        bs   = xb.size(0)\n",
    "\n",
    "        tot_rmse += rmse(pred, yb).item() * bs\n",
    "        tot_nmse += nmse(pred, yb).item() * bs\n",
    "        tot_n    += bs\n",
    "\n",
    "    return tot_rmse / tot_n, tot_nmse / tot_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c2ed0412-306c-440a-b301-48116024e204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "def rmse(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Root-Mean-Squared Error (batch mean)\n",
    "    \"\"\"\n",
    "    return torch.sqrt(F.mse_loss(pred, target, reduction=\"mean\"))\n",
    "\n",
    "def nmse(pred: torch.Tensor, target: torch.Tensor, eps: float = 1e-12) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Normalized MSE (linear):\n",
    "      E[â€–pred â€“ targetâ€–Â²] / E[â€–targetâ€–Â²]\n",
    "    returns scalar (batch mean)\n",
    "    \"\"\"\n",
    "    mse_s = ((pred - target)**2).view(pred.size(0), -1).sum(dim=1)\n",
    "    pwr_s = (target**2).view(target.size(0), -1).sum(dim=1) + eps\n",
    "    return (mse_s / pwr_s).mean()\n",
    "\n",
    "def evaluate(model,\n",
    "             loader,\n",
    "             device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Validation loop **without any inverse-transform**.\n",
    "    Assumes your dataset already yields unit-power normalized targets.\n",
    "    Returns dict with:\n",
    "      \"RMSE\" : linear RMSE,\n",
    "      \"NMSE\" : linear NMSE.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_rmse, total_nmse, total_samples = 0.0, 0.0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            pred   = model(xb)\n",
    "\n",
    "            bs = xb.size(0)\n",
    "            total_rmse  += rmse(pred, yb).item() * bs\n",
    "            total_nmse  += nmse(pred, yb).item() * bs\n",
    "            total_samples += bs\n",
    "\n",
    "    return {\n",
    "        \"RMSE\": total_rmse  / total_samples,\n",
    "        \"NMSE\": total_nmse  / total_samples\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a06b20a",
   "metadata": {},
   "source": [
    "# model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7b169d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training gru ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gru 01/10] Train Loss: 0.0064  Val RMSE: 0.0397  Val NMSE: 8.0955e-03  Val NMSE_dB: -20.9 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gru 02/10] Train Loss: 0.0028  Val RMSE: 0.0385  Val NMSE: 7.7995e-03  Val NMSE_dB: -21.1 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gru 03/10] Train Loss: 0.0025  Val RMSE: 0.0387  Val NMSE: 7.7534e-03  Val NMSE_dB: -21.1 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gru 04/10] Train Loss: 0.0024  Val RMSE: 0.0375  Val NMSE: 7.4857e-03  Val NMSE_dB: -21.3 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gru 05/10] Train Loss: 0.0023  Val RMSE: 0.0372  Val NMSE: 7.4040e-03  Val NMSE_dB: -21.3 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gru 06/10] Train Loss: 0.0022  Val RMSE: 0.0368  Val NMSE: 7.2813e-03  Val NMSE_dB: -21.4 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gru 07/10] Train Loss: 0.0021  Val RMSE: 0.0368  Val NMSE: 7.2418e-03  Val NMSE_dB: -21.4 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gru 08/10] Train Loss: 0.0020  Val RMSE: 0.0367  Val NMSE: 7.2382e-03  Val NMSE_dB: -21.4 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gru 09/10] Train Loss: 0.0020  Val RMSE: 0.0361  Val NMSE: 7.0640e-03  Val NMSE_dB: -21.5 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dlghd\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gru 10/10] Train Loss: 0.0019  Val RMSE: 0.0361  Val NMSE: 7.0833e-03  Val NMSE_dB: -21.5 dB\n",
      "gru training time: 723.12s\n",
      "\n",
      "=== Training transformer ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[transformer 01/10] Train Loss: 0.0058  Val RMSE: 0.0380  Val NMSE: 7.6651e-03  Val NMSE_dB: -21.2 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[transformer 02/10] Train Loss: 0.0025  Val RMSE: 0.0367  Val NMSE: 7.2496e-03  Val NMSE_dB: -21.4 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[transformer 03/10] Train Loss: 0.0022  Val RMSE: 0.0359  Val NMSE: 7.0929e-03  Val NMSE_dB: -21.5 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[transformer 04/10] Train Loss: 0.0021  Val RMSE: 0.0359  Val NMSE: 7.1014e-03  Val NMSE_dB: -21.5 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[transformer 05/10] Train Loss: 0.0020  Val RMSE: 0.0351  Val NMSE: 6.9362e-03  Val NMSE_dB: -21.6 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[transformer 06/10] train:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 5213/6268 [01:44<00:21, 49.76it/s, train_loss=0.00189]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "num_epochs     = 10\n",
    "LR             = 1e-4\n",
    "start_time_all = time.time()\n",
    "results        = {}\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ëª¨ë¸ë³„ Training & Validation Loop\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "for model_name, ModelCls in MODEL_CATALOG.items():\n",
    "    print(f\"\\n=== Training {model_name} ===\")\n",
    "    # 1) ëª¨ë¸ ì´ˆê¸°í™”\n",
    "    args  = MODEL_PARAMS[model_name]\n",
    "    model = ModelCls(**args).to(device)\n",
    "\n",
    "    # 2) trainable íŒŒë¼ë¯¸í„° ì²´í¬\n",
    "    trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "    if len(trainable_params) == 0:\n",
    "        print(f\"âš ï¸  '{model_name}' has no trainable parameters â€” skipping training.\")\n",
    "        # í•„ìš”í•˜ë‹¤ë©´ validationë§Œ ëŒë ¤ë³´ê±°ë‚˜, ê²°ê³¼ì— NaN/None ê¸°ë¡\n",
    "        results[model_name] = float('nan')\n",
    "        continue\n",
    "\n",
    "    # 3) ì˜µí‹°ë§ˆì´ì €\n",
    "    optimizer = torch.optim.Adam(trainable_params, lr=LR)\n",
    "\n",
    "    start_time_model = time.time()\n",
    "\n",
    "    # 4) ì—í­ ë£¨í”„\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        pbar = tqdm(train_loader, desc=f\"[{model_name} {epoch:02d}/{num_epochs}] train\", leave=False)\n",
    "        for i, (xb, yb) in enumerate(pbar, 1):\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(xb)\n",
    "            loss = criterion(pred, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 0:\n",
    "                pbar.set_postfix(train_loss=running_loss / i)\n",
    "\n",
    "        avg_train_loss = running_loss / i\n",
    "\n",
    "        # VALIDATION\n",
    "        metrics     = evaluate(model, val_loader, device)\n",
    "        val_rmse    = metrics[\"RMSE\"]\n",
    "        val_nmse    = metrics[\"NMSE\"]\n",
    "        val_nmse_db = 10 * math.log10(val_nmse)\n",
    "\n",
    "        print(\n",
    "            f\"[{model_name} {epoch:02d}/{num_epochs}] \"\n",
    "            f\"Train Loss: {avg_train_loss:.4f}  \"\n",
    "            f\"Val RMSE: {val_rmse:.4f}  \"\n",
    "            f\"Val NMSE: {val_nmse:.4e}  \"\n",
    "            f\"Val NMSE_dB: {val_nmse_db:.1f} dB\"\n",
    "        )\n",
    "\n",
    "    elapsed = time.time() - start_time_model\n",
    "    print(f\"{model_name} training time: {elapsed:.2f}s\")\n",
    "    results[model_name] = val_nmse_db\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ëª¨ë“  ëª¨ë¸ ìš”ì•½\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\n=== Summary of NMSE(dB) by model ===\")\n",
    "for name, nmse_db in results.items():\n",
    "    print(f\"{name:20s}: {nmse_db if not math.isnan(nmse_db) else 'skipped':>6}\")\n",
    "\n",
    "print(f\"\\nTotal training time for all models: {time.time() - start_time_all:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6932b03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c721e61b-0c2f-43fa-b12d-16e02a703ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb9b24c-bd94-4495-8334-e777fd697995",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
