{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0939df15-abc7-40e7-83bf-f12820dd42f2",
   "metadata": {},
   "source": [
    "# All Model saves here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cbf7fb-304f-432d-a3f9-580052d5a375",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0e94396-1d80-4df3-8648-19368f82c4b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import DeepMIMOv3\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "plt . rcParams [ 'figure.figsize' ]  =  [ 12 ,  8 ]  # 기본 플롯 크기 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b517656b-b91e-4bb6-a766-59c77f93f9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch\n",
      "  Downloading torch-2.7.1-cp310-cp310-manylinux_2_28_x86_64.whl (821.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.2/821.2 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparselt-cu12==0.6.3\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch) (3.0.3)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.7.77\n",
      "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==9.5.1.17\n",
      "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.14.0)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Collecting triton==3.3.1\n",
      "  Downloading triton-3.3.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/155.6 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.6.77\n",
      "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 KB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.26.2\n",
      "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.7.1.2\n",
      "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.5.4.2\n",
      "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.6.77\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufile-cu12==1.11.1.6\n",
      "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.6.77\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 KB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting fsspec\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.6.80\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.3.0.4\n",
      "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.6.4.1\n",
      "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sympy>=1.13.3\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=40.8.0 in /usr/lib/python3/dist-packages (from triton==3.3.1->torch) (59.6.0)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 KB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, mpmath, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
      "\u001b[33m  WARNING: The scripts proton and proton-viewer are installed in '/home/dlghdbs200/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script isympy is installed in '/home/dlghdbs200/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts torchfrtrace and torchrun are installed in '/home/dlghdbs200/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed filelock-3.18.0 fsspec-2025.5.1 mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 sympy-1.14.0 torch-2.7.1 triton-3.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb2d8b4-7d3d-43ae-b997-2a4e6eab9a1a",
   "metadata": {},
   "source": [
    "## GPU Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6479f7-d2b2-4632-b3a8-ffe3c49a6608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea87b9c9-a4b1-4442-b26f-606828c4dc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)                   \n",
    "print(torch.backends.cudnn.version())       \n",
    "print(\"CUDA available:\", torch.cuda.is_available())  # True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dc1a47-3bc0-4236-813e-c7be4c21bd41",
   "metadata": {},
   "source": [
    "## DeepMIMOv3 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821eb69b-806e-4694-adf9-fd0efcbf5e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = DeepMIMOv3.default_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d1f75d-54c0-4198-990f-15eaeec28e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change parameters for the setup\n",
    "# Scenario O1_60 extracted at the dataset_folder\n",
    "#LWM dynamic senario\n",
    "# parameters['dataset_folder'] = r'/content/drive/MyDrive/Colab Notebooks/LWM'\n",
    "scene = 15 # scene 15\n",
    "# change my linux route\n",
    "parameters['dataset_folder'] = '/home/dlghdbs200/LWM'\n",
    "\n",
    "# scnario = 02_dyn_3p5 <- download file\n",
    "parameters['scenario'] = 'O2_dyn_3p5'\n",
    "parameters['dynamic_scenario_scenes'] = np.arange(scene) #scene 0~9\n",
    "\n",
    "# Up to 10 multipath paths per user-to-base station channel\n",
    "parameters['num_paths'] = 10\n",
    "\n",
    "# User rows 1-100\n",
    "parameters['user_rows'] = np.arange(100)\n",
    "# User subsampling\n",
    "parameters['user_subsampling'] = 0.01\n",
    "\n",
    "# Activate only the first basestation\n",
    "parameters['active_BS'] = np.array([1])\n",
    "\n",
    "parameters['activate_OFDM'] = 1\n",
    "\n",
    "parameters['OFDM']['bandwidth'] = 0.05 # 50 MHz\n",
    "parameters['OFDM']['subcarriers'] = 512 # OFDM with 512 subcarriers\n",
    "parameters['OFDM']['selected_subcarriers'] = np.arange(0, 64, 1)\n",
    "#parameters['OFDM']['subcarriers_limit'] = 64 # Keep only first 64 subcarriers\n",
    "\n",
    "parameters['ue_antenna']['shape'] = np.array([1, 1]) # Single antenna\n",
    "parameters['bs_antenna']['shape'] = np.array([1, 32]) # ULA of 32 elements\n",
    "#parameters['bs_antenna']['rotation'] = np.array([0, 30, 90]) # ULA of 32 elements\n",
    "#parameters['ue_antenna']['rotation'] = np.array([[0, 30], [30, 60], [60, 90]]) # ULA of 32 elements\n",
    "#parameters['ue_antenna']['radiation_pattern'] = 'isotropic'\n",
    "#parameters['bs_antenna']['radiation_pattern'] = 'halfwave-dipole'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5195cacf-c393-4cb9-b0ba-51ff90230e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dataset setting (chunked on‑the‑fly generation)\n",
    "import time, gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 0~999 scene index , process 50 at that time\n",
    "scene_indices = np.arange(scene)\n",
    "chunk_size   = 5\n",
    "all_data     = []\n",
    "\n",
    "# Call generate_data for each scene chunk\n",
    "for i in tqdm(range(0, len(scene_indices), chunk_size)):\n",
    "    chunk = scene_indices[i : i+chunk_size].tolist()\n",
    "    parameters['dynamic_scenario_scenes'] = chunk\n",
    "\n",
    "    start = time.time()\n",
    "    data_chunk = DeepMIMOv3.generate_data(parameters)\n",
    "    print(f\"Scenes {chunk[0]}–{chunk[-1]} generation time: {time.time() - start:.2f}s\")\n",
    "\n",
    "    # combine all_data or save in the Disk\n",
    "    all_data.extend(data_chunk)\n",
    "\n",
    "    # free memory \n",
    "    del data_chunk\n",
    "    gc.collect()\n",
    "\n",
    "# comvine Dataset\n",
    "dataset = all_data\n",
    "\n",
    "\n",
    "print(parameters['user_rows'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc75e14-9605-49b0-8034-2a1dc367f97e",
   "metadata": {},
   "source": [
    "## About Information\n",
    "User : 737\n",
    "UE antenna : 1\n",
    "BS antenna : 32  Shape(a+bj)\n",
    "subcarrier : 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48148074-4682-4ab8-acbe-71ef042a5020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unmasked Data Model(gru\n",
    "# separate maksed data and unmasked data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe56d11-0ebb-4c13-b4c2-61fadd9c714b",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba0a2d3-ee35-43dc-b457-bd400e5b75c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────\n",
    "# ❶ IterableDataset: stream all users and subcarriers\n",
    "import torch\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class UnmaskedChannelSeqDataset(IterableDataset):\n",
    "    \"\"\"\n",
    "    • Predict next-timestep vector from seq_len past channel vectors (real 64 + imag 64 → 128)\n",
    "    • Vectors are power-normalized to unit average power before returning\n",
    "    \"\"\"\n",
    "    def __init__(self, scenes, seq_len: int = 5, eps: float = 1e-9):\n",
    "        super().__init__()\n",
    "        self.scenes   = scenes\n",
    "        self.seq_len  = seq_len\n",
    "        self.eps      = eps                        # small constant to prevent division by zero\n",
    "        ch0           = scenes[0][0]['user']['channel']\n",
    "        self.U        = ch0.shape[0]               # number of users\n",
    "        self.A        = ch0.shape[2]               # number of antennas (e.g., 32)\n",
    "        self.S        = ch0.shape[3]               # number of subcarriers (e.g., 64)\n",
    "        self.vec_len  = 2 * self.A                 # length of real+imag vector (2 * antennas)\n",
    "        0\n",
    "\n",
    "    def _vec(self, scene, u: int, sc: int) -> torch.Tensor:\n",
    "        \"\"\"Convert complex channel vector (32,) to float32 vector (64,) + power normalization\"\"\"\n",
    "        h = scene[0]['user']['channel'][u, 0, :, sc]          # complex vector of shape (A,)\n",
    "        v = np.concatenate([h.real, h.imag]).astype(np.float32)\n",
    "        p = np.mean(v * v) + self.eps                         # average power: mean of squared amplitudes\n",
    "        v /= np.sqrt(p)                                       # normalize to unit power\n",
    "        return torch.from_numpy(v)                            # return tensor of shape (vec_len,)\n",
    "\n",
    "    def __iter__(self):\n",
    "        T = len(self.scenes)\n",
    "        for t in range(self.seq_len, T):  # target timestep index\n",
    "            past_scenes = self.scenes[t - self.seq_len : t]\n",
    "            tgt_scene   = self.scenes[t]\n",
    "            for u in range(self.U):\n",
    "                for s in range(self.S):\n",
    "                    seq = torch.stack([self._vec(ps, u, s) for ps in past_scenes])\n",
    "                    if not torch.any(seq):        # skip if all sequence entries are zero\n",
    "                        continue\n",
    "                    target = self._vec(tgt_scene, u, s)\n",
    "                    if not torch.any(target):     # skip if target vector is zero\n",
    "                        continue\n",
    "                    yield seq, target             # masked_pos removed here\n",
    "                # shapes: (seq_len, vec_len) / (vec_len,)\n",
    "\n",
    "    def __len__(self):\n",
    "         return (len(self.scenes) - self.seq_len) * self.U * self.S\n",
    "# ─────────────────────────────────────────────\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d365ac-69a6-494c-bfc7-198bdeb29582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────\n",
    "# ❶ IterableDataset: stream all users and subcarriers\n",
    "import torch\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class MaskedChannelSeqDataset(IterableDataset):\n",
    "    \"\"\"\n",
    "    • Predict next-timestep vector from seq_len past channel vectors (real 64 + imag 64 → 128)\n",
    "    • Vectors are power-normalized to unit average power before returning\n",
    "    \"\"\"\n",
    "    def __init__(self, scenes, seq_len: int = 5, eps: float = 1e-9):\n",
    "        super().__init__()\n",
    "        self.scenes   = scenes\n",
    "        self.seq_len  = seq_len\n",
    "        self.eps      = eps                        # small constant to prevent division by zero\n",
    "        ch0           = scenes[0][0]['user']['channel']\n",
    "        self.U        = ch0.shape[0]               # number of users\n",
    "        self.A        = ch0.shape[2]               # number of antennas (e.g., 32)\n",
    "        self.S        = ch0.shape[3]               # number of subcarriers (e.g., 64)\n",
    "        self.vec_len  = 2 * self.A                 # length of real+imag vector (2 * antennas)\n",
    "        0\n",
    "\n",
    "    def _vec(self, scene, u: int, sc: int) -> torch.Tensor:\n",
    "        \"\"\"Convert complex channel vector (32,) to float32 vector (64,) + power normalization\"\"\"\n",
    "        h = scene[0]['user']['channel'][u, 0, :, sc]          # complex vector of shape (A,)\n",
    "        v = np.concatenate([h.real, h.imag]).astype(np.float32)\n",
    "        p = np.mean(v * v) + self.eps                         # average power: mean of squared amplitudes\n",
    "        v /= np.sqrt(p)                                       # normalize to unit power\n",
    "        return torch.from_numpy(v)                            # return tensor of shape (vec_len,)\n",
    "\n",
    "    def __iter__(self):\n",
    "        T = len(self.scenes)\n",
    "        for t in range(self.seq_len, T):  # target timestep index\n",
    "            past_scenes = self.scenes[t - self.seq_len : t]\n",
    "            tgt_scene   = self.scenes[t]\n",
    "            for u in range(self.U):\n",
    "                for s in range(self.S):\n",
    "                    seq = torch.stack([self._vec(ps, u, s) for ps in past_scenes])\n",
    "                    if not torch.any(seq):        # skip if all sequence entries are zero\n",
    "                        continue\n",
    "                    target = self._vec(tgt_scene, u, s)\n",
    "                    if not torch.any(target):     # skip if target vector is zero\n",
    "                        continue\n",
    "                    yield seq, target             # masked_pos removed here\n",
    "                # shapes: (seq_len, vec_len) / (vec_len,)\n",
    "\n",
    "    def __len__(self):\n",
    "         return (len(self.scenes) - self.seq_len) * self.U * self.S\n",
    "# ─────────────────────────────────────────────\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e1373a-f803-49f3-b891-f9d6f59e5dc9",
   "metadata": {},
   "source": [
    "## Split Train/Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd809a5-3720-4ffd-90ce-b2d5ccf541f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ❷ Train/Validation DataLoader split train : val = 6 : 4\n",
    "seq_len      = 5\n",
    "split_ratio  = 0.6\n",
    "split_idx    = int(len(dataset) * split_ratio)\n",
    "\n",
    "unmasked_train_ds = UnmaskedChannelSeqDataset(dataset[:split_idx], seq_len=seq_len)\n",
    "unmasked_val_ds   = UnmaskedChannelSeqDataset(dataset[split_idx:], seq_len=seq_len)\n",
    "\n",
    "# iterate over train_ds to compute min and max of features/targets\n",
    "\n",
    "batch_size   = 32\n",
    "unmasked_train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False)\n",
    "unmasked_val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False)\n",
    "# ─────────────────────────────────────────────\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b29d65-387d-4326-b989-afe274279c38",
   "metadata": {},
   "source": [
    "## Normalization Dataset(Min-Max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcd8948-f183-4cc2-94d6-a5041d2141d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data      import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# 1) extract Numpy \n",
    "# tgt = target\n",
    "X_list, y_list = [], []\n",
    "for seq, tgt in ChannelSeqDataset(dataset, seq_len=seq_len):\n",
    "    X_list.append(seq.numpy())\n",
    "    y_list.append(tgt.numpy())\n",
    "\n",
    "X = np.stack(X_list, axis=0)  # (N, L, D)\n",
    "y = np.stack(y_list, axis=0)  # (N, D)\n",
    "\n",
    "# 2) Train/Val split\n",
    "split_idx = int(len(X) * split_ratio)\n",
    "X_tr, X_va = X[:split_idx], X[split_idx:]\n",
    "y_tr, y_va = y[:split_idx], y[split_idx:]\n",
    "\n",
    "# 3) normalize MinMaxScaler\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "Ntr, L, D = X_tr.shape\n",
    "\n",
    "scaler_x.fit(X_tr.reshape(-1, D))\n",
    "scaler_y.fit(y_tr)\n",
    "\n",
    "# 4) Restore original shape after transform\n",
    "X_tr_s = scaler_x.transform(X_tr.reshape(-1, D)).reshape(Ntr, L, D)\n",
    "\n",
    "Nva = X_va.shape[0]\n",
    "X_va_s = scaler_x.transform(X_va.reshape(-1, D)).reshape(Nva, L, D)\n",
    "\n",
    "y_tr_s = scaler_y.transform(y_tr)\n",
    "y_va_s = scaler_y.transform(y_va)\n",
    "\n",
    "# 5) Dataset & DataLoader\n",
    "train_ds    = TensorDataset(\n",
    "    torch.from_numpy(X_tr_s).float(),\n",
    "    torch.from_numpy(y_tr_s).float()\n",
    ")\n",
    "val_ds      = TensorDataset(\n",
    "    torch.from_numpy(X_va_s).float(),\n",
    "    torch.from_numpy(y_va_s).float()\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 6) first batch unpacking\n",
    "seqs, tgts = next(iter(train_loader))  # seqs: (B, L, D), tgts: (B, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c33fca-38fa-4842-b886-69972e5d28a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e8f0ee-6782-4eb2-b6c3-fe363ed8d507",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
