{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% PACKAGES & MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from inference import prepare_for_lwm\n",
    "from input_preprocess import tokenizer\n",
    "from lwm_model import lwm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "n_layers = 12\n",
    "n_heads = 12\n",
    "d_model = 64\n",
    "d_ff = d_model * 4\n",
    "d_k = d_model // n_heads\n",
    "d_v = d_model // n_heads\n",
    "dropout = 0.1\n",
    "max_len = 129\n",
    "element_length = 16\n",
    "batch_size = 64\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.2\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% PRE-TRAINING DATA GENERATION<br>\n",
    "The following DeepMIMO scenarios are not enough for pre-training a <br>\n",
    "Transformer-based foundation model like LWM. Add more scenarios for <br>\n",
    "more effective pre-training. The instruction for reproducing the actual <br>\n",
    "dataset used for pre-training LWM can be found in the Huggingface forum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_names = np.array([\n",
    "    \"city_18_denver\", \"city_15_indianapolis\", \"city_19_oklahoma\", \n",
    "    \"city_12_fortworth\", \"city_11_santaclara\", \"city_7_sandiego\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_idxs = np.array([0, 1, 2, 3, 4, 5])  \n",
    "selected_scenario_names = scenario_names[scenario_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_chs = tokenizer(\n",
    "    selected_scenario_names=selected_scenario_names, \n",
    "    manual_data=None, \n",
    "    gen_raw=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "% DATALOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(train_ratio * len(preprocessed_chs))\n",
    "val_size = int(val_ratio * len(preprocessed_chs))\n",
    "test_size = len(preprocessed_chs) - val_size - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = torch.utils.data.random_split(\n",
    "    preprocessed_chs, [train_size, val_size, test_size]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = prepare_for_lwm(train_data, device, batch_size=batch_size, shuffle=True)\n",
    "val_loader = prepare_for_lwm(val_data, device, batch_size=batch_size, shuffle=True)\n",
    "test_loader = prepare_for_lwm(test_data, device, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%% Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lwm()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_model:\n",
    "    model_name = 'models/pretrained_model.pth'\n",
    "    model.load_state_dict(torch.load(model_name))\n",
    "    print(f\"Model loaded from {model_name}\")\n",
    "    \n",
    "# Loss function\n",
    "criterionMLM = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%% Optimizer and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_lr = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = (\n",
    "    optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')\n",
    "    if adaptive_lr\n",
    "    else StepLR(optimizer, step_size=10, gamma=0.9)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%% Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = []\n",
    "validation_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, scheduler=None, device=\"cuda\"):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    criterionMCM = nn.MSELoss()\n",
    "    for idx, batch in enumerate(dataloader):\n",
    "        input_ids = batch[0].to(device)\n",
    "        masked_tokens = batch[1].to(device)\n",
    "        masked_pos = batch[2].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits_lm, _ = model(input_ids, masked_pos)\n",
    "        loss_lm = criterionMCM(logits_lm, masked_tokens)\n",
    "        loss = loss_lm / torch.var(masked_tokens) \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        running_loss += loss.item()\n",
    "    average_loss = running_loss / len(dataloader)\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    criterionMCM = nn.MSELoss()\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(dataloader):\n",
    "            input_ids = batch[0].to(device)\n",
    "            masked_tokens = batch[1].to(device)\n",
    "            masked_pos = batch[2].to(device)\n",
    "            logits_lm, _ = model(input_ids, masked_pos)\n",
    "            loss_lm = criterionMCM(logits_lm, masked_tokens)\n",
    "            loss = loss_lm / torch.var(masked_tokens)  \n",
    "            running_loss += loss.item()\n",
    "    average_loss = running_loss / len(dataloader)\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%% Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{n_epochs}\")\n",
    "\n",
    "    # Training step\n",
    "    train_loss = train(model, train_loader, optimizer, scheduler, device)\n",
    "    training_loss.append(train_loss)\n",
    "    print(f\"Training Loss: {train_loss:.4f}\")\n",
    "\n",
    "    # Validation step\n",
    "    if val_loader is not None:\n",
    "        val_loss = validate(model, val_loader, device)\n",
    "        validation_loss.append(val_loss)\n",
    "        print(f\"Validation Loss: {val_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
