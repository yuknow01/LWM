{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeacb7fd",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ec90d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "#LWM을 하기위한 라이브러리 가져오기\n",
    "import DeepMIMOv3\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "plt . rcParams [ 'figure.figsize' ]  =  [ 12 ,  8 ]  # 기본 플롯 크기 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e17e0b",
   "metadata": {},
   "source": [
    "## GPU설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47baa533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# GPU 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a6fcece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8\n",
      "90100\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)                   # 설치된 CUDA 버전 (예: '11.7')\n",
    "print(torch.backends.cudnn.version())       # cuDNN 버전 (예: 8200)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())  # True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9e064d",
   "metadata": {},
   "source": [
    "# DeepMIMOv3 다운"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23623e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install DeepMIMOv3 umap-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19540670",
   "metadata": {},
   "source": [
    "## 파라미터 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce5ac681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'OFDM': {'RX_filter': 0,\n",
      "          'bandwidth': 0.05,\n",
      "          'selected_subcarriers': array([0]),\n",
      "          'subcarriers': 512},\n",
      " 'OFDM_channels': 1,\n",
      " 'active_BS': array([1]),\n",
      " 'bs_antenna': {'FoV': array([360, 180]),\n",
      "                'radiation_pattern': 'isotropic',\n",
      "                'rotation': array([0, 0, 0]),\n",
      "                'shape': array([8, 4]),\n",
      "                'spacing': 0.5},\n",
      " 'dataset_folder': './Raytracing_scenarios',\n",
      " 'dynamic_scenario_scenes': array([1]),\n",
      " 'enable_BS2BS': 1,\n",
      " 'enable_doppler': 0,\n",
      " 'enable_dual_polar': 0,\n",
      " 'num_paths': 5,\n",
      " 'scenario': 'O1_60',\n",
      " 'ue_antenna': {'FoV': array([360, 180]),\n",
      "                'radiation_pattern': 'isotropic',\n",
      "                'rotation': array([0, 0, 0]),\n",
      "                'shape': array([4, 2]),\n",
      "                'spacing': 0.5},\n",
      " 'user_rows': array([1]),\n",
      " 'user_subsampling': 1}\n"
     ]
    }
   ],
   "source": [
    "## Load and print the default parameters\n",
    "# bandwith: 0.05GHz(50MHz 대역폭 사용)\n",
    "parameters = DeepMIMOv3.default_params()\n",
    "pprint(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f0642c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change parameters for the setup\n",
    "# Scenario O1_60 extracted at the dataset_folder\n",
    "#LWM 동적 시나리오 불러오기\n",
    "#자신의 LWM 파일 위치 경로 작성\n",
    "# parameters['dataset_folder'] = r'/content/drive/MyDrive/Colab Notebooks/LWM'\n",
    "scene = 15 # 장면 수\n",
    "parameters['dataset_folder'] = r'C:\\Users\\dlghd\\졸업프로젝트\\LWM'\n",
    "\n",
    "# scnario = 02_dyn_3p5 <- 다운받은 파일(동적시나리오)\n",
    "parameters['scenario'] = 'O2_dyn_3p5'\n",
    "parameters['dynamic_scenario_scenes'] = np.arange(scene) #scene 0~9\n",
    "\n",
    "# 각 사용자-기지국 채널에 대해 최대 10개 멀티패스 경로 사용\n",
    "parameters['num_paths'] = 10\n",
    "\n",
    "# User rows 1-100\n",
    "parameters['user_rows'] = np.arange(100)\n",
    "# User 축소하기\n",
    "parameters['user_subsampling'] = 0.01\n",
    "\n",
    "# Activate only the first basestation\n",
    "parameters['active_BS'] = np.array([1])\n",
    "\n",
    "parameters['activate_OFDM'] = 1\n",
    "\n",
    "parameters['OFDM']['bandwidth'] = 0.05 # 50 MHz\n",
    "parameters['OFDM']['subcarriers'] = 512 # OFDM with 512 subcarriers\n",
    "parameters['OFDM']['selected_subcarriers'] = np.arange(0, 64, 1)\n",
    "#parameters['OFDM']['subcarriers_limit'] = 64 # Keep only first 64 subcarriers\n",
    "\n",
    "parameters['ue_antenna']['shape'] = np.array([1, 1]) # Single antenna\n",
    "parameters['bs_antenna']['shape'] = np.array([1, 32]) # ULA of 32 elements\n",
    "#parameters['bs_antenna']['rotation'] = np.array([0, 30, 90]) # ULA of 32 elements\n",
    "#parameters['ue_antenna']['rotation'] = np.array([[0, 30], [30, 60], [60, 90]]) # ULA of 32 elements\n",
    "#parameters['ue_antenna']['radiation_pattern'] = 'isotropic'\n",
    "#parameters['bs_antenna']['radiation_pattern'] = 'halfwave-dipole'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30aa4ae2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_folder': 'C:\\\\Users\\\\dlghd\\\\졸업프로젝트\\\\LWM', 'scenario': 'O2_dyn_3p5', 'dynamic_scenario_scenes': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]), 'num_paths': 10, 'active_BS': array([1]), 'user_rows': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
      "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
      "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]), 'user_subsampling': 0.01, 'bs_antenna': {'shape': array([ 1, 32]), 'spacing': 0.5, 'rotation': array([0, 0, 0]), 'FoV': array([360, 180]), 'radiation_pattern': 'isotropic'}, 'ue_antenna': {'shape': array([1, 1]), 'spacing': 0.5, 'rotation': array([0, 0, 0]), 'FoV': array([360, 180]), 'radiation_pattern': 'isotropic'}, 'enable_doppler': 0, 'enable_dual_polar': 0, 'enable_BS2BS': 1, 'OFDM_channels': 1, 'OFDM': {'subcarriers': 512, 'selected_subcarriers': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]), 'bandwidth': 0.05, 'RX_filter': 0}, 'activate_OFDM': 1}\n"
     ]
    }
   ],
   "source": [
    "print(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3326b22d",
   "metadata": {},
   "source": [
    "## dataset 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b87a86e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following parameters seem unnecessary:\n",
      "{'activate_OFDM'}\n",
      "\n",
      "Scene 1/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                   | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  27%|█████████████▉                                     | 18842/69006 [00:00<00:00, 188409.85it/s]\u001b[A\n",
      "Reading ray-tracing:  57%|████████████████████████████▉                      | 39182/69006 [00:00<00:00, 197108.91it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 197861.33it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                     | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 4674.00it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 109.15it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 2/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                   | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  25%|████████████▊                                      | 17327/69006 [00:00<00:00, 172374.24it/s]\u001b[A\n",
      "Reading ray-tracing:  56%|████████████████████████████▊                      | 38925/69006 [00:00<00:00, 197411.96it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 170836.65it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                     | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 4490.85it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 493.74it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 3/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                   | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  28%|██████████████                                     | 19007/69006 [00:00<00:00, 189761.63it/s]\u001b[A\n",
      "Reading ray-tracing:  55%|████████████████████████████                       | 37984/69006 [00:00<00:00, 182436.55it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 190129.44it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                     | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels:  25%|██████████████                                           | 179/727 [00:00<00:00, 1774.38it/s]\u001b[A\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 3035.52it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 998.41it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 498.85it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 4/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                   | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  32%|████████████████▍                                  | 22240/69006 [00:00<00:00, 221409.38it/s]\u001b[A\n",
      "Reading ray-tracing:  64%|████████████████████████████████▊                  | 44381/69006 [00:00<00:00, 213371.09it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 199685.36it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                     | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 4162.90it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|█████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1000.79it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 459.45it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 5/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                   | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  21%|██████████▊                                        | 14586/69006 [00:00<00:00, 144586.74it/s]\u001b[A\n",
      "Reading ray-tracing:  42%|█████████████████████▍                             | 29045/69006 [00:00<00:00, 132927.05it/s]\u001b[A\n",
      "Reading ray-tracing:  69%|██████████████████████████████████▉                | 47280/69006 [00:00<00:00, 153845.20it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 157224.46it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                     | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 4809.62it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 999.83it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 302.03it/s]\u001b[A\n",
      " 33%|████████████████████████████                                                        | 1/3 [00:08<00:16,  8.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenes 0–4 generation time: 8.18s\n",
      "The following parameters seem unnecessary:\n",
      "{'activate_OFDM'}\n",
      "\n",
      "Scene 1/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                   | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  28%|██████████████▏                                    | 19226/69006 [00:00<00:00, 190766.09it/s]\u001b[A\n",
      "Reading ray-tracing:  56%|████████████████████████████▎                      | 38303/69006 [00:00<00:00, 160216.45it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 160803.76it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                     | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 3783.04it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 333.28it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 2/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                   | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  23%|███████████▉                                       | 16216/69006 [00:00<00:00, 161013.87it/s]\u001b[A\n",
      "Reading ray-tracing:  48%|████████████████████████▍                          | 33109/69006 [00:00<00:00, 165408.48it/s]\u001b[A\n",
      "Reading ray-tracing:  73%|█████████████████████████████████████▍             | 50627/69006 [00:00<00:00, 169228.75it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 161992.49it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                     | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 4604.53it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 333.28it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 3/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                   | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  27%|█████████████▌                                     | 18410/69006 [00:00<00:00, 182949.52it/s]\u001b[A\n",
      "Reading ray-tracing:  58%|█████████████████████████████▎                     | 39689/69006 [00:00<00:00, 200413.22it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 198661.65it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                     | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels:  20%|███████████▎                                             | 145/727 [00:00<00:00, 1443.80it/s]\u001b[A\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 2817.55it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|█████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1002.22it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 166.22it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 4/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                   | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  30%|███████████████▎                                   | 20657/69006 [00:00<00:00, 206343.89it/s]\u001b[A\n",
      "Reading ray-tracing:  60%|██████████████████████████████▊                    | 41681/69006 [00:00<00:00, 208013.12it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 201197.98it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                     | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 3797.77it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 332.99it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 5/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                   | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  29%|██████████████▊                                    | 20092/69006 [00:00<00:00, 200522.90it/s]\u001b[A\n",
      "Reading ray-tracing:  58%|█████████████████████████████▋                     | 40145/69006 [00:00<00:00, 193646.04it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 185004.26it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                     | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 4099.41it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 333.09it/s]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████████                            | 2/3 [00:16<00:08,  8.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenes 5–9 generation time: 8.10s\n",
      "The following parameters seem unnecessary:\n",
      "{'activate_OFDM'}\n",
      "\n",
      "Scene 1/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                   | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  26%|█████████████▏                                     | 17813/69006 [00:00<00:00, 177520.28it/s]\u001b[A\n",
      "Reading ray-tracing:  52%|██████████████████████████▎                        | 35566/69006 [00:00<00:00, 151725.30it/s]\u001b[A\n",
      "Reading ray-tracing:  74%|█████████████████████████████████████▋             | 50975/69006 [00:00<00:00, 103679.76it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 117763.77it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                     | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels:  35%|███████████████████▉                                     | 255/727 [00:00<00:00, 2545.02it/s]\u001b[A\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 3028.38it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 235.40it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 2/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                   | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  23%|███████████▍                                       | 15548/69006 [00:00<00:00, 154473.23it/s]\u001b[A\n",
      "Reading ray-tracing:  48%|████████████████████████▍                          | 33120/69006 [00:00<00:00, 166619.86it/s]\u001b[A\n",
      "Reading ray-tracing:  72%|████████████████████████████████████▊              | 49784/69006 [00:00<00:00, 166082.80it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 162930.38it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                     | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels:  27%|███████████████▌                                         | 198/727 [00:00<00:00, 1945.05it/s]\u001b[A\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 2794.61it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 333.04it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 3/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                   | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  15%|███████▌                                           | 10276/69006 [00:00<00:00, 102745.16it/s]\u001b[A\n",
      "Reading ray-tracing:  31%|███████████████▊                                   | 21360/69006 [00:00<00:00, 106935.99it/s]\u001b[A\n",
      "Reading ray-tracing:  53%|███████████████████████████                        | 36701/69006 [00:00<00:00, 127620.00it/s]\u001b[A\n",
      "Reading ray-tracing:  74%|█████████████████████████████████████▋             | 51016/69006 [00:00<00:00, 133223.67it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 128516.22it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                     | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 3723.29it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 499.92it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 108.76it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 4/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                   | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  26%|█████████████▍                                     | 18182/69006 [00:00<00:00, 180237.94it/s]\u001b[A\n",
      "Reading ray-tracing:  53%|███████████████████████████▏                       | 36724/69006 [00:00<00:00, 183052.02it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 184629.69it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                     | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 3905.88it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 250.11it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 5/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                   | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  24%|████████████▎                                      | 16634/69006 [00:00<00:00, 165826.19it/s]\u001b[A\n",
      "Reading ray-tracing:  52%|██████████████████████████▌                        | 35919/69006 [00:00<00:00, 181592.77it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 185084.95it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                     | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 4012.56it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 999.83it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 249.96it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:25<00:00,  8.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenes 10–14 generation time: 8.69s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## dataset 구축 (chunked on‑the‑fly generation)\n",
    "import time, gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 0~999 씬 인덱스, 한 번에 50개씩 처리\n",
    "scene_indices = np.arange(scene)\n",
    "chunk_size   = 5\n",
    "all_data     = []\n",
    "\n",
    "# 씬 묶음(chunk)마다 generate_data 호출\n",
    "for i in tqdm(range(0, len(scene_indices), chunk_size)):\n",
    "    chunk = scene_indices[i : i+chunk_size].tolist()\n",
    "    parameters['dynamic_scenario_scenes'] = chunk\n",
    "\n",
    "    start = time.time()\n",
    "    data_chunk = DeepMIMOv3.generate_data(parameters)\n",
    "    print(f\"Scenes {chunk[0]}–{chunk[-1]} generation time: {time.time() - start:.2f}s\")\n",
    "\n",
    "    # 바로 all_data에 합치거나, 디스크에 저장해도 OK\n",
    "    all_data.extend(data_chunk)\n",
    "\n",
    "    # 메모리 해제\n",
    "    del data_chunk\n",
    "    gc.collect()\n",
    "\n",
    "# 마지막에 하나의 리스트로 합친 데이터셋\n",
    "dataset = all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b6f3c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98 99]\n"
     ]
    }
   ],
   "source": [
    "print(parameters['user_rows'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ee486e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_folder': 'C:\\\\Users\\\\dlghd\\\\졸업프로젝트\\\\LWM', 'scenario': 'O2_dyn_3p5', 'dynamic_scenario_scenes': [10, 11, 12, 13, 14], 'num_paths': 10, 'active_BS': array([1]), 'user_rows': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
      "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
      "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]), 'user_subsampling': 0.01, 'bs_antenna': {'shape': array([ 1, 32]), 'spacing': 0.5, 'rotation': array([0, 0, 0]), 'FoV': array([360, 180]), 'radiation_pattern': 'isotropic'}, 'ue_antenna': {'shape': array([1, 1]), 'spacing': 0.5, 'rotation': array([0, 0, 0]), 'FoV': array([360, 180]), 'radiation_pattern': 'isotropic'}, 'enable_doppler': 0, 'enable_dual_polar': 0, 'enable_BS2BS': 1, 'OFDM_channels': 1, 'OFDM': {'subcarriers': 512, 'selected_subcarriers': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]), 'bandwidth': 0.05, 'RX_filter': 0}, 'activate_OFDM': 1}\n"
     ]
    }
   ],
   "source": [
    "print(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4e72d4",
   "metadata": {},
   "source": [
    "# 사용자 접근 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57828d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['paths', 'LoS', 'location', 'distance', 'pathloss', 'channel'])\n"
     ]
    }
   ],
   "source": [
    "user_data = dataset[0][0]['user']\n",
    "print(user_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5a3b0c",
   "metadata": {},
   "source": [
    "# 사용자 채널 정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23b2884b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(727, 1, 32, 64)\n"
     ]
    }
   ],
   "source": [
    "# subcarries = 나눈 각각의 주파수 채널\n",
    "# Channel = H <- 채널 벡터\n",
    "# 채널 형태\n",
    "# (user, UE antenna, Bs antenna, subcarrier)\n",
    "channel = dataset[0][0]['user']['channel']\n",
    "print(channel.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf443dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 8.57045598e-06+5.5781261e-06j  8.89099283e-06+5.0515800e-06j\n",
      "    9.17921989e-06+4.5066768e-06j ... -1.02173499e-05-4.1711201e-07j\n",
      "   -1.02239183e-05+1.9928974e-07j -1.01933329e-05+8.1496728e-07j]\n",
      "  [ 1.02161603e-05+4.4529790e-07j  1.02244285e-05-1.7108337e-07j\n",
      "    1.01955429e-05-7.8684292e-07j ... -9.00999748e-06+4.8361312e-06j\n",
      "   -8.70222630e-06+5.3702393e-06j -8.36283198e-06+5.8848323e-06j]\n",
      "  [ 9.02330430e-06-4.8112561e-06j  8.71700831e-06-5.3462113e-06j\n",
      "    8.37903553e-06-5.8617388e-06j ... -5.29921817e-06+8.7456565e-06j\n",
      "   -4.76262221e-06+9.0490685e-06j -4.20871947e-06+9.3195977e-06j]\n",
      "  ...\n",
      "  [-7.00710962e-06-7.4477266e-06j -7.44313866e-06-7.0119827e-06j\n",
      "   -7.85211978e-06-6.5507575e-06j ...  9.82847632e-06+2.8229874e-06j\n",
      "    9.98071755e-06+2.2256456e-06j  1.00966881e-05+1.6202162e-06j]\n",
      "  [-9.82065103e-06-2.8500913e-06j -9.97453935e-06-2.2531719e-06j\n",
      "   -1.00921798e-05-1.6480645e-06j ...  9.89848286e-06-2.5667589e-06j\n",
      "    9.72583803e-06-3.1585257e-06j  9.51785023e-06-3.7388147e-06j]\n",
      "  [-9.90552599e-06+2.5394413e-06j -9.73451461e-06+3.1316822e-06j\n",
      "   -9.52812843e-06+3.7125428e-06j ...  7.21819652e-06-7.2433313e-06j\n",
      "    6.76863647e-06-7.6651013e-06j  6.29447914e-06-8.0590162e-06j]]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][0]['user']['channel'][100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b079846",
   "metadata": {},
   "source": [
    "# 사용자 위치 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84337e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(727, 3)\n",
      "[[-71.03330231 -15.57629967   1.        ]\n",
      " [-68.63330078 -15.57629967   1.        ]\n",
      " [-52.83330154 -15.57629967   1.        ]\n",
      " [-31.23329926 -15.57629967   1.        ]]\n"
     ]
    }
   ],
   "source": [
    "location = dataset[0][0]['user']['location']\n",
    "print(location.shape)      # (사용자 수, 3)\n",
    "print(location[0:4])         # 첫 번째 사용자의 (x, y, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e9a9b6",
   "metadata": {},
   "source": [
    "# 경로정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79cde8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "727\n",
      "{'num_paths': 2, 'DoD_phi': array([-160.941, -160.941], dtype=float32), 'DoD_theta': array([93.6525, 94.7439], dtype=float32), 'DoA_phi': array([19.0585, 19.0585], dtype=float32), 'DoA_theta': array([86.3475, 94.7439], dtype=float32), 'phase': array([ 143.357, -137.611], dtype=float32), 'ToA': array([2.61886e-07, 2.62253e-07], dtype=float32), 'LoS': array([1., 0.], dtype=float32), 'power': array([7.5363324e-09, 3.2098095e-09], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "paths = dataset[0][0]['user']['paths']\n",
    "#사용자 수\n",
    "print(len(paths))\n",
    "# 첫 번째 사용자 경로 정보\n",
    "print(paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2242869",
   "metadata": {},
   "source": [
    "# 기지국 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2900e481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['paths', 'LoS', 'location', 'distance', 'pathloss', 'channel'])\n"
     ]
    }
   ],
   "source": [
    "bs_data = dataset[0][0]['basestation']\n",
    "print(bs_data.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c063ea95",
   "metadata": {},
   "source": [
    "# Scene 및 사용자 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a20df92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scene 0: 727 users\n"
     ]
    }
   ],
   "source": [
    "for i, scene in enumerate(dataset[0]):\n",
    "    user_locs = scene['user']['location']\n",
    "    print(f\"Scene {i}: {len(user_locs)} users\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38f71e1",
   "metadata": {},
   "source": [
    "# 채널 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbbee52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "727"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[0][0]['user']['channel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d474195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_paths': 2, 'DoD_phi': array([-160.941, -160.941], dtype=float32), 'DoD_theta': array([93.6525, 94.7439], dtype=float32), 'DoA_phi': array([19.0585, 19.0585], dtype=float32), 'DoA_theta': array([86.3475, 94.7439], dtype=float32), 'phase': array([ 143.357, -137.611], dtype=float32), 'ToA': array([2.61886e-07, 2.62253e-07], dtype=float32), 'LoS': array([1., 0.], dtype=float32), 'power': array([7.5363324e-09, 3.2098095e-09], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][0]['user']['paths'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73df9912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 64)\n"
     ]
    }
   ],
   "source": [
    "scene = dataset[0][0] # scene 0\n",
    "ue_idx = 0 # 첫 번째 사용자\n",
    "channel = scene['user']['channel'][ue_idx]\n",
    "print(channel.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373ffb59",
   "metadata": {},
   "source": [
    "# channel CIR mat 정보 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec4461cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'CIR_array_full'])\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "\n",
    "file_path = r'C:\\Users\\dlghd\\졸업프로젝트\\LWM\\O2_dyn_3p5\\scene_0\\O2_dyn_3p5.1.CIR.mat'\n",
    "mat_data = sio.loadmat(file_path)\n",
    "\n",
    "# 파일 안의 key 확인\n",
    "print(mat_data.keys())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "662cb441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'MATLAB 5.0 MAT-file, Platform: PCWIN64, Created on: Wed Jun 30 11:33:01 2021'\n"
     ]
    }
   ],
   "source": [
    "# 일반적으로 CIR key는 'CIR' 또는 'cir' 같은 이름일 가능성 높음\n",
    "H_cir = mat_data['__header__']  \n",
    "print(H_cir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f3d7c7",
   "metadata": {},
   "source": [
    "# Time-Prediction 시작\n",
    "## Time Series 형태로 변환\n",
    "### 단일사용자 채널 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f36971f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0이 존재하는 채널 개수 0\n"
     ]
    }
   ],
   "source": [
    "# print(dataset[0][0]['user']['channel'][150][0][3])\n",
    "\n",
    "count = 0\n",
    "for h in dataset[0][0]['user']['channel'][100][0]:\n",
    "#     h = h.squeeze(0)\n",
    "    h_real = h.real\n",
    "    h_imag = h.imag\n",
    "    if np.sum(np.abs(h_real)) ==0:\n",
    "        count+=1\n",
    "    elif np.sum(np.abs(h_imag)) == 0:\n",
    "        count+=1\n",
    "\n",
    "print(\"0이 존재하는 채널 개수\",count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7575de2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antenna #3 subcarriers: [ 5.3233252e-06-8.73100362e-06j  4.7875683e-06-9.03589535e-06j\n",
      "  4.2344141e-06-9.30795068e-06j  3.6658719e-06-9.54618190e-06j\n",
      "  3.0840083e-06-9.74972318e-06j  2.4909377e-06-9.91783418e-06j\n",
      "  1.8888149e-06-1.00499046e-05j  1.2798286e-06-1.01454543e-05j\n",
      "  6.6619128e-07-1.02041367e-05j  5.0133124e-08-1.02257372e-05j\n",
      " -5.6610725e-07-1.02101776e-05j -1.1802904e-06-1.01575160e-05j\n",
      " -1.7901845e-06-1.00679417e-05j -2.3935731e-06-9.94178117e-06j\n",
      " -2.9882635e-06-9.77949367e-06j -3.5720950e-06-9.58166765e-06j\n",
      " -4.1429457e-06-9.34902255e-06j -4.6987411e-06-9.08240327e-06j\n",
      " -5.2374617e-06-8.78277933e-06j -5.7571492e-06-8.45123941e-06j\n",
      " -6.2559161e-06-8.08898767e-06j -6.7319493e-06-7.69734197e-06j\n",
      " -7.1835188e-06-7.27772431e-06j -7.6089841e-06-6.83165945e-06j\n",
      " -8.0067985e-06-6.36076902e-06j -8.3755176e-06-5.86676424e-06j\n",
      " -8.7137996e-06-5.35144000e-06j -9.0204167e-06-4.81666848e-06j\n",
      " -9.2942537e-06-4.26439374e-06j -9.5343166e-06-3.69662257e-06j\n",
      " -9.7397324e-06-3.11541817e-06j -9.9097542e-06-2.52289237e-06j\n",
      " -1.0043765e-05-1.92119842e-06j -1.0141277e-05-1.31252318e-06j\n",
      " -1.0201937e-05-6.99078271e-07j -1.0225523e-05-8.30929494e-08j\n",
      " -1.0211949e-05+5.33194338e-07j -1.0161268e-05+1.14754403e-06j\n",
      " -1.0073660e-05+1.75772368e-06j -9.9494455e-06+2.36151573e-06j\n",
      " -9.7890743e-06+2.95672635e-06j -9.5931318e-06+3.54119220e-06j\n",
      " -9.3623275e-06+4.11278961e-06j -9.0975009e-06+4.66944175e-06j\n",
      " -8.7996150e-06+5.20912499e-06j -8.4697522e-06+5.72987892e-06j\n",
      " -8.1091102e-06+6.22981088e-06j -7.7190007e-06+6.70710369e-06j\n",
      " -7.3008405e-06+7.16002387e-06j -6.8561499e-06+7.58692431e-06j\n",
      " -6.3865441e-06+7.98625479e-06j -5.8937303e-06+8.35656374e-06j\n",
      " -5.3794988e-06+8.69650557e-06j -4.8457186e-06+9.00484429e-06j\n",
      " -4.2943293e-06+9.28046029e-06j -3.7273348e-06+9.52235223e-06j\n",
      " -3.1467955e-06+9.72963971e-06j -2.5548209e-06+9.90157059e-06j\n",
      " -1.9535621e-06+1.00375200e-05j -1.3452043e-06+1.01369933e-05j\n",
      " -7.3195804e-07+1.01996302e-05j -1.1605191e-07+1.02252015e-05j\n",
      "  5.0027592e-07+1.02136155e-05j  1.1147858e-06+1.01649139e-05j]\n",
      "0+0j인 서브캐리어 개수: 0\n",
      "완전 0+0j 안테나 포트 개수: 0\n",
      "0이 아닌 서브캐리어 개수: 2048\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1) (user, ue_port, bs_ant, subc) → (bs_ant, subc) 로 squeeze\n",
    "H = dataset[0][0]['user']['channel'][100, 0]   # shape: (32, 64), complex\n",
    "\n",
    "# 2) BS 안테나 인덱스 3의 서브캐리어 벡터 (64,)\n",
    "print(\"Antenna #3 subcarriers:\", H[3])\n",
    "\n",
    "# 3) 전체 서브캐리어(32×64) 중 값이 정확히 0인 요소 개수\n",
    "zero_elements = np.sum(H == 0)\n",
    "print(\"0+0j인 서브캐리어 개수:\", zero_elements)\n",
    "\n",
    "# 4) 서브캐리어 전부가 0인 안테나 포트(행) 개수\n",
    "zero_ports = np.sum(np.all(H == 0, axis=1))\n",
    "print(\"완전 0+0j 안테나 포트 개수:\", zero_ports)\n",
    "\n",
    "# 5) 만약 “값이 하나도 0이 아닌” 서브캐리어 요소 개수를 보고 싶다면\n",
    "nonzero_elements = np.sum(np.abs(H) > 0)\n",
    "print(\"0이 아닌 서브캐리어 개수:\", nonzero_elements)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20a73af",
   "metadata": {},
   "source": [
    "## 결측치 제거 및 dataload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94309077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────\n",
    "# ❶ IterableDataset: 모든 유저·서브캐리어를 스트리밍\n",
    "import torch\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class ChannelSeqDataset(IterableDataset):\n",
    "    \"\"\"\n",
    "    • seq_len 개의 과거 채널 벡터(real 64 + imag 64 → 128) → 다음 시점 벡터 예측\n",
    "    • 벡터는 평균전력 1 로 power‑normalize 후 반환\n",
    "    \"\"\"\n",
    "    def __init__(self, scenes, seq_len: int = 5, eps: float = 1e-9):\n",
    "        super().__init__()\n",
    "        self.scenes   = scenes\n",
    "        self.seq_len  = seq_len\n",
    "        self.eps      = eps                        # 0 division 방지용 신호세기의 크기 \n",
    "        ch0           = scenes[0][0]['user']['channel']\n",
    "        self.U        = ch0.shape[0]               # 사용자 수\n",
    "        self.A        = ch0.shape[2]               # 안테나 32\n",
    "        self.S        = ch0.shape[3]               # 서브캐리어 64\n",
    "        self.vec_len  = 2 * self.A                 # 64 real + imag\n",
    "        0\n",
    "    def _vec(self, scene, u: int, sc: int) -> torch.Tensor:\n",
    "        \"\"\"(32,) complex → (64,) float32  +  power norm\"\"\"\n",
    "        h = scene[0]['user']['channel'][u, 0, :, sc]          # (32,)\n",
    "        v = np.concatenate([h.real, h.imag]).astype(np.float32)\n",
    "        p = np.mean(v * v) + self.eps                         # 평균 전력: 채널 벡터 h의 각 성분의 진폭 제곱을 합산\n",
    "        v /= np.sqrt(p)                                       # 정규화\n",
    "        return torch.from_numpy(v)                            # (64,)\n",
    "\n",
    "    def __iter__(self):\n",
    "        T = len(self.scenes)\n",
    "        for t in range(self.seq_len, T):                      # 타깃 시점\n",
    "            past_scenes = self.scenes[t - self.seq_len : t]\n",
    "            tgt_scene   = self.scenes[t]\n",
    "            for u in range(self.U):\n",
    "                for s in range(self.S):\n",
    "                    seq = torch.stack([self._vec(ps, u, s) for ps in past_scenes])\n",
    "                    if not torch.any(seq):                    # 전부 0 이면 skip\n",
    "                        continue\n",
    "                    target     = self._vec(tgt_scene, u, s)\n",
    "                    if not torch.any(target): # target이 0이면 스킵\n",
    "                        continue\n",
    "                    masked_pos = torch.tensor([self.seq_len - 2], dtype=torch.long)\n",
    "                    yield seq, masked_pos, target             # shapes: (5,64) / (1,) / (64,)\n",
    "    \n",
    "    def __len__(self):\n",
    "         return (len(self.scenes) - self.seq_len) * self.U * self.S\n",
    "# ─────────────────────────────────────────────\n",
    "# ❷ 학습·검증 DataLoader train : val = 6 : 4\n",
    "seq_len      = 5\n",
    "split_ratio  = 0.6\n",
    "split_idx    = int(len(dataset) * split_ratio)\n",
    "\n",
    "train_ds = ChannelSeqDataset(dataset[:split_idx], seq_len=seq_len)\n",
    "val_ds   = ChannelSeqDataset(dataset[split_idx:], seq_len=seq_len)\n",
    "\n",
    "# train_ds 순회하면서 feature/target min, max 계산\n",
    "\n",
    "\n",
    "batch_size   = 32\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False)\n",
    "# ─────────────────────────────────────────────\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21a23b60-4cf1-45de-9a26-ae1f1c1dfba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing   import MinMaxScaler\n",
    "from torch.utils.data        import TensorDataset, DataLoader\n",
    "\n",
    "# ❶ 모든 seq/mask/target을 한 번에 뽑아서 NumPy로\n",
    "X_list, mposes_list, y_list = [], [], []\n",
    "for seq, mpos, tgt in ChannelSeqDataset(dataset, seq_len=seq_len):\n",
    "    X_list.append( seq.numpy() )           # (seq_len, vec_len)\n",
    "    mposes_list.append( mpos.item() )      # 스칼라 마스크 인덱스\n",
    "    y_list.append( tgt.numpy() )           # (vec_len,)\n",
    "\n",
    "X       = np.stack(X_list,      axis=0)    # (N, seq_len, vec_len)\n",
    "mposes  = np.array(mposes_list).reshape(-1,1)  # (N, 1)\n",
    "y       = np.stack(y_list,      axis=0)    # (N, vec_len)\n",
    "\n",
    "# ❷ Train/Val split  (6:4)\n",
    "split_idx = int(len(X) * split_ratio)\n",
    "X_tr,  X_va  = X[:split_idx],  X[split_idx:]\n",
    "mp_tr, mp_va = mposes[:split_idx], mposes[split_idx:]\n",
    "y_tr,  y_va  = y[:split_idx],  y[split_idx:]\n",
    "\n",
    "# ❸ 스케일링 (X, y 만)\n",
    "scaler_x = MinMaxScaler(); scaler_y = MinMaxScaler()\n",
    "Ntr, L, D = X_tr.shape\n",
    "\n",
    "# train 에서만 fit\n",
    "scaler_x .fit( X_tr.reshape(-1, D) )\n",
    "scaler_y .fit( y_tr )\n",
    "\n",
    "# transform 후 원래 shape 복원\n",
    "X_tr_s = scaler_x.transform(X_tr.reshape(-1, D)).reshape(Ntr, L, D)\n",
    "X_va_s = scaler_x.transform(X_va.reshape(-1, D)).reshape(X_va.shape)\n",
    "y_tr_s = scaler_y.transform(y_tr)\n",
    "y_va_s = scaler_y.transform(y_va)\n",
    "\n",
    "# ❹ TensorDataset 에 세 개 모두 담기\n",
    "train_ds = TensorDataset(\n",
    "    torch.from_numpy(X_tr_s).float(),     # seqs\n",
    "    torch.from_numpy(mp_tr).long(),       # mposes\n",
    "    torch.from_numpy(y_tr_s).float()      # tgts\n",
    ")\n",
    "val_ds   = TensorDataset(\n",
    "    torch.from_numpy(X_va_s).float(),\n",
    "    torch.from_numpy(mp_va).long(),\n",
    "    torch.from_numpy(y_va_s).float()\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 이제 배치 언패킹이 딱 맞습니다!\n",
    "first_batch = next(iter(train_loader))\n",
    "seqs, mposes, tgts = first_batch   # (B, L, D), (B,1), (B, D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0aaadd66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200563"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds) #4x727x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90f5b39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133709"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_ds) #1x727x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe8a8a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x000002326ED8EC30>\n",
      "batch_size: 32\n",
      "dataset: <torch.utils.data.dataset.TensorDataset object at 0x000002325E282300>\n",
      "total samples: 200563\n",
      "total batches: 6268\n",
      "seqs.shape: torch.Size([32, 5, 64])\n",
      "mposes.shape: torch.Size([32, 1])\n",
      "tgts.shape: torch.Size([32, 64])\n"
     ]
    }
   ],
   "source": [
    "# 1) DataLoader 설정 확인\n",
    "print(train_loader)                # DataLoader 정보 전체\n",
    "print(\"batch_size:\", train_loader.batch_size)\n",
    "print(\"dataset:\",   train_loader.dataset)\n",
    "\n",
    "# 총 샘플 수\n",
    "print(\"total samples:\", len(train_loader.dataset))\n",
    "# → (len(scenes) - seq_len) * U * S 와 동일한 값\n",
    "\n",
    "# 총 배치 수\n",
    "print(\"total batches:\", len(train_loader))\n",
    "# → ceil(total_samples / batch_size)\n",
    "\n",
    "\n",
    "# 3) 첫 번째 배치 내용 확인\n",
    "first_batch = next(iter(train_loader))\n",
    "seqs, mposes, tgts = first_batch\n",
    "print(\"seqs.shape:\",   seqs.shape)    # (B, seq_len, vec_len)\n",
    "print(\"mposes.shape:\", mposes.shape)  # (B, 1)\n",
    "print(\"tgts.shape:\",   tgts.shape)    # (B, vec_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87a41f65-8d0b-4a20-a8e2-e5e692bf2959",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.TensorDataset object at 0x000002325E282300>\n",
      "전체 샘플 수 (len): 6268\n",
      "\n",
      "샘플 #0\n",
      "  seq shape : torch.Size([32, 5, 64])\n",
      "  masked_pos : tensor([[3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3]])\n",
      "  target shape: torch.Size([32, 64])\n",
      "  seq example:\n",
      " tensor([[[0.5009, 0.5127, 0.5130,  ..., 0.5131, 0.5078, 0.4909],\n",
      "         [0.4765, 0.4900, 0.4917,  ..., 0.5351, 0.5279, 0.5102],\n",
      "         [0.5278, 0.5381, 0.5371,  ..., 0.4888, 0.4852, 0.4689],\n",
      "         [0.4557, 0.4685, 0.4695,  ..., 0.5567, 0.5496, 0.5328],\n",
      "         [0.4572, 0.4681, 0.4673,  ..., 0.5565, 0.5508, 0.5355]],\n",
      "\n",
      "        [[0.4868, 0.4997, 0.5014,  ..., 0.5759, 0.5703, 0.5546],\n",
      "         [0.4868, 0.4997, 0.5014,  ..., 0.5759, 0.5703, 0.5546],\n",
      "         [0.4868, 0.4997, 0.5014,  ..., 0.5759, 0.5703, 0.5546],\n",
      "         [0.4580, 0.4706, 0.4722,  ..., 0.4791, 0.4786, 0.4667],\n",
      "         [0.4580, 0.4706, 0.4722,  ..., 0.4791, 0.4786, 0.4667]],\n",
      "\n",
      "        [[0.3430, 0.3535, 0.3654,  ..., 0.7452, 0.7089, 0.6566],\n",
      "         [0.3430, 0.3535, 0.3654,  ..., 0.7452, 0.7089, 0.6566],\n",
      "         [0.3430, 0.3535, 0.3654,  ..., 0.7452, 0.7089, 0.6566],\n",
      "         [0.3430, 0.3535, 0.3654,  ..., 0.7452, 0.7089, 0.6566],\n",
      "         [0.3430, 0.3535, 0.3654,  ..., 0.7452, 0.7089, 0.6566]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.3373, 0.2503, 0.2486,  ..., 0.4951, 0.3099, 0.1878],\n",
      "         [0.3373, 0.2503, 0.2486,  ..., 0.4951, 0.3099, 0.1878],\n",
      "         [0.3373, 0.2503, 0.2486,  ..., 0.4951, 0.3099, 0.1878],\n",
      "         [0.3373, 0.2503, 0.2486,  ..., 0.4951, 0.3099, 0.1878],\n",
      "         [0.3373, 0.2503, 0.2486,  ..., 0.4951, 0.3099, 0.1878]],\n",
      "\n",
      "        [[0.9044, 0.7487, 0.5464,  ..., 0.9786, 0.8140, 0.5783],\n",
      "         [0.8427, 0.8247, 0.7169,  ..., 0.8531, 0.8103, 0.6918],\n",
      "         [0.9579, 0.8984, 0.7393,  ..., 0.9575, 0.8393, 0.6443],\n",
      "         [0.5514, 0.4751, 0.3875,  ..., 0.7450, 0.6924, 0.5744],\n",
      "         [0.6160, 0.5938, 0.5390,  ..., 0.9727, 0.8723, 0.6834]],\n",
      "\n",
      "        [[0.3718, 0.4396, 0.4996,  ..., 0.5076, 0.4514, 0.3900],\n",
      "         [0.3718, 0.4396, 0.4996,  ..., 0.5076, 0.4514, 0.3900],\n",
      "         [0.4057, 0.4625, 0.5113,  ..., 0.4643, 0.4055, 0.3419],\n",
      "         [0.4057, 0.4625, 0.5113,  ..., 0.4643, 0.4055, 0.3419],\n",
      "         [0.4057, 0.4625, 0.5113,  ..., 0.4643, 0.4055, 0.3419]]])\n",
      "  target example:\n",
      " tensor([[0.4954, 0.5088, 0.5159,  ..., 0.4887, 0.5145, 0.5122],\n",
      "        [0.4580, 0.4705, 0.4770,  ..., 0.4505, 0.4831, 0.4879],\n",
      "        [0.4437, 0.4793, 0.5100,  ..., 0.5784, 0.5891, 0.5713],\n",
      "        ...,\n",
      "        [0.3894, 0.2962, 0.2903,  ..., 0.4761, 0.3156, 0.2108],\n",
      "        [0.7595, 0.6523, 0.5126,  ..., 0.7992, 0.6975, 0.5210],\n",
      "        [0.4057, 0.4624, 0.5164,  ..., 0.4356, 0.4106, 0.3681]])\n",
      "\n",
      "샘플 #1\n",
      "  seq shape : torch.Size([32, 5, 64])\n",
      "  masked_pos : tensor([[3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3]])\n",
      "  target shape: torch.Size([32, 64])\n",
      "  seq example:\n",
      " tensor([[[0.4184, 0.4489, 0.4706,  ..., 0.5387, 0.5388, 0.5277],\n",
      "         [0.4184, 0.4489, 0.4706,  ..., 0.5387, 0.5388, 0.5277],\n",
      "         [0.4184, 0.4489, 0.4706,  ..., 0.5387, 0.5388, 0.5277],\n",
      "         [0.4184, 0.4489, 0.4706,  ..., 0.5387, 0.5388, 0.5277],\n",
      "         [0.4184, 0.4489, 0.4706,  ..., 0.5387, 0.5388, 0.5277]],\n",
      "\n",
      "        [[0.1478, 0.1525, 0.2449,  ..., 0.0772, 0.2183, 0.4117],\n",
      "         [0.2041, 0.4136, 0.6293,  ..., 0.3638, 0.3911, 0.4492],\n",
      "         [0.2254, 0.3247, 0.4493,  ..., 0.1615, 0.2844, 0.4488],\n",
      "         [0.1851, 0.3009, 0.4424,  ..., 0.2386, 0.3544, 0.5112],\n",
      "         [0.2677, 0.3917, 0.5361,  ..., 0.2084, 0.3038, 0.4416]],\n",
      "\n",
      "        [[0.5436, 0.5538, 0.5525,  ..., 0.4773, 0.4762, 0.4622],\n",
      "         [0.5329, 0.5444, 0.5444,  ..., 0.4892, 0.4868, 0.4719],\n",
      "         [0.5469, 0.5571, 0.5559,  ..., 0.4743, 0.4732, 0.4590],\n",
      "         [0.5322, 0.5427, 0.5417,  ..., 0.4869, 0.4855, 0.4716],\n",
      "         [0.4858, 0.4973, 0.4973,  ..., 0.5247, 0.5196, 0.5035]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.6118, 0.5642, 0.5084,  ..., 0.4123, 0.4056, 0.3913],\n",
      "         [0.6128, 0.5922, 0.5555,  ..., 0.3466, 0.3634, 0.3691],\n",
      "         [0.6619, 0.6342, 0.5909,  ..., 0.3872, 0.4069, 0.4168],\n",
      "         [0.6370, 0.6128, 0.5727,  ..., 0.3678, 0.3860, 0.3937],\n",
      "         [0.6370, 0.6128, 0.5727,  ..., 0.3678, 0.3860, 0.3937]],\n",
      "\n",
      "        [[0.5009, 0.5127, 0.5130,  ..., 0.5131, 0.5078, 0.4909],\n",
      "         [0.5009, 0.5127, 0.5130,  ..., 0.5131, 0.5078, 0.4909],\n",
      "         [0.5033, 0.5163, 0.5176,  ..., 0.5075, 0.5013, 0.4834],\n",
      "         [0.5033, 0.5163, 0.5176,  ..., 0.5075, 0.5013, 0.4834],\n",
      "         [0.5009, 0.5127, 0.5130,  ..., 0.5131, 0.5078, 0.4909]],\n",
      "\n",
      "        [[0.5009, 0.5127, 0.5130,  ..., 0.5131, 0.5078, 0.4909],\n",
      "         [0.5009, 0.5127, 0.5130,  ..., 0.5131, 0.5078, 0.4909],\n",
      "         [0.5009, 0.5127, 0.5130,  ..., 0.5131, 0.5078, 0.4909],\n",
      "         [0.5009, 0.5127, 0.5130,  ..., 0.5131, 0.5078, 0.4909],\n",
      "         [0.5206, 0.5323, 0.5326,  ..., 0.4961, 0.4910, 0.4735]]])\n",
      "  target example:\n",
      " tensor([[0.4889, 0.5208, 0.5492,  ..., 0.4905, 0.5296, 0.5390],\n",
      "        [0.2751, 0.3691, 0.4916,  ..., 0.1269, 0.2884, 0.4706],\n",
      "        [0.4693, 0.4794, 0.4831,  ..., 0.5169, 0.5429, 0.5415],\n",
      "        ...,\n",
      "        [0.5805, 0.5586, 0.5266,  ..., 0.3342, 0.3819, 0.4035],\n",
      "        [0.4743, 0.4868, 0.4928,  ..., 0.5093, 0.5350, 0.5332],\n",
      "        [0.5240, 0.5349, 0.5401,  ..., 0.4634, 0.4920, 0.4917]])\n",
      "\n",
      "샘플 #2\n",
      "  seq shape : torch.Size([32, 5, 64])\n",
      "  masked_pos : tensor([[3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3]])\n",
      "  target shape: torch.Size([32, 64])\n",
      "  seq example:\n",
      " tensor([[[0.5178, 0.5277, 0.5262,  ..., 0.5020, 0.4986, 0.4831],\n",
      "         [0.4797, 0.4913, 0.4912,  ..., 0.5353, 0.5296, 0.5133],\n",
      "         [0.4844, 0.4980, 0.4999,  ..., 0.5247, 0.5175, 0.4993],\n",
      "         [0.5228, 0.5347, 0.5351,  ..., 0.4910, 0.4861, 0.4687],\n",
      "         [0.5264, 0.5377, 0.5376,  ..., 0.4889, 0.4845, 0.4675]],\n",
      "\n",
      "        [[0.3205, 0.2950, 0.3021,  ..., 0.2375, 0.2830, 0.3477],\n",
      "         [0.3970, 0.4112, 0.4461,  ..., 0.2857, 0.3795, 0.4844],\n",
      "         [0.2827, 0.2889, 0.3271,  ..., 0.2209, 0.3229, 0.4461],\n",
      "         [0.1982, 0.1984, 0.2345,  ..., 0.2360, 0.3121, 0.4118],\n",
      "         [0.2373, 0.2411, 0.2796,  ..., 0.2021, 0.2783, 0.3760]],\n",
      "\n",
      "        [[0.4711, 0.4788, 0.4756,  ..., 0.5130, 0.5043, 0.4844],\n",
      "         [0.4711, 0.4788, 0.4756,  ..., 0.5130, 0.5043, 0.4844],\n",
      "         [0.4352, 0.4364, 0.4278,  ..., 0.5260, 0.5132, 0.4902],\n",
      "         [0.4792, 0.4806, 0.4721,  ..., 0.5000, 0.4921, 0.4730],\n",
      "         [0.4501, 0.4588, 0.4571,  ..., 0.4493, 0.4402, 0.4181]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.4831, 0.4971, 0.4993,  ..., 0.5241, 0.5167, 0.4982],\n",
      "         [0.5237, 0.5334, 0.5317,  ..., 0.4969, 0.4938, 0.4784],\n",
      "         [0.5198, 0.5324, 0.5335,  ..., 0.4913, 0.4859, 0.4680],\n",
      "         [0.4876, 0.4982, 0.4972,  ..., 0.5307, 0.5259, 0.5103],\n",
      "         [0.5082, 0.5215, 0.5233,  ..., 0.5006, 0.4943, 0.4760]],\n",
      "\n",
      "        [[0.4751, 0.5865, 0.6521,  ..., 0.7432, 0.7937, 0.7979],\n",
      "         [0.5285, 0.6248, 0.6770,  ..., 0.7504, 0.8048, 0.8142],\n",
      "         [0.4402, 0.5395, 0.6150,  ..., 0.7641, 0.7769, 0.7451],\n",
      "         [0.4075, 0.4963, 0.5634,  ..., 0.7894, 0.8027, 0.7729],\n",
      "         [0.5107, 0.5953, 0.6573,  ..., 0.7795, 0.7929, 0.7628]],\n",
      "\n",
      "        [[0.4589, 0.4735, 0.4772,  ..., 0.5999, 0.5990, 0.5882],\n",
      "         [0.4143, 0.4308, 0.4362,  ..., 0.6197, 0.6094, 0.5896],\n",
      "         [0.6673, 0.6784, 0.6754,  ..., 0.5155, 0.5088, 0.4899],\n",
      "         [0.6514, 0.6670, 0.6683,  ..., 0.4648, 0.4606, 0.4426],\n",
      "         [0.5605, 0.5658, 0.5578,  ..., 0.5832, 0.5676, 0.5427]]])\n",
      "  target example:\n",
      " tensor([[0.5068, 0.5167, 0.5208,  ..., 0.4827, 0.5115, 0.5120],\n",
      "        [0.3448, 0.3153, 0.3140,  ..., 0.2305, 0.3534, 0.4599],\n",
      "        [0.4125, 0.4211, 0.4238,  ..., 0.4434, 0.4636, 0.4561],\n",
      "        ...,\n",
      "        [0.5001, 0.5099, 0.5137,  ..., 0.4917, 0.5203, 0.5207],\n",
      "        [0.5708, 0.6807, 0.7500,  ..., 0.6814, 0.7549, 0.7606],\n",
      "        [0.4364, 0.4533, 0.4618,  ..., 0.5541, 0.5682, 0.5562]])\n",
      "\n",
      "샘플 #3\n",
      "  seq shape : torch.Size([32, 5, 64])\n",
      "  masked_pos : tensor([[3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3]])\n",
      "  target shape: torch.Size([32, 64])\n",
      "  seq example:\n",
      " tensor([[[0.5976, 0.5828, 0.5545,  ..., 0.4497, 0.4402, 0.4198],\n",
      "         [0.5976, 0.5828, 0.5545,  ..., 0.4497, 0.4402, 0.4198],\n",
      "         [0.5976, 0.5828, 0.5545,  ..., 0.4497, 0.4402, 0.4198],\n",
      "         [0.5976, 0.5828, 0.5545,  ..., 0.4497, 0.4402, 0.4198],\n",
      "         [0.5976, 0.5828, 0.5545,  ..., 0.4497, 0.4402, 0.4198]],\n",
      "\n",
      "        [[0.5078, 0.5176, 0.5159,  ..., 0.5150, 0.5112, 0.4959],\n",
      "         [0.5078, 0.5176, 0.5159,  ..., 0.5150, 0.5112, 0.4959],\n",
      "         [0.5078, 0.5176, 0.5159,  ..., 0.5150, 0.5112, 0.4959],\n",
      "         [0.5078, 0.5176, 0.5159,  ..., 0.5150, 0.5112, 0.4959],\n",
      "         [0.5078, 0.5176, 0.5159,  ..., 0.5150, 0.5112, 0.4959]],\n",
      "\n",
      "        [[0.3542, 0.3990, 0.4459,  ..., 0.6558, 0.6181, 0.5707],\n",
      "         [0.1935, 0.2356, 0.2797,  ..., 0.6040, 0.5447, 0.4763],\n",
      "         [0.2998, 0.3348, 0.3734,  ..., 0.6281, 0.5849, 0.5293],\n",
      "         [0.2879, 0.3121, 0.3396,  ..., 0.6537, 0.5941, 0.5239],\n",
      "         [0.2074, 0.2435, 0.2833,  ..., 0.6502, 0.5952, 0.5286]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5009, 0.5127, 0.5130,  ..., 0.5131, 0.5078, 0.4909],\n",
      "         [0.5009, 0.5127, 0.5130,  ..., 0.5131, 0.5078, 0.4909],\n",
      "         [0.5009, 0.5127, 0.5130,  ..., 0.5131, 0.5078, 0.4909],\n",
      "         [0.5009, 0.5127, 0.5130,  ..., 0.5131, 0.5078, 0.4909],\n",
      "         [0.5482, 0.5513, 0.5413,  ..., 0.5030, 0.4737, 0.4332]],\n",
      "\n",
      "        [[0.5511, 0.5531, 0.5443,  ..., 0.5344, 0.5279, 0.5104],\n",
      "         [0.4556, 0.4633, 0.4596,  ..., 0.5812, 0.5677, 0.5453],\n",
      "         [0.5869, 0.5876, 0.5774,  ..., 0.5297, 0.5256, 0.5102],\n",
      "         [0.4687, 0.4740, 0.4680,  ..., 0.5800, 0.5680, 0.5469],\n",
      "         [0.5259, 0.5269, 0.5171,  ..., 0.5873, 0.5778, 0.5595]],\n",
      "\n",
      "        [[0.7724, 0.7569, 0.7169,  ..., 0.4620, 0.4421, 0.4139],\n",
      "         [0.7971, 0.7761, 0.7334,  ..., 0.4364, 0.4195, 0.3904],\n",
      "         [0.8505, 0.8253, 0.7788,  ..., 0.4102, 0.3995, 0.3756],\n",
      "         [0.8477, 0.8226, 0.7761,  ..., 0.4138, 0.4044, 0.3821],\n",
      "         [0.7622, 0.7362, 0.6889,  ..., 0.4993, 0.4836, 0.4583]]])\n",
      "  target example:\n",
      " tensor([[0.5976, 0.5827, 0.5601,  ..., 0.4209, 0.4450, 0.4428],\n",
      "        [0.5078, 0.5174, 0.5212,  ..., 0.4865, 0.5153, 0.5159],\n",
      "        [0.4464, 0.4568, 0.4649,  ..., 0.6292, 0.5829, 0.5066],\n",
      "        ...,\n",
      "        [0.5482, 0.5511, 0.5468,  ..., 0.4745, 0.4782, 0.4557],\n",
      "        [0.5418, 0.5405, 0.5341,  ..., 0.5453, 0.5700, 0.5675],\n",
      "        [0.7183, 0.7007, 0.6682,  ..., 0.4415, 0.4542, 0.4413]])\n",
      "\n",
      "샘플 #4\n",
      "  seq shape : torch.Size([32, 5, 64])\n",
      "  masked_pos : tensor([[3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3]])\n",
      "  target shape: torch.Size([32, 64])\n",
      "  seq example:\n",
      " tensor([[[0.3380, 0.3600, 0.3745,  ..., 0.4617, 0.4838, 0.4919],\n",
      "         [0.4816, 0.4902, 0.4914,  ..., 0.5098, 0.5338, 0.5450],\n",
      "         [0.3370, 0.3296, 0.3178,  ..., 0.5180, 0.5490, 0.5662],\n",
      "         [0.4365, 0.4380, 0.4335,  ..., 0.4743, 0.5162, 0.5423],\n",
      "         [0.4108, 0.3955, 0.3760,  ..., 0.5538, 0.5858, 0.6048]],\n",
      "\n",
      "        [[0.6680, 0.6321, 0.5835,  ..., 0.3320, 0.3448, 0.3423],\n",
      "         [0.5879, 0.5368, 0.4750,  ..., 0.3784, 0.3815, 0.3717],\n",
      "         [0.5687, 0.5370, 0.4922,  ..., 0.3862, 0.3918, 0.3840],\n",
      "         [0.7071, 0.6586, 0.5978,  ..., 0.3862, 0.3911, 0.3824],\n",
      "         [0.5322, 0.4867, 0.4304,  ..., 0.3812, 0.3822, 0.3706]],\n",
      "\n",
      "        [[0.6458, 0.6567, 0.6453,  ..., 0.3861, 0.4061, 0.4174],\n",
      "         [0.6458, 0.6567, 0.6453,  ..., 0.3861, 0.4061, 0.4174],\n",
      "         [0.6302, 0.6535, 0.6546,  ..., 0.4127, 0.4447, 0.4677],\n",
      "         [0.5971, 0.6229, 0.6266,  ..., 0.3820, 0.4139, 0.4360],\n",
      "         [0.6050, 0.6250, 0.6232,  ..., 0.4098, 0.4368, 0.4548]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.4303, 0.4108, 0.3892,  ..., 0.6373, 0.6374, 0.6207],\n",
      "         [0.4303, 0.4108, 0.3892,  ..., 0.6373, 0.6374, 0.6207],\n",
      "         [0.4372, 0.4132, 0.3866,  ..., 0.5730, 0.5694, 0.5481],\n",
      "         [0.4284, 0.4006, 0.3707,  ..., 0.5827, 0.5747, 0.5493],\n",
      "         [0.4691, 0.4401, 0.4084,  ..., 0.6109, 0.6046, 0.5818]],\n",
      "\n",
      "        [[0.5105, 0.5240, 0.5258,  ..., 0.4910, 0.4855, 0.4677],\n",
      "         [0.5105, 0.5240, 0.5258,  ..., 0.4910, 0.4855, 0.4677],\n",
      "         [0.5094, 0.5208, 0.5206,  ..., 0.5022, 0.4981, 0.4819],\n",
      "         [0.5237, 0.5387, 0.5420,  ..., 0.4700, 0.4641, 0.4450],\n",
      "         [0.4822, 0.4979, 0.5017,  ..., 0.5099, 0.5020, 0.4825]],\n",
      "\n",
      "        [[0.5003, 0.5136, 0.5153,  ..., 0.5100, 0.5034, 0.4852],\n",
      "         [0.5274, 0.5383, 0.5377,  ..., 0.4890, 0.4850, 0.4684],\n",
      "         [0.5660, 0.5744, 0.5712,  ..., 0.5067, 0.5079, 0.4972],\n",
      "         [0.5416, 0.5526, 0.5517,  ..., 0.5256, 0.5243, 0.5118],\n",
      "         [0.5735, 0.5845, 0.5839,  ..., 0.4945, 0.4937, 0.4805]]])\n",
      "  target example:\n",
      " tensor([[0.3020, 0.3376, 0.3708,  ..., 0.4643, 0.5262, 0.5546],\n",
      "        [0.6180, 0.5865, 0.5474,  ..., 0.3274, 0.3715, 0.3862],\n",
      "        [0.6123, 0.6261, 0.6252,  ..., 0.4313, 0.4897, 0.5229],\n",
      "        ...,\n",
      "        [0.4782, 0.4430, 0.4100,  ..., 0.6332, 0.6558, 0.6447],\n",
      "        [0.4873, 0.5000, 0.5063,  ..., 0.4902, 0.5169, 0.5157],\n",
      "        [0.5604, 0.5708, 0.5758,  ..., 0.4361, 0.4691, 0.4726]])\n"
     ]
    }
   ],
   "source": [
    "# 1) train_ds 자체 정보 출력\n",
    "print(train_ds)\n",
    "print(\"전체 샘플 수 (len):\", len(train_loader))\n",
    "\n",
    "# 2) 앞에서 5개 예시 뽑아서 확인\n",
    "for idx, (seq, mpos, tgt) in enumerate(train_loader):\n",
    "    print(f\"\\n샘플 #{idx}\")\n",
    "    print(\"  seq shape :\", seq.shape)    # (seq_len, feat_dim)\n",
    "    print(\"  masked_pos :\", mpos)        # tensor([ ... ])\n",
    "    print(\"  target shape:\", tgt.shape)   # (feat_dim,)\n",
    "    print(\"  seq example:\\n\", seq)        # 실제 값 보기\n",
    "    print(\"  target example:\\n\", tgt)\n",
    "    if idx >= 4:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3348886",
   "metadata": {},
   "source": [
    "## 이론적 input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ccebf6ff-5f90-47c7-9f2d-64498d5de98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ 이론상 전체 가능 시퀀스: 465280\n",
      "▶ 이론상 Train 최대 샘플: 279168\n",
      "▶ 이론상 Val   최대 샘플: 186112\n"
     ]
    }
   ],
   "source": [
    "# (1) 장면(scene) 수, 시퀀스 길이\n",
    "T = len(dataset)\n",
    "L = 5          # 이제 int!\n",
    "\n",
    "# (2) 사용자 수(U), 서브캐리어 수(S)\n",
    "ch0 = dataset[0][0]['user']['channel']  # shape = (U,1,A,S)\n",
    "U   = ch0.shape[0]\n",
    "S   = ch0.shape[3]\n",
    "\n",
    "# (3) 이론상 최대 시퀀스 수\n",
    "total_possible = (T - L) * U * S\n",
    "\n",
    "# (4) train/val 분할 기준에서 이론상 최대 개수\n",
    "train_max = int(total_possible * split_ratio)\n",
    "val_max   = total_possible - train_max\n",
    "\n",
    "print(f\"▶ 이론상 전체 가능 시퀀스: {total_possible}\")\n",
    "print(f\"▶ 이론상 Train 최대 샘플: {train_max}\")\n",
    "print(f\"▶ 이론상 Val   최대 샘플: {val_max}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff85e07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ 실제 전체 샘플 수: 334272\n",
      "▶ 실제   Train 샘플 수: 200563   → 배치 수: 6268\n",
      "▶ 실제   Val   샘플 수: 133709   → 배치 수: 4179\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 전체 실제 샘플 수\n",
    "N_total   = X.shape[0]\n",
    "# 실제 train/val 샘플 수\n",
    "N_train   = X_tr.shape[0]\n",
    "N_val     = X_va.shape[0]\n",
    "\n",
    "# 실제 배치 수 (올림)\n",
    "bsize     = batch_size\n",
    "B_train   = int(np.ceil(N_train / bsize))\n",
    "B_val     = int(np.ceil(N_val   / bsize))\n",
    "\n",
    "print(f\"▶ 실제 전체 샘플 수: {N_total}\")\n",
    "print(f\"▶ 실제   Train 샘플 수: {N_train}   → 배치 수: {B_train}\")\n",
    "print(f\"▶ 실제   Val   샘플 수: {N_val}   → 배치 수: {B_val}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf6bac8",
   "metadata": {},
   "source": [
    "# 아래 코드 구조\n",
    "┌──────────────────────────────────────────────────────────────┐\n",
    "│ input_ids  (B, seq_len, element_length)  ─┐                 │\n",
    "│ masked_pos (B, num_mask)                  ├─>  LWM backbone │\n",
    "│                                           │    (12-층 트랜스포머)  \n",
    "└────────────────────────────────────────────┘         │\n",
    "            logits_lm  (B, num_mask, element_length)  │   enc_output (B, seq_len, d_model)\n",
    "                                                      ▼\n",
    "                        ┌─[풀링]───────────────┐      ←── feat (B, d_model)\n",
    "                        │ 첫 토큰(0번) 선택    │\n",
    "                        │   or 평균/최대 풀링 │\n",
    "                        └──────────────────────┘\n",
    "                                      ▼\n",
    "                       FC 헤드  (d_model → hidden_dim → out_dim)\n",
    "                                      ▼\n",
    "                                out (B, out_dim)\n",
    "\n",
    "# 시각적비유\n",
    "\n",
    "[패치 프로젝터]──▶[Transformer ×12]──▶[LayerNorm]──┐\n",
    "                                                  ├─▶ 64-차 벡터 (CLS 또는 풀링) ─▶ MLP ─▶ out                                                \n",
    "[Positional Embedding]─────────────────────────────┘\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d882a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LWMWithHead: 사전학습된 LWM(Transformer encoder)을 ‘백본(backbone)’으로 사용하고,\n",
    "             그 뒤에 새로운 완전연결(FC) 헤드(head)를 붙여 다운스트림 작업\n",
    "             (회귀·분류 등)에 사용할 수 있도록 만든 래퍼(wrapper) 클래스입니다.\n",
    "\n",
    "변경점:\n",
    "- input_dim: 실제 데이터 차원 (예: 64)\n",
    "- patch_length: backbone이 기대하는 패치 길이 (예: 16)\n",
    "- 기존 element_length 파라미터 대신 위 두 개로 명확히 분리\n",
    "- forward()에서 투영 레이어(self.input_proj) 적용\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from lwm_model import lwm   # 기존 LWM 모델 클래스\n",
    "\n",
    "class LWMWithHead(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim:      int,    # 실제 입력 벡터 차원, 예: 64 (real+imag 합친 길이)\n",
    "        patch_length:   int,    # backbone in_features, 예: 16 (사전학습된 패치 길이)\n",
    "        d_model:        int = 64,# backbone hidden size (사전학습된 d_model)\n",
    "        max_len:        int = 129,# 포지셔널 인코딩 최대 길이\n",
    "        n_layers:       int = 12,# transformer encoder 층 수\n",
    "        hidden_dim:     int = 256,# 헤드 FC 중간 차원\n",
    "        out_dim:        int = 64, # 최종 출력 차원\n",
    "        freeze_backbone: bool = True,  # 백본 동결 여부\n",
    "        ckpt_path:      str | None = \"./model_weights.pth\", \n",
    "        device:         str = \"cuda\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # ────────────────────────────────────\n",
    "        # ➊ 입력 투영 레이어\n",
    "        #   • 실제 데이터(input_dim) → patch_length 차원으로 줄여줌\n",
    "        #   • backbone이 기대하는 in_features 길이에 맞추기 위함\n",
    "        # ────────────────────────────────────\n",
    "        self.input_proj = nn.Linear(input_dim, patch_length)\n",
    "\n",
    "        # ────────────────────────────────────\n",
    "        # ➋ 백본(backbone) 초기화\n",
    "        # ────────────────────────────────────\n",
    "        if ckpt_path is None:\n",
    "            # 랜덤 초기화된 backbone\n",
    "            self.backbone = lwm(\n",
    "                element_length=patch_length,\n",
    "                d_model=d_model,\n",
    "                max_len=max_len,\n",
    "                n_layers=n_layers\n",
    "            ).to(device)\n",
    "        else:\n",
    "            # 사전학습 가중치 로드\n",
    "            self.backbone = lwm.from_pretrained(\n",
    "                ckpt_name=ckpt_path,\n",
    "                device=device\n",
    "            )\n",
    "        # 백본 동결(gradient off)\n",
    "        if freeze_backbone:\n",
    "            for p in self.backbone.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        # ────────────────────────────────────\n",
    "        # ➌ 다운스트림 FC 헤드 정의\n",
    "        #   • d_model → hidden_dim → out_dim\n",
    "        # ────────────────────────────────────\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(d_model, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, masked_pos):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_ids : Tensor  (B, seq_len, input_dim)\n",
    "            원본 채널 시퀀스, 예: (B, 5, 64)\n",
    "        masked_pos: Tensor  (B, num_mask)\n",
    "            backbone의 masked position 인덱스\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out : Tensor  (B, out_dim)\n",
    "            최종 FC 헤드를 거친 예측값\n",
    "        \"\"\"\n",
    "        # ────────────────────────────────────\n",
    "        # 1) 입력 투영: (B, L, 64) → (B, L, 16)\n",
    "        # ────────────────────────────────────\n",
    "        x = self.input_proj(input_ids)\n",
    "\n",
    "        # ────────────────────────────────────\n",
    "        # 2) backbone forward\n",
    "        #    • logits_lm (unused), enc_output: (B, L, d_model)\n",
    "        # ────────────────────────────────────\n",
    "        _, enc_output = self.backbone(x, masked_pos)\n",
    "\n",
    "        # ────────────────────────────────────\n",
    "        # 3) 특징 추출: CLS 토큰 벡터 (첫 번째 토큰)\n",
    "        #    • feat: (B, d_model)\n",
    "        # ────────────────────────────────────\n",
    "        feat = enc_output[:, 0, :]\n",
    "\n",
    "        # ────────────────────────────────────\n",
    "        # 4) FC 헤드 통과\n",
    "        #    • out: (B, out_dim)\n",
    "        # ────────────────────────────────────\n",
    "        out = self.head(feat)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3cec5b",
   "metadata": {},
   "source": [
    "## input_size\n",
    "-input_size = (scene - seq_len) * U * S -> (10-5)+69040*64 = 22092800  \n",
    "-batch_size = 32  \n",
    "-배치 수 = input_size / batch_size = 690400배치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d041ddd-88c1-412e-ab42-cd4326695f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200563, 5, 64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b37383cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from ./model_weights.pth to cuda\n"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────\n",
    "# 모델 초기화 (새로운 생성자 시그니처에 맞춰 수정)\n",
    "# ─────────────────────────────────────────────\n",
    "from torch.optim import Adam\n",
    "\n",
    "batch_size, seq_len, D = X_tr_s.shape  # D = 64\n",
    "hidden_dim = 256\n",
    "\n",
    "model = LWMWithHead(\n",
    "    input_dim     = D,      # 실제 채널 벡터 차원 (real+imag=64)\n",
    "    patch_length  = 16,     # pretrained 백본이 기대하는 패치 길이\n",
    "    d_model       = 64,     # pretrained 백본 hidden size\n",
    "    max_len       = seq_len,\n",
    "    n_layers      = 12,\n",
    "    hidden_dim    = hidden_dim,\n",
    "    out_dim       = D,      # downstream 예측 차원 (64)\n",
    "    freeze_backbone = True,\n",
    "    ckpt_path     = \"./model_weights.pth\",\n",
    "    device        = device\n",
    ").to(device)\n",
    "# ─────────────────────────────────────────────\n",
    "\n",
    "# 손실함수 & 옵티마이저는 그대로\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47b92345-e8e1-4683-a722-ff290e5d0644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone requires_grad flags:\n",
      "  decoder_bias                            : False\n",
      "  embedding.proj.weight                   : False\n",
      "  embedding.proj.bias                     : False\n",
      "  embedding.pos_embed.weight              : False\n",
      "  embedding.norm.alpha                    : False\n",
      "  embedding.norm.bias                     : False\n",
      "  layers.0.enc_self_attn.W_Q.weight       : False\n",
      "  layers.0.enc_self_attn.W_Q.bias         : False\n",
      "  layers.0.enc_self_attn.W_K.weight       : False\n",
      "  layers.0.enc_self_attn.W_K.bias         : False\n",
      "  layers.0.enc_self_attn.W_V.weight       : False\n",
      "  layers.0.enc_self_attn.W_V.bias         : False\n",
      "  layers.0.enc_self_attn.linear.weight    : False\n",
      "  layers.0.enc_self_attn.linear.bias      : False\n",
      "  layers.0.enc_self_attn.norm.alpha       : False\n",
      "  layers.0.enc_self_attn.norm.bias        : False\n",
      "  layers.0.pos_ffn.fc1.weight             : False\n",
      "  layers.0.pos_ffn.fc1.bias               : False\n",
      "  layers.0.pos_ffn.fc2.weight             : False\n",
      "  layers.0.pos_ffn.fc2.bias               : False\n",
      "  layers.0.pos_ffn.norm.alpha             : False\n",
      "  layers.0.pos_ffn.norm.bias              : False\n",
      "  layers.0.norm.alpha                     : False\n",
      "  layers.0.norm.bias                      : False\n",
      "  layers.1.enc_self_attn.W_Q.weight       : False\n",
      "  layers.1.enc_self_attn.W_Q.bias         : False\n",
      "  layers.1.enc_self_attn.W_K.weight       : False\n",
      "  layers.1.enc_self_attn.W_K.bias         : False\n",
      "  layers.1.enc_self_attn.W_V.weight       : False\n",
      "  layers.1.enc_self_attn.W_V.bias         : False\n",
      "  layers.1.enc_self_attn.linear.weight    : False\n",
      "  layers.1.enc_self_attn.linear.bias      : False\n",
      "  layers.1.enc_self_attn.norm.alpha       : False\n",
      "  layers.1.enc_self_attn.norm.bias        : False\n",
      "  layers.1.pos_ffn.fc1.weight             : False\n",
      "  layers.1.pos_ffn.fc1.bias               : False\n",
      "  layers.1.pos_ffn.fc2.weight             : False\n",
      "  layers.1.pos_ffn.fc2.bias               : False\n",
      "  layers.1.pos_ffn.norm.alpha             : False\n",
      "  layers.1.pos_ffn.norm.bias              : False\n",
      "  layers.1.norm.alpha                     : False\n",
      "  layers.1.norm.bias                      : False\n",
      "  layers.2.enc_self_attn.W_Q.weight       : False\n",
      "  layers.2.enc_self_attn.W_Q.bias         : False\n",
      "  layers.2.enc_self_attn.W_K.weight       : False\n",
      "  layers.2.enc_self_attn.W_K.bias         : False\n",
      "  layers.2.enc_self_attn.W_V.weight       : False\n",
      "  layers.2.enc_self_attn.W_V.bias         : False\n",
      "  layers.2.enc_self_attn.linear.weight    : False\n",
      "  layers.2.enc_self_attn.linear.bias      : False\n",
      "  layers.2.enc_self_attn.norm.alpha       : False\n",
      "  layers.2.enc_self_attn.norm.bias        : False\n",
      "  layers.2.pos_ffn.fc1.weight             : False\n",
      "  layers.2.pos_ffn.fc1.bias               : False\n",
      "  layers.2.pos_ffn.fc2.weight             : False\n",
      "  layers.2.pos_ffn.fc2.bias               : False\n",
      "  layers.2.pos_ffn.norm.alpha             : False\n",
      "  layers.2.pos_ffn.norm.bias              : False\n",
      "  layers.2.norm.alpha                     : False\n",
      "  layers.2.norm.bias                      : False\n",
      "  layers.3.enc_self_attn.W_Q.weight       : False\n",
      "  layers.3.enc_self_attn.W_Q.bias         : False\n",
      "  layers.3.enc_self_attn.W_K.weight       : False\n",
      "  layers.3.enc_self_attn.W_K.bias         : False\n",
      "  layers.3.enc_self_attn.W_V.weight       : False\n",
      "  layers.3.enc_self_attn.W_V.bias         : False\n",
      "  layers.3.enc_self_attn.linear.weight    : False\n",
      "  layers.3.enc_self_attn.linear.bias      : False\n",
      "  layers.3.enc_self_attn.norm.alpha       : False\n",
      "  layers.3.enc_self_attn.norm.bias        : False\n",
      "  layers.3.pos_ffn.fc1.weight             : False\n",
      "  layers.3.pos_ffn.fc1.bias               : False\n",
      "  layers.3.pos_ffn.fc2.weight             : False\n",
      "  layers.3.pos_ffn.fc2.bias               : False\n",
      "  layers.3.pos_ffn.norm.alpha             : False\n",
      "  layers.3.pos_ffn.norm.bias              : False\n",
      "  layers.3.norm.alpha                     : False\n",
      "  layers.3.norm.bias                      : False\n",
      "  layers.4.enc_self_attn.W_Q.weight       : False\n",
      "  layers.4.enc_self_attn.W_Q.bias         : False\n",
      "  layers.4.enc_self_attn.W_K.weight       : False\n",
      "  layers.4.enc_self_attn.W_K.bias         : False\n",
      "  layers.4.enc_self_attn.W_V.weight       : False\n",
      "  layers.4.enc_self_attn.W_V.bias         : False\n",
      "  layers.4.enc_self_attn.linear.weight    : False\n",
      "  layers.4.enc_self_attn.linear.bias      : False\n",
      "  layers.4.enc_self_attn.norm.alpha       : False\n",
      "  layers.4.enc_self_attn.norm.bias        : False\n",
      "  layers.4.pos_ffn.fc1.weight             : False\n",
      "  layers.4.pos_ffn.fc1.bias               : False\n",
      "  layers.4.pos_ffn.fc2.weight             : False\n",
      "  layers.4.pos_ffn.fc2.bias               : False\n",
      "  layers.4.pos_ffn.norm.alpha             : False\n",
      "  layers.4.pos_ffn.norm.bias              : False\n",
      "  layers.4.norm.alpha                     : False\n",
      "  layers.4.norm.bias                      : False\n",
      "  layers.5.enc_self_attn.W_Q.weight       : False\n",
      "  layers.5.enc_self_attn.W_Q.bias         : False\n",
      "  layers.5.enc_self_attn.W_K.weight       : False\n",
      "  layers.5.enc_self_attn.W_K.bias         : False\n",
      "  layers.5.enc_self_attn.W_V.weight       : False\n",
      "  layers.5.enc_self_attn.W_V.bias         : False\n",
      "  layers.5.enc_self_attn.linear.weight    : False\n",
      "  layers.5.enc_self_attn.linear.bias      : False\n",
      "  layers.5.enc_self_attn.norm.alpha       : False\n",
      "  layers.5.enc_self_attn.norm.bias        : False\n",
      "  layers.5.pos_ffn.fc1.weight             : False\n",
      "  layers.5.pos_ffn.fc1.bias               : False\n",
      "  layers.5.pos_ffn.fc2.weight             : False\n",
      "  layers.5.pos_ffn.fc2.bias               : False\n",
      "  layers.5.pos_ffn.norm.alpha             : False\n",
      "  layers.5.pos_ffn.norm.bias              : False\n",
      "  layers.5.norm.alpha                     : False\n",
      "  layers.5.norm.bias                      : False\n",
      "  layers.6.enc_self_attn.W_Q.weight       : False\n",
      "  layers.6.enc_self_attn.W_Q.bias         : False\n",
      "  layers.6.enc_self_attn.W_K.weight       : False\n",
      "  layers.6.enc_self_attn.W_K.bias         : False\n",
      "  layers.6.enc_self_attn.W_V.weight       : False\n",
      "  layers.6.enc_self_attn.W_V.bias         : False\n",
      "  layers.6.enc_self_attn.linear.weight    : False\n",
      "  layers.6.enc_self_attn.linear.bias      : False\n",
      "  layers.6.enc_self_attn.norm.alpha       : False\n",
      "  layers.6.enc_self_attn.norm.bias        : False\n",
      "  layers.6.pos_ffn.fc1.weight             : False\n",
      "  layers.6.pos_ffn.fc1.bias               : False\n",
      "  layers.6.pos_ffn.fc2.weight             : False\n",
      "  layers.6.pos_ffn.fc2.bias               : False\n",
      "  layers.6.pos_ffn.norm.alpha             : False\n",
      "  layers.6.pos_ffn.norm.bias              : False\n",
      "  layers.6.norm.alpha                     : False\n",
      "  layers.6.norm.bias                      : False\n",
      "  layers.7.enc_self_attn.W_Q.weight       : False\n",
      "  layers.7.enc_self_attn.W_Q.bias         : False\n",
      "  layers.7.enc_self_attn.W_K.weight       : False\n",
      "  layers.7.enc_self_attn.W_K.bias         : False\n",
      "  layers.7.enc_self_attn.W_V.weight       : False\n",
      "  layers.7.enc_self_attn.W_V.bias         : False\n",
      "  layers.7.enc_self_attn.linear.weight    : False\n",
      "  layers.7.enc_self_attn.linear.bias      : False\n",
      "  layers.7.enc_self_attn.norm.alpha       : False\n",
      "  layers.7.enc_self_attn.norm.bias        : False\n",
      "  layers.7.pos_ffn.fc1.weight             : False\n",
      "  layers.7.pos_ffn.fc1.bias               : False\n",
      "  layers.7.pos_ffn.fc2.weight             : False\n",
      "  layers.7.pos_ffn.fc2.bias               : False\n",
      "  layers.7.pos_ffn.norm.alpha             : False\n",
      "  layers.7.pos_ffn.norm.bias              : False\n",
      "  layers.7.norm.alpha                     : False\n",
      "  layers.7.norm.bias                      : False\n",
      "  layers.8.enc_self_attn.W_Q.weight       : False\n",
      "  layers.8.enc_self_attn.W_Q.bias         : False\n",
      "  layers.8.enc_self_attn.W_K.weight       : False\n",
      "  layers.8.enc_self_attn.W_K.bias         : False\n",
      "  layers.8.enc_self_attn.W_V.weight       : False\n",
      "  layers.8.enc_self_attn.W_V.bias         : False\n",
      "  layers.8.enc_self_attn.linear.weight    : False\n",
      "  layers.8.enc_self_attn.linear.bias      : False\n",
      "  layers.8.enc_self_attn.norm.alpha       : False\n",
      "  layers.8.enc_self_attn.norm.bias        : False\n",
      "  layers.8.pos_ffn.fc1.weight             : False\n",
      "  layers.8.pos_ffn.fc1.bias               : False\n",
      "  layers.8.pos_ffn.fc2.weight             : False\n",
      "  layers.8.pos_ffn.fc2.bias               : False\n",
      "  layers.8.pos_ffn.norm.alpha             : False\n",
      "  layers.8.pos_ffn.norm.bias              : False\n",
      "  layers.8.norm.alpha                     : False\n",
      "  layers.8.norm.bias                      : False\n",
      "  layers.9.enc_self_attn.W_Q.weight       : False\n",
      "  layers.9.enc_self_attn.W_Q.bias         : False\n",
      "  layers.9.enc_self_attn.W_K.weight       : False\n",
      "  layers.9.enc_self_attn.W_K.bias         : False\n",
      "  layers.9.enc_self_attn.W_V.weight       : False\n",
      "  layers.9.enc_self_attn.W_V.bias         : False\n",
      "  layers.9.enc_self_attn.linear.weight    : False\n",
      "  layers.9.enc_self_attn.linear.bias      : False\n",
      "  layers.9.enc_self_attn.norm.alpha       : False\n",
      "  layers.9.enc_self_attn.norm.bias        : False\n",
      "  layers.9.pos_ffn.fc1.weight             : False\n",
      "  layers.9.pos_ffn.fc1.bias               : False\n",
      "  layers.9.pos_ffn.fc2.weight             : False\n",
      "  layers.9.pos_ffn.fc2.bias               : False\n",
      "  layers.9.pos_ffn.norm.alpha             : False\n",
      "  layers.9.pos_ffn.norm.bias              : False\n",
      "  layers.9.norm.alpha                     : False\n",
      "  layers.9.norm.bias                      : False\n",
      "  layers.10.enc_self_attn.W_Q.weight      : False\n",
      "  layers.10.enc_self_attn.W_Q.bias        : False\n",
      "  layers.10.enc_self_attn.W_K.weight      : False\n",
      "  layers.10.enc_self_attn.W_K.bias        : False\n",
      "  layers.10.enc_self_attn.W_V.weight      : False\n",
      "  layers.10.enc_self_attn.W_V.bias        : False\n",
      "  layers.10.enc_self_attn.linear.weight   : False\n",
      "  layers.10.enc_self_attn.linear.bias     : False\n",
      "  layers.10.enc_self_attn.norm.alpha      : False\n",
      "  layers.10.enc_self_attn.norm.bias       : False\n",
      "  layers.10.pos_ffn.fc1.weight            : False\n",
      "  layers.10.pos_ffn.fc1.bias              : False\n",
      "  layers.10.pos_ffn.fc2.weight            : False\n",
      "  layers.10.pos_ffn.fc2.bias              : False\n",
      "  layers.10.pos_ffn.norm.alpha            : False\n",
      "  layers.10.pos_ffn.norm.bias             : False\n",
      "  layers.10.norm.alpha                    : False\n",
      "  layers.10.norm.bias                     : False\n",
      "  layers.11.enc_self_attn.W_Q.weight      : False\n",
      "  layers.11.enc_self_attn.W_Q.bias        : False\n",
      "  layers.11.enc_self_attn.W_K.weight      : False\n",
      "  layers.11.enc_self_attn.W_K.bias        : False\n",
      "  layers.11.enc_self_attn.W_V.weight      : False\n",
      "  layers.11.enc_self_attn.W_V.bias        : False\n",
      "  layers.11.enc_self_attn.linear.weight   : False\n",
      "  layers.11.enc_self_attn.linear.bias     : False\n",
      "  layers.11.enc_self_attn.norm.alpha      : False\n",
      "  layers.11.enc_self_attn.norm.bias       : False\n",
      "  layers.11.pos_ffn.fc1.weight            : False\n",
      "  layers.11.pos_ffn.fc1.bias              : False\n",
      "  layers.11.pos_ffn.fc2.weight            : False\n",
      "  layers.11.pos_ffn.fc2.bias              : False\n",
      "  layers.11.pos_ffn.norm.alpha            : False\n",
      "  layers.11.pos_ffn.norm.bias             : False\n",
      "  layers.11.norm.alpha                    : False\n",
      "  layers.11.norm.bias                     : False\n",
      "  linear.weight                           : False\n",
      "  linear.bias                             : False\n",
      "  norm.alpha                              : False\n",
      "  norm.bias                               : False\n",
      "  decoder.weight                          : False\n",
      "\n",
      "→ Is backbone fully frozen? True\n"
     ]
    }
   ],
   "source": [
    "# model: LWMWithHead 인스턴스\n",
    "print(\"Backbone requires_grad flags:\")\n",
    "for name, param in model.backbone.named_parameters():\n",
    "    print(f\"  {name:40s}: {param.requires_grad}\")\n",
    "\n",
    "# 또한 전체가 동결됐는지 한 줄로 요약하려면:\n",
    "all_frozen = all(not p.requires_grad for p in model.backbone.parameters())\n",
    "print(f\"\\n→ Is backbone fully frozen? {all_frozen}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6a78d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가 함수\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ─────────────────────────────────────────\n",
    "# 1. 배치 단위 RMSE, NMSE 함수\n",
    "# ─────────────────────────────────────────\n",
    "def rmse(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Root-Mean-Squared Error\n",
    "    returns: 스칼라 (배치 평균)\n",
    "    \"\"\"\n",
    "    return torch.sqrt(F.mse_loss(pred, target, reduction=\"mean\"))   # √MSE\n",
    "\n",
    "def nmse(pred: torch.Tensor, target: torch.Tensor, eps : float = 1e-12) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Normalized MSE  =  E[‖ŷ − y‖²] / E[‖y‖²]\n",
    "      · 채널 예측 분야에서 흔히 쓰는 지표\n",
    "    returns: 스칼라 (배치 평균)\n",
    "    \"\"\"\n",
    "    # (B, …) → (B,)  : 각 샘플별 제곱합\n",
    "    mse_per_sample   = ((pred - target)**2).view(pred.size(0), -1).sum(dim=1)\n",
    "    power_per_sample = (target**2).view(target.size(0), -1).sum(dim=1) + eps\n",
    "    return (mse_per_sample / power_per_sample).mean()\n",
    "\n",
    "\n",
    "# ─────────────────────────────────────────\n",
    "# 2. 검증 루프 예시\n",
    "# ─────────────────────────────────────────\n",
    "def evaluate(model, loader, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Validation loop for IterableDataset.\n",
    "    Returns average RMSE and NMSE over all samples.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_rmse, total_nmse, total_samples = 0.0, 0.0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_ids, masked_pos, target in loader:\n",
    "            # Move to device\n",
    "            input_ids, masked_pos, target = (\n",
    "                input_ids.to(device),\n",
    "                masked_pos.to(device),\n",
    "                target.to(device),\n",
    "            )\n",
    "            # Batch size\n",
    "            bs = input_ids.size(0)\n",
    "\n",
    "            # Forward\n",
    "            pred = model(input_ids, masked_pos)\n",
    "\n",
    "            # Accumulate batch metrics\n",
    "            total_rmse    += rmse(pred, target).item() * bs\n",
    "            total_nmse    += nmse(pred, target).item() * bs\n",
    "            total_samples += bs\n",
    "\n",
    "    # Compute averages\n",
    "    return {\n",
    "        \"RMSE\": total_rmse / total_samples,\n",
    "        \"NMSE\": total_nmse / total_samples\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a06b20a",
   "metadata": {},
   "source": [
    "# model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1f7ce629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01/10] Train Loss: 0.0126  Val RMSE: 0.0693  Val NMSE: 2.5363e-02  Val NMSE_dB: -16.0 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/10] Train Loss: 0.0065  Val RMSE: 0.0638  Val NMSE: 2.1190e-02  Val NMSE_dB: -16.7 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/10] Train Loss: 0.0056  Val RMSE: 0.0601  Val NMSE: 1.8502e-02  Val NMSE_dB: -17.3 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04/10] Train Loss: 0.0050  Val RMSE: 0.0577  Val NMSE: 1.7175e-02  Val NMSE_dB: -17.7 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/10] Train Loss: 0.0047  Val RMSE: 0.0566  Val NMSE: 1.6362e-02  Val NMSE_dB: -17.9 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06/10] Train Loss: 0.0044  Val RMSE: 0.0560  Val NMSE: 1.5875e-02  Val NMSE_dB: -18.0 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07/10] Train Loss: 0.0042  Val RMSE: 0.0552  Val NMSE: 1.5434e-02  Val NMSE_dB: -18.1 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08/10] Train Loss: 0.0041  Val RMSE: 0.0545  Val NMSE: 1.4986e-02  Val NMSE_dB: -18.2 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09/10] Train Loss: 0.0039  Val RMSE: 0.0538  Val NMSE: 1.4573e-02  Val NMSE_dB: -18.4 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/10] Train Loss: 0.0038  Val RMSE: 0.0533  Val NMSE: 1.4316e-02  Val NMSE_dB: -18.4 dB\n",
      "Total training time: 3747.72s\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time, torch\n",
    "\n",
    "num_epochs   = 10                      # 원하는 epoch 수\n",
    "start_time   = time.time()\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "\n",
    "    # ① TRAIN ────────────────────────────────\n",
    "    model.train()\n",
    "    run_loss = 0.0\n",
    "\n",
    "    tq = tqdm(train_loader, desc=f\"[{epoch:02d}/{num_epochs}] train\", leave=False)\n",
    "    for b, (inp, mpos, tgt) in enumerate(tq, 1):\n",
    "        inp, mpos, tgt = inp.to(device), mpos.to(device), tgt.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred  = model(inp, mpos).squeeze(-1)\n",
    "        loss  = criterion(pred, tgt)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        run_loss += loss.item()\n",
    "        if b % 100 == 0:                   # 100 배치마다 진행바에 표시\n",
    "            tq.set_postfix(loss=run_loss/b)\n",
    "\n",
    "    avg_train_loss = run_loss / b\n",
    "\n",
    "    # ② VALID ────────────────────────────────\n",
    "    metrics   = evaluate(model, val_loader, device)\n",
    "    val_rmse  = metrics[\"RMSE\"]\n",
    "    val_nmse  = metrics[\"NMSE\"]\n",
    "    val_nmse_db = 10 * torch.log10(torch.tensor(val_nmse)).item()\n",
    "\n",
    "    print(\n",
    "    f\"[{epoch:02d}/{num_epochs}] \"\n",
    "    f\"Train Loss: {avg_train_loss:.4f}  \"\n",
    "    f\"Val RMSE: {val_rmse:.4f}  \"\n",
    "    f\"Val NMSE: {val_nmse:.4e}  \"\n",
    "    f\"Val NMSE_dB: {val_nmse_db:.1f} dB\"\n",
    ")\n",
    "print(f\"Total training time: {time.time() - start_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7b169d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6932b03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a9fbc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68711972-6378-452d-9ab4-592f63fa4d68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e512fd9c-7e73-4543-af98-dcd07ecd5d78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
