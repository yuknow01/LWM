{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0939df15-abc7-40e7-83bf-f12820dd42f2",
   "metadata": {},
   "source": [
    "# All Model saves here\n",
    "- option 1: all random separate train / test dataset\n",
    "- solve mpos part and transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cbf7fb-304f-432d-a3f9-580052d5a375",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0e94396-1d80-4df3-8648-19368f82c4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import DeepMIMOv3\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import IterableDataset\n",
    "import numpy as np\n",
    "import time, gc\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from lwm_model import lwm\n",
    "from torch.optim import Adam\n",
    "from pathlib import Path\n",
    "import torch, time\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb2d8b4-7d3d-43ae-b997-2a4e6eab9a1a",
   "metadata": {},
   "source": [
    "## GPU Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a6479f7-d2b2-4632-b3a8-ffe3c49a6608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# GPU \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea87b9c9-a4b1-4442-b26f-606828c4dc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.6\n",
      "90501\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)                   \n",
    "print(torch.backends.cudnn.version())       \n",
    "print(\"CUDA available:\", torch.cuda.is_available())  # True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dc1a47-3bc0-4236-813e-c7be4c21bd41",
   "metadata": {},
   "source": [
    "## DeepMIMOv3 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "821eb69b-806e-4694-adf9-fd0efcbf5e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = DeepMIMOv3.default_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1d1f75d-54c0-4198-990f-15eaeec28e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change parameters for the setup\n",
    "# Scenario O1_60 extracted at the dataset_folder\n",
    "#LWM dynamic senario\n",
    "# parameters['dataset_folder'] = r'/content/drive/MyDrive/Colab Notebooks/LWM'\n",
    "scene = 15 # scene 15\n",
    "# change my linux route\n",
    "parameters['dataset_folder'] = '/home/dlghdbs200/LWM'\n",
    "\n",
    "# scnario = 02_dyn_3p5 <- download file\n",
    "parameters['scenario'] = 'O2_dyn_3p5'\n",
    "parameters['dynamic_scenario_scenes'] = np.arange(scene) #scene 0~9\n",
    "\n",
    "# Up to 10 multipath paths per user-to-base station channel\n",
    "parameters['num_paths'] = 10\n",
    "\n",
    "# User rows 1-100\n",
    "parameters['user_rows'] = np.arange(100)\n",
    "# User subsampling\n",
    "parameters['user_subsampling'] = 0.01\n",
    "\n",
    "# Activate only the first basestation\n",
    "parameters['active_BS'] = np.array([1])\n",
    "\n",
    "parameters['activate_OFDM'] = 1\n",
    "\n",
    "parameters['OFDM']['bandwidth'] = 0.05 # 50 MHz\n",
    "parameters['OFDM']['subcarriers'] = 512 # OFDM with 512 subcarriers\n",
    "parameters['OFDM']['selected_subcarriers'] = np.arange(0, 64, 1)\n",
    "#parameters['OFDM']['subcarriers_limit'] = 64 # Keep only first 64 subcarriers\n",
    "\n",
    "parameters['ue_antenna']['shape'] = np.array([1, 1]) # Single antenna\n",
    "parameters['bs_antenna']['shape'] = np.array([1, 32]) # ULA of 32 elements\n",
    "#parameters['bs_antenna']['rotation'] = np.array([0, 30, 90]) # ULA of 32 elements\n",
    "#parameters['ue_antenna']['rotation'] = np.array([[0, 30], [30, 60], [60, 90]]) # ULA of 32 elements\n",
    "#parameters['ue_antenna']['radiation_pattern'] = 'isotropic'\n",
    "#parameters['bs_antenna']['radiation_pattern'] = 'halfwave-dipole'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a9e7bb3-7cb7-4742-a949-9dd84ca31a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                             | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following parameters seem unnecessary:\n",
      "{'activate_OFDM'}\n",
      "\n",
      "Scene 1/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                    | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  37%|███████████████████▍                                | 25854/69006 [00:00<00:00, 258513.13it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|████████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 248316.62it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                      | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 5807.59it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 4275.54it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 793.32it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 2/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                    | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  41%|█████████████████████▎                              | 28264/69006 [00:00<00:00, 282622.08it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|████████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 288009.38it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                      | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 6219.50it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6393.76it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 108.55it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 3/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                    | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  34%|█████████████████▋                                  | 23432/69006 [00:00<00:00, 234281.68it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|████████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 238774.47it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                      | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 6948.91it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 4341.93it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 402.41it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 4/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                    | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  47%|████████████████████████▍                           | 32360/69006 [00:00<00:00, 323572.54it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|████████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 277124.49it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                      | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 6455.99it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5090.17it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 299.14it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 5/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                    | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  38%|███████████████████▋                                | 26099/69006 [00:00<00:00, 260963.49it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|████████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 273914.86it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                      | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 6869.12it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6754.11it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 465.93it/s]\u001b[A\n",
      " 33%|████████████████████████████▎                                                        | 1/3 [00:07<00:14,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenes 0–4 generation time: 7.07s\n",
      "The following parameters seem unnecessary:\n",
      "{'activate_OFDM'}\n",
      "\n",
      "Scene 1/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                    | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  46%|███████████████████████▉                            | 31692/69006 [00:00<00:00, 316892.35it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|████████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 272666.69it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 7331.43it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 4917.12it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 209.11it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 2/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                    | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  46%|███████████████████████▊                            | 31535/69006 [00:00<00:00, 315306.70it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|████████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 299456.76it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                      | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 7013.29it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5874.38it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 638.69it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 3/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                    | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  45%|███████████████████████▍                            | 31046/69006 [00:00<00:00, 310436.61it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|████████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 302855.93it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 7657.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5966.29it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 865.88it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 4/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                    | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  43%|██████████████████████▍                             | 29857/69006 [00:00<00:00, 298546.80it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|████████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 306028.69it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                      | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 5479.96it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 7449.92it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 967.32it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 5/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                    | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  41%|█████████████████████▍                              | 28450/69006 [00:00<00:00, 283951.23it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|████████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 289030.68it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 7623.13it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 6335.81it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 807.53it/s]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████████▋                            | 2/3 [00:14<00:07,  7.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenes 5–9 generation time: 6.77s\n",
      "The following parameters seem unnecessary:\n",
      "{'activate_OFDM'}\n",
      "\n",
      "Scene 1/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                    | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  45%|███████████████████████▎                            | 30896/69006 [00:00<00:00, 308934.52it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|████████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 298110.74it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                      | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 7124.54it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 5698.78it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 921.83it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 2/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                    | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  41%|█████████████████████▍                              | 28456/69006 [00:00<00:00, 284540.60it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|████████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 273553.72it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                      | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 6804.32it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 4476.31it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 702.09it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 3/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                    | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  41%|█████████████████████                               | 27960/69006 [00:00<00:00, 279566.27it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|████████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 290192.74it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                      | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 6653.33it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 3379.78it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 942.54it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 4/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                    | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  39%|████████████████████▎                               | 26929/69006 [00:00<00:00, 269253.02it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|████████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 290758.87it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                      | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 6309.30it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 4650.00it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 644.09it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 5/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                    | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  46%|███████████████████████▋                            | 31428/69006 [00:00<00:00, 314257.82it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|████████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 297404.06it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                      | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 6667.36it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 4424.37it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 646.77it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:21<00:00,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenes 10–14 generation time: 6.84s\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98 99]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## dataset setting (chunked on‑the‑fly generation)\n",
    "import time, gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 0~999 scene index , process 50 at that time\n",
    "scene_indices = np.arange(scene)\n",
    "chunk_size   = 5\n",
    "all_data     = []\n",
    "\n",
    "# Call generate_data for each scene chunk\n",
    "for i in tqdm(range(0, len(scene_indices), chunk_size)):\n",
    "    chunk = scene_indices[i : i+chunk_size].tolist()\n",
    "    parameters['dynamic_scenario_scenes'] = chunk\n",
    "\n",
    "    start = time.time()\n",
    "    data_chunk = DeepMIMOv3.generate_data(parameters)\n",
    "    print(f\"Scenes {chunk[0]}–{chunk[-1]} generation time: {time.time() - start:.2f}s\")\n",
    "\n",
    "    # combine all_data or save in the Disk\n",
    "    all_data.extend(data_chunk)\n",
    "\n",
    "    # free memory \n",
    "    del data_chunk\n",
    "    gc.collect()\n",
    "\n",
    "# comvine Dataset\n",
    "dataset = all_data\n",
    "\n",
    "\n",
    "print(parameters['user_rows'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc75e14-9605-49b0-8034-2a1dc367f97e",
   "metadata": {},
   "source": [
    "## About Information\n",
    "User : 737\n",
    "UE antenna : 1\n",
    "BS antenna : 32  Shape(a+bj)\n",
    "subcarrier : 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48148074-4682-4ab8-acbe-71ef042a5020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unmasked Data Model(gru\n",
    "# separate maksed data and unmasked data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe56d11-0ebb-4c13-b4c2-61fadd9c714b",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ba0a2d3-ee35-43dc-b457-bd400e5b75c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnMaskedChannelSeqDataset(IterableDataset):\n",
    "    \"\"\"\n",
    "    IterableDataset (un-masked version)\n",
    "\n",
    "    * Task : predict the next-step channel vector from the past `seq_len` steps.\n",
    "    * Pipeline\n",
    "        1. **Power-normalise** each complex channel vector → real + imag concat.\n",
    "        2. **Min–Max scale** inputs and targets with *one* shared scaler\n",
    "           (fitted on the same power-normalised data).\n",
    "        3. Yield `(sequence, target)` pairs as `torch.FloatTensor`.\n",
    "    * Optionally reuse externally provided scalers (train/val split consistency).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        scenes,\n",
    "        seq_len: int = 5,\n",
    "        eps: float   = 1e-9,\n",
    "        scalers: tuple[MinMaxScaler, MinMaxScaler] | None = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.scenes  = scenes\n",
    "        self.seq_len = seq_len\n",
    "        self.eps     = eps\n",
    "\n",
    "        # --- channel tensor dimensions --------------------------------------\n",
    "        ch0          = scenes[0][0]['user']['channel']        # (U, 1, A, S)\n",
    "        self.U       = ch0.shape[0]                           # users\n",
    "        self.A       = ch0.shape[2]                           # BS antennas\n",
    "        self.S       = ch0.shape[3]                           # sub-carriers\n",
    "        self.vec_len = 2 * self.A                            # real + imag\n",
    "\n",
    "        # --------------------------------------------------------------------\n",
    "        # 1) Fit / reuse MinMax scalers on power-normalised data\n",
    "        # --------------------------------------------------------------------\n",
    "        if scalers is None:\n",
    "            X_list, y_list = [], []\n",
    "            T = len(scenes)\n",
    "            for t in range(self.seq_len, T):\n",
    "                past  = scenes[t - self.seq_len : t]\n",
    "                s_tgt = scenes[t]\n",
    "\n",
    "                for u in range(self.U):\n",
    "                    for s in range(self.S):\n",
    "                        # power-normalised sequence (seq_len, vec_len)\n",
    "                        seq_np = np.stack([\n",
    "                            self._power_norm(p[0]['user']['channel'][u, 0, :, s])\n",
    "                            for p in past\n",
    "                        ], axis=0).astype(np.float32)\n",
    "\n",
    "                        # power-normalised target   (vec_len,)\n",
    "                        tgt_np = self._power_norm(\n",
    "                            s_tgt[0]['user']['channel'][u, 0, :, s]\n",
    "                        ).astype(np.float32)\n",
    "\n",
    "                        # skip if empty (all zeros)\n",
    "                        if not np.any(seq_np) or not np.any(tgt_np):\n",
    "                            continue\n",
    "\n",
    "                        X_list.append(seq_np.reshape(-1, self.vec_len))\n",
    "                        y_list.append(tgt_np)\n",
    "\n",
    "            X_all = np.vstack(X_list)          # (N*seq_len, vec_len)\n",
    "            y_all = np.stack(y_list)           # (N, vec_len)\n",
    "            self.scaler_x = MinMaxScaler().fit(X_all)\n",
    "            self.scaler_y = MinMaxScaler().fit(y_all)\n",
    "        else:\n",
    "            # use pre-computed scalers (train/val share the same)\n",
    "            self.scaler_x, self.scaler_y = scalers\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # iterator\n",
    "    # ------------------------------------------------------------------------\n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        Yields:\n",
    "            seq_tensor   : FloatTensor (seq_len, vec_len)\n",
    "            target_tensor: FloatTensor (vec_len,)\n",
    "        Both tensors are power-normalised **and** Min–Max scaled.\n",
    "        \"\"\"\n",
    "        T = len(self.scenes)\n",
    "        for t in range(self.seq_len, T):\n",
    "            past  = self.scenes[t - self.seq_len : t]\n",
    "            s_tgt = self.scenes[t]\n",
    "\n",
    "            for u in range(self.U):\n",
    "                for s in range(self.S):\n",
    "                    seq_np = np.stack([\n",
    "                        self._power_norm(p[0]['user']['channel'][u, 0, :, s])\n",
    "                        for p in past\n",
    "                    ], axis=0)\n",
    "                    tgt_np = self._power_norm(\n",
    "                        s_tgt[0]['user']['channel'][u, 0, :, s]\n",
    "                    )\n",
    "\n",
    "                    if not np.any(seq_np) or not np.any(tgt_np):\n",
    "                        continue\n",
    "\n",
    "                    # identical scalers for train / val\n",
    "                    N, D = seq_np.shape\n",
    "                    seq_np = self.scaler_x.transform(seq_np.reshape(-1, D)).reshape(N, D)\n",
    "                    tgt_np = self.scaler_y.transform(tgt_np.reshape(1, -1)).reshape(-1,)\n",
    "\n",
    "                    yield torch.from_numpy(seq_np), torch.from_numpy(tgt_np)\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # helpers\n",
    "    # ------------------------------------------------------------------------\n",
    "    def _power_norm(self, h: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Convert complex vector → real|imag concatenation\n",
    "        and force average power to 1.\n",
    "        \"\"\"\n",
    "        v      = np.concatenate([h.real, h.imag]).astype(np.float32)\n",
    "        power  = np.mean(v * v) + self.eps\n",
    "        return v / np.sqrt(power)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Rough size estimate (not used by IterableDataset).\"\"\"\n",
    "        return (len(self.scenes) - self.seq_len) * self.U * self.S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97d365ac-69a6-494c-bfc7-198bdeb29582",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedChannelSeqDataset(IterableDataset):\n",
    "    \"\"\"\n",
    "    IterableDataset for masked channel sequence data.\n",
    "\n",
    "    - Predicts the next-step channel vector from a sequence of past vectors.\n",
    "    - Applies power normalization and MinMax scaling to both inputs and targets.\n",
    "    - Masks 15% of the patches according to:\n",
    "        * 80% chance: replace selected patch with zeros\n",
    "        * 10% chance: replace selected patch with Gaussian noise\n",
    "        * 10% chance: leave the selected patch unchanged\n",
    "      The other 85% of samples are returned unmasked.\n",
    "    \"\"\"\n",
    "    def __init__(self, scenes, seq_len=5, eps=1e-9, noise_std=1.0):\n",
    "        super().__init__()\n",
    "        self.scenes    = scenes\n",
    "        self.seq_len   = seq_len\n",
    "        self.eps       = eps\n",
    "        self.noise_std = noise_std\n",
    "\n",
    "        # Determine dimensions: U=users, A=antennas, S=subcarriers\n",
    "        ch0 = scenes[0][0]['user']['channel']   # shape: (U, 1, A, S)\n",
    "        self.U       = ch0.shape[0]\n",
    "        self.A       = ch0.shape[2]\n",
    "        self.S       = ch0.shape[3]\n",
    "        self.vec_len = 2 * self.A               # real+imag concatenated\n",
    "\n",
    "        # ----------------------------------------------------------------------\n",
    "        # 1) PRECOMPUTE power-norm → fit MinMax scalers on exactly the same data\n",
    "        # ----------------------------------------------------------------------\n",
    "        X_list, y_list = [], []\n",
    "        T = len(scenes)\n",
    "        for t in range(self.seq_len, T):\n",
    "            past         = scenes[t - self.seq_len : t]\n",
    "            target_scene = scenes[t]\n",
    "            for u in range(self.U):\n",
    "                for s in range(self.S):\n",
    "                    # power-normalize each time-slice in the sequence\n",
    "                    seq_np = np.stack([\n",
    "                        self._power_norm(ps[0]['user']['channel'][u,0,:,s])\n",
    "                        for ps in past\n",
    "                    ], axis=0).astype(np.float32)  # (seq_len, vec_len)\n",
    "\n",
    "                    # power-normalize target\n",
    "                    tgt_np = self._power_norm(\n",
    "                        target_scene[0]['user']['channel'][u,0,:,s]\n",
    "                    ).astype(np.float32)            # (vec_len,)\n",
    "\n",
    "                    # skip if invalid\n",
    "                    if not np.any(seq_np) or not np.any(tgt_np):\n",
    "                        continue\n",
    "\n",
    "                    # flatten sequence for scaler\n",
    "                    X_list.append(seq_np.reshape(-1, self.vec_len))\n",
    "                    y_list.append(tgt_np)\n",
    "\n",
    "        # fit scalers on the exact same power-normalized data\n",
    "        X_all = np.vstack(X_list)  # (num_samples*seq_len, vec_len)\n",
    "        y_all = np.stack(y_list)   # (num_samples, vec_len)\n",
    "        self.scaler_x = MinMaxScaler().fit(X_all)\n",
    "        self.scaler_y = MinMaxScaler().fit(y_all)\n",
    "\n",
    "        # prepare a zero-mask vector\n",
    "        self.mask_value = torch.zeros(self.vec_len, dtype=torch.float32)\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "        Yields:\n",
    "            seq_tensor      (seq_len, vec_len) : normalized & scaled sequence\n",
    "            masked_pos      (1,) tensor long   : index of masked time step\n",
    "            target_tensor   (vec_len,)          : normalized & scaled target\n",
    "        \"\"\"\n",
    "        T = len(self.scenes)\n",
    "        # it is not necessary mask because already pretrained about LWM \n",
    "        # so Change mask_prob = 0 \n",
    "        mask_prob  = 0\n",
    "        zero_prob  = mask_prob * 0.8\n",
    "        noise_prob = mask_prob * 0.1\n",
    "\n",
    "        for t in range(self.seq_len, T):\n",
    "            past       = self.scenes[t - self.seq_len : t]\n",
    "            scene_dict = self.scenes[t]\n",
    "\n",
    "            for u in range(self.U):\n",
    "                for s in range(self.S):\n",
    "                    # power-normalize each slice\n",
    "                    seq_np = np.stack([\n",
    "                        self._power_norm(ps[0]['user']['channel'][u,0,:,s])\n",
    "                        for ps in past\n",
    "                    ], axis=0)\n",
    "                    tgt_np = self._power_norm(\n",
    "                        scene_dict[0]['user']['channel'][u,0,:,s]\n",
    "                    )\n",
    "\n",
    "                    if not np.any(seq_np) or not np.any(tgt_np):\n",
    "                        continue\n",
    "\n",
    "                    # MinMax transform (using the same scalers)\n",
    "                    N, D = seq_np.shape\n",
    "                    seq_np = self.scaler_x.transform(seq_np.reshape(-1, D)).reshape(N, D)\n",
    "                    tgt_np = self.scaler_y.transform(tgt_np.reshape(1, -1)).reshape(-1,)\n",
    "\n",
    "                    seq_tensor   = torch.from_numpy(seq_np)\n",
    "                    target_tensor= torch.from_numpy(tgt_np)\n",
    "\n",
    "                    # select mask position\n",
    "                    mpos = random.randrange(self.seq_len)\n",
    "\n",
    "                    r = random.random()\n",
    "                    if r < zero_prob:\n",
    "                        masked_seq = seq_tensor.clone()\n",
    "                        masked_seq[mpos] = self.mask_value\n",
    "                        yield masked_seq, torch.tensor([mpos]), target_tensor\n",
    "\n",
    "                    elif r < zero_prob + noise_prob:\n",
    "                        masked_seq = seq_tensor.clone()\n",
    "                        masked_seq[mpos] = torch.randn(self.vec_len) * self.noise_std\n",
    "                        yield masked_seq, torch.tensor([mpos]), target_tensor\n",
    "\n",
    "                    elif r < mask_prob:\n",
    "                        # masked-but-unchanged\n",
    "                        yield seq_tensor, torch.tensor([mpos]), target_tensor\n",
    "\n",
    "                    else:\n",
    "                        # unmasked\n",
    "                        yield seq_tensor, torch.tensor([mpos]), target_tensor\n",
    "\n",
    "    def _power_norm(self, h: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Convert complex vector to real+imag concat and normalize power to 1.\n",
    "        \"\"\"\n",
    "        v = np.concatenate([h.real, h.imag]).astype(np.float32)\n",
    "        power = np.mean(v * v) + self.eps\n",
    "        return v / np.sqrt(power)\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.scenes) - self.seq_len) * self.U * self.S\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b0cc00-cfa9-49f3-b981-87e55e3d9e20",
   "metadata": {},
   "source": [
    "## define trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fc802ee-c248-4351-9d38-bc8386b76424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_trainable_params(model: nn.Module) -> int:\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e1373a-f803-49f3-b891-f9d6f59e5dc9",
   "metadata": {},
   "source": [
    "## Split Train/Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29548f28-3188-4562-bb96-634ed3bac496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ❷ Train/Validation DataLoader split train : val = 6 : 4\n",
    "seq_len      = 5\n",
    "split_ratio  = 0.6\n",
    "split_idx    = int(len(dataset) * split_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fd809a5-3720-4ffd-90ce-b2d5ccf541f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "unmasked_train_ds = UnMaskedChannelSeqDataset(dataset[:split_idx], seq_len=seq_len)\n",
    "unmasked_val_ds   = UnMaskedChannelSeqDataset(dataset[split_idx:], seq_len=seq_len)\n",
    "\n",
    "# iterate over train_ds to compute min and max of features/targets\n",
    "\n",
    "batch_size   = 32\n",
    "unmasked_train_loader = DataLoader(unmasked_train_ds, batch_size=batch_size, shuffle=False)\n",
    "unmasked_val_loader   = DataLoader(unmasked_val_ds,   batch_size=batch_size, shuffle=False)\n",
    "# ─────────────────────────────────────────────\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49c214a4-1b26-49a7-b308-e16a000f0ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ❷ Train/Validation DataLoader split train : val = 6 : 4\n",
    "\n",
    "masked_train_ds = MaskedChannelSeqDataset(dataset[:split_idx], seq_len=seq_len)\n",
    "masked_val_ds   = MaskedChannelSeqDataset(dataset[split_idx:], seq_len=seq_len)\n",
    "\n",
    "# iterate over train_ds to compute min and max of features/targets\n",
    "\n",
    "batch_size   = 32\n",
    "masked_train_loader = DataLoader(masked_train_ds, batch_size=batch_size, shuffle=False)\n",
    "masked_val_loader   = DataLoader(masked_val_ds,   batch_size=batch_size, shuffle=False)\n",
    "# ─────────────────────────────────────────────\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b29d65-387d-4326-b989-afe274279c38",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0383c46a-7e6c-4907-aaa4-e6b1902a770d",
   "metadata": {},
   "source": [
    "LWMWithHead: A wrapper class that uses a pre-trained LWM (Transformer encoder) as the backbone,\n",
    "             and attaches a new fully-connected (FC) head for downstream tasks\n",
    "             (regression, classification, etc.).\n",
    "\n",
    "Changes:\n",
    "- input_dim: Dimension of the actual input data (e.g., 64)\n",
    "- patch_length: Patch length expected by the backbone (e.g., 16)\n",
    "- Replaces the original element_length parameter with these two distinct parameters\n",
    "- Applies a projection layer (self.input_proj) in forward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80c33fca-38fa-4842-b886-69972e5d28a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LWMWithHead(nn.Module):\n",
    "    \"\"\"\n",
    "    LWMWithHead: A wrapper class that uses a pre-trained LWM (Transformer encoder) as the backbone,\n",
    "                 and attaches a new fully-connected (FC) head for downstream tasks\n",
    "                 (regression, classification, etc.).\n",
    "\n",
    "    Changes:\n",
    "    - input_dim: Dimension of the actual input data (e.g., 64)\n",
    "    - patch_length: Patch length expected by the backbone (e.g., 16)\n",
    "    - Replaces the original element_length parameter with these two distinct parameters\n",
    "    - Applies a projection layer (self.input_proj) in forward()\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,                 # Dimension of the actual input data (e.g., 64)\n",
    "        patch_length: int,              # Patch length expected by the backbone (e.g., 16)\n",
    "        d_model: int = 64,              # LWM hidden size\n",
    "        max_len: int = 129,             # Positional encoding max length\n",
    "        n_layers: int = 12,             # Number of Transformer encoder layers\n",
    "        hidden_dim: int = 256,          # FC head hidden dimension\n",
    "        out_dim: int = 64,              # FC head output dimension\n",
    "        freeze_backbone: bool = True,   # Whether to freeze the backbone\n",
    "        checkpoint_path: str | None = \"./model_weights.pth\",\n",
    "        device: str = \"cuda\"\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # apply a projection layer to match backbone's expected patch_length\n",
    "        self.input_proj = nn.Linear(input_dim, patch_length)\n",
    "\n",
    "        # initialize backbone\n",
    "        if checkpoint_path is None:\n",
    "            # randomly initialized backbone\n",
    "            self.backbone = lwm(\n",
    "                element_length=patch_length,\n",
    "                d_model=d_model,\n",
    "                max_len=max_len,\n",
    "                n_layers=n_layers\n",
    "            ).to(device)\n",
    "        else:\n",
    "            # load pre-trained weights\n",
    "            self.backbone = lwm.from_pretrained(\n",
    "                ckpt_name=checkpoint_path,\n",
    "                device=device\n",
    "            )\n",
    "\n",
    "        # freeze backbone parameters if required\n",
    "        if freeze_backbone:\n",
    "            for p in self.backbone.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        # attach a new fully-connected head for downstream tasks\n",
    "        self.head = nn.Sequential(\n",
    "            # change 2 layer -> 1 layer\n",
    "            nn.Linear(d_model, out_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, masked_pos: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_ids: Tensor of shape (B, L, input_dim)\n",
    "            masked_pos: Tensor of shape (B, num_mask)\n",
    "        Returns:\n",
    "            out: Tensor of shape (B, out_dim)\n",
    "        \"\"\"\n",
    "        # project inputs to patch_length dimension\n",
    "        x = self.input_proj(input_ids)\n",
    "\n",
    "        # backbone forward: returns (logits_lm, enc_output)\n",
    "        _, enc_output = self.backbone(x, masked_pos)\n",
    "\n",
    "        # extract CLS token feature (first token)\n",
    "        feat = enc_output[:, 0, :]\n",
    "\n",
    "        # pass through FC head to get final output\n",
    "        out = self.head(feat)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2e8f0ee-6782-4eb2-b6c3-fe363ed8d507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class GRUWithHead(nn.Module):\n",
    "    \"\"\"\n",
    "    GRUWithHead (projected):\n",
    "      • Projects the raw feature dimension (input_dim) to a smaller patch_length\n",
    "        so every backbone receives the same patch-sized input (like LWM).\n",
    "      • Stacks N GRU layers, then an FC head for downstream tasks.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int    = 64,   # raw feature dimension coming from the DataLoader\n",
    "        patch_length: int = 16,   # target dimension fed to the GRU backbone\n",
    "        d_model: int      = 64,   # GRU hidden size\n",
    "        n_layers: int     = 12,   # number of stacked GRU layers\n",
    "        bidirectional: bool = True,\n",
    "        dropout: float      = 0.1,\n",
    "        hidden_dim: int     = 256, # FC-head hidden size\n",
    "        out_dim: int        = 64,  # FC-head output size\n",
    "        freeze_backbone: bool = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # 0) Project raw_dim → patch_length (64 → 16)\n",
    "        self.input_proj = nn.Linear(input_dim, patch_length)\n",
    "\n",
    "        # 1) GRU backbone that expects 'patch_length' features per time step\n",
    "        self.backbone = nn.GRU(\n",
    "            input_size     = patch_length,\n",
    "            hidden_size    = d_model,\n",
    "            num_layers     = n_layers,\n",
    "            batch_first    = True,\n",
    "            bidirectional  = bidirectional,\n",
    "            dropout        = dropout if n_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        if freeze_backbone:\n",
    "            for p in self.backbone.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        # 2) Fully-connected head\n",
    "        gru_out_dim = d_model * (2 if bidirectional else 1)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(gru_out_dim, out_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x : Tensor of shape (batch, seq_len, input_dim) – raw features\n",
    "        Returns:\n",
    "            Tensor of shape (batch, out_dim)\n",
    "        \"\"\"\n",
    "        # project raw features to patch_length\n",
    "        x_proj = self.input_proj(x)                 # (B, seq_len, patch_length)\n",
    "\n",
    "        # sequence modelling with GRU\n",
    "        out, _ = self.backbone(x_proj)              # (B, seq_len, num_dirs*d_model)\n",
    "\n",
    "        # use the last time-step representation\n",
    "        feat = out[:, -1, :]                        # (B, gru_out_dim)\n",
    "\n",
    "        # downstream head\n",
    "        return self.head(feat)                      # (B, out_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f9d84d1-33a1-4f34-9e97-51242fc2d57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        # Create positional encoding matrix of shape (1, max_len, d_model)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(pos * div_term)\n",
    "        pe[:, 1::2] = torch.cos(pos * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor of shape (batch_size, seq_len, d_model)\n",
    "        Returns:\n",
    "            Tensor: x plus positional encodings\n",
    "        \"\"\"\n",
    "        seq_len = x.size(1)\n",
    "        return x + self.pe[:, :seq_len, :]\n",
    "\n",
    "class InputEmbedding(nn.Module):\n",
    "    def __init__(self, feat_dim: int, d_model: int, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        # Optional linear projection from feat_dim to d_model\n",
    "        self.proj = nn.Linear(feat_dim, d_model) if feat_dim != d_model else None\n",
    "        self.pos_enc = PositionalEncoding(d_model, max_len)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor of shape (batch, seq_len, feat_dim)\n",
    "        Returns:\n",
    "            Tensor of shape (batch, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        if self.proj is not None:\n",
    "            x = self.proj(x)\n",
    "        return self.pos_enc(x)\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model: int, n_heads: int, dim_ff: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        # Multi-Head Self-Attention\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, n_heads, dropout=dropout)\n",
    "        # Position-wise Feed-Forward Network\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(d_model, dim_ff),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim_ff, d_model)\n",
    "        )\n",
    "        # Layer Normalization and Dropout for residual connections\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        src_mask: torch.Tensor = None,\n",
    "        src_key_padding_mask: torch.Tensor = None\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor of shape (seq_len, batch, d_model)\n",
    "            src_mask: Optional Tensor of shape (seq_len, seq_len)\n",
    "            src_key_padding_mask: Optional Tensor of shape (batch, seq_len)\n",
    "        Returns:\n",
    "            Tensor of shape (seq_len, batch, d_model)\n",
    "        \"\"\"\n",
    "        # Self-attention sublayer\n",
    "        attn_out, _ = self.self_attn(x, x, x, attn_mask=src_mask, key_padding_mask=src_key_padding_mask)\n",
    "        x = x + self.dropout1(attn_out)\n",
    "        x = self.norm1(x)\n",
    "        # Feed-forward sublayer\n",
    "        ff_out = self.ff(x)\n",
    "        x = x + self.dropout2(ff_out)\n",
    "        x = self.norm2(x)\n",
    "        return x\n",
    "\n",
    "class TransformerEncoderCustom(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        feat_dim: int,\n",
    "        d_model: int,\n",
    "        n_heads: int,\n",
    "        dim_ff: int,\n",
    "        n_layers: int,\n",
    "        dropout: float = 0.1,\n",
    "        max_len: int = 5000\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # Input embedding: feature projection + positional encoding\n",
    "        self.input_embedding = InputEmbedding(feat_dim, d_model, max_len)\n",
    "        # Stack of N encoder layers\n",
    "        self.layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, n_heads, dim_ff, dropout)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        src_mask: torch.Tensor = None,\n",
    "        src_key_padding_mask: torch.Tensor = None\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor of shape (batch, seq_len, feat_dim)\n",
    "        Returns:\n",
    "            Tensor of shape (seq_len, batch, d_model)\n",
    "        \"\"\"\n",
    "        x = self.input_embedding(x)       # (batch, seq_len, d_model)\n",
    "        x = x.transpose(0, 1)             # (seq_len, batch, d_model)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, src_mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
    "        return x\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model: int, n_heads: int, dim_ff: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        # Masked Self-Attention\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, n_heads, dropout=dropout)\n",
    "        # Encoder-Decoder Attention\n",
    "        self.multihead_attn = nn.MultiheadAttention(d_model, n_heads, dropout=dropout)\n",
    "        # Position-wise Feed-Forward Network\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(d_model, dim_ff),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim_ff, d_model)\n",
    "        )\n",
    "        # Layer Normalizations and Dropouts\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        tgt: torch.Tensor,\n",
    "        memory: torch.Tensor,\n",
    "        tgt_mask: torch.Tensor = None,\n",
    "        memory_mask: torch.Tensor = None,\n",
    "        tgt_key_padding_mask: torch.Tensor = None,\n",
    "        memory_key_padding_mask: torch.Tensor = None\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tgt: Tensor of shape (tgt_len, batch, d_model)\n",
    "            memory: Tensor of shape (src_len, batch, d_model)\n",
    "        Returns:\n",
    "            Tensor of shape (tgt_len, batch, d_model)\n",
    "        \"\"\"\n",
    "        # Masked self-attention sublayer\n",
    "        attn1, _ = self.self_attn(\n",
    "            tgt, tgt, tgt,\n",
    "            attn_mask=tgt_mask,\n",
    "            key_padding_mask=tgt_key_padding_mask\n",
    "        )\n",
    "        tgt = tgt + self.dropout1(attn1)\n",
    "        tgt = self.norm1(tgt)\n",
    "        # Encoder-decoder attention sublayer\n",
    "        attn2, _ = self.multihead_attn(\n",
    "            tgt, memory, memory,\n",
    "            attn_mask=memory_mask,\n",
    "            key_padding_mask=memory_key_padding_mask\n",
    "        )\n",
    "        tgt = tgt + self.dropout2(attn2)\n",
    "        tgt = self.norm2(tgt)\n",
    "        # Feed-forward sublayer\n",
    "        ff_out = self.ff(tgt)\n",
    "        tgt = tgt + self.dropout3(ff_out)\n",
    "        tgt = self.norm3(tgt)\n",
    "        return tgt\n",
    "\n",
    "class TransformerDecoderCustom(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        feat_dim: int,\n",
    "        d_model: int,\n",
    "        n_heads: int,\n",
    "        dim_ff: int,\n",
    "        n_layers: int,\n",
    "        dropout: float = 0.1,\n",
    "        max_len: int = 5000\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # Input embedding for target sequence\n",
    "        self.input_embedding = InputEmbedding(feat_dim, d_model, max_len)\n",
    "        # Stack of N decoder layers\n",
    "        self.layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model, n_heads, dim_ff, dropout)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "        # Final projection back to feature dimension\n",
    "        # self.output_linear = nn.Linear(d_model, feat_dim)\n",
    "        self.output_linear = nn.Identity()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        tgt: torch.Tensor,\n",
    "        memory: torch.Tensor,\n",
    "        tgt_mask: torch.Tensor = None,\n",
    "        memory_mask: torch.Tensor = None,\n",
    "        tgt_key_padding_mask: torch.Tensor = None,\n",
    "        memory_key_padding_mask: torch.Tensor = None\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tgt: Tensor of shape (batch, tgt_len, feat_dim)\n",
    "            memory: Tensor of shape (src_len, batch, d_model)\n",
    "        Returns:\n",
    "            Tensor of shape (batch, tgt_len, feat_dim)\n",
    "        \"\"\"\n",
    "        x = self.input_embedding(tgt)       # (batch, tgt_len, d_model)\n",
    "        x = x.transpose(0, 1)               # (tgt_len, batch, d_model)\n",
    "        for layer in self.layers:\n",
    "            x = layer(\n",
    "                x,\n",
    "                memory,\n",
    "                tgt_mask=tgt_mask,\n",
    "                memory_mask=memory_mask,\n",
    "                tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "                memory_key_padding_mask=memory_key_padding_mask\n",
    "            )\n",
    "        x = x.transpose(0, 1)               # (batch, tgt_len, d_model)\n",
    "        return self.output_linear(x)        # project back to feat_dim\n",
    "\n",
    "        \n",
    "\n",
    "class TransformerWithHead(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int    = 64,   # raw feature dimension\n",
    "        patch_length: int = 16,   # sequence length consumed by encoder/decoder\n",
    "        d_model: int      = 64,   # hidden size inside the transformer\n",
    "        n_heads: int      = 4,\n",
    "        dim_ff: int       = 256,\n",
    "        n_layers: int     = 12,\n",
    "        dropout: float    = 0.1,\n",
    "        hidden_dim: int   = 256,\n",
    "        out_dim: int      = 64,\n",
    "        max_len: int      = 5000,\n",
    "        freeze_backbone: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # 0) Project raw input dimension to patch length\n",
    "        self.input_proj = nn.Linear(input_dim, patch_length)\n",
    "\n",
    "        # 1) Encoder: processes the source sequence\n",
    "        self.encoder = TransformerEncoderCustom(\n",
    "            feat_dim = patch_length,\n",
    "            d_model  = d_model,\n",
    "            n_heads  = n_heads,\n",
    "            dim_ff   = dim_ff,\n",
    "            n_layers = n_layers,\n",
    "            dropout  = dropout,\n",
    "            max_len  = max_len,\n",
    "        )\n",
    "        if freeze_backbone:\n",
    "            for p in self.encoder.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        # 2) Decoder: generates target sequence using encoder memory\n",
    "        self.decoder = TransformerDecoderCustom(\n",
    "            feat_dim = patch_length,\n",
    "            d_model  = d_model,\n",
    "            n_heads  = n_heads,\n",
    "            dim_ff   = dim_ff,\n",
    "            n_layers = n_layers,\n",
    "            dropout  = dropout,\n",
    "            max_len  = max_len,\n",
    "        )\n",
    "\n",
    "        # 3) Task head: maps final decoder output to desired output dimension\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(d_model, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        src: torch.Tensor,                # (batch, src_len, input_dim)\n",
    "        tgt: torch.Tensor,                # (batch, tgt_len, input_dim)\n",
    "        src_mask: torch.Tensor = None,\n",
    "        src_key_padding_mask: torch.Tensor = None,\n",
    "        tgt_mask: torch.Tensor = None,\n",
    "        tgt_key_padding_mask: torch.Tensor = None,\n",
    "    ) -> torch.Tensor:\n",
    "        # 1) Encode source sequence to produce memory\n",
    "        src_patch = self.input_proj(src)  # (batch, src_len, patch_length)\n",
    "        memory = self.encoder(\n",
    "            src_patch,\n",
    "            src_mask=src_mask,\n",
    "            src_key_padding_mask=src_key_padding_mask\n",
    "        )  # (src_len, batch, d_model)\n",
    "\n",
    "        # 2) Decode target sequence using encoder memory\n",
    "        tgt_patch = self.input_proj(tgt)  # (batch, tgt_len, patch_length)\n",
    "        dec_out = self.decoder(\n",
    "            tgt_patch,\n",
    "            memory,\n",
    "            tgt_mask=tgt_mask,\n",
    "            memory_mask=None,\n",
    "            tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "            memory_key_padding_mask=src_key_padding_mask\n",
    "        )  # (batch, tgt_len, d_model)\n",
    "\n",
    "        # 3) Use last time-step output from decoder for prediction\n",
    "        last_step = dec_out[:, -1, :]      # (batch, d_model)\n",
    "        return self.head(last_step)        # (batch, out_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2503278-03dd-4b6d-8497-e9f9d83e10fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNWithHead(nn.Module):\n",
    "    \"\"\"\n",
    "    RNNWithHead (projected):\n",
    "      • Projects raw feature vectors from `input_dim` to `patch_length`\n",
    "      • Feeds the projected sequence to an RNN backbone\n",
    "      • Maps the last hidden state through an FC head\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int    = 64,   # raw feature dimension coming from DataLoader\n",
    "        patch_length: int = 16,   # dimension consumed by the RNN backbone\n",
    "        hidden_size: int  = 64,   # RNN hidden size\n",
    "        num_layers: int   = 12,   # number of stacked RNN layers\n",
    "        bidirectional: bool = True,\n",
    "        dropout: float      = 0.1,\n",
    "        hidden_dim: int     = 256, # FC-head hidden size\n",
    "        out_dim: int        = 64,  # FC-head output size\n",
    "        freeze_backbone: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # 0) project raw 64-dim → 16-dim\n",
    "        self.input_proj = nn.Linear(input_dim, patch_length)\n",
    "\n",
    "        # 1) RNN backbone\n",
    "        self.backbone = nn.RNN(\n",
    "            input_size     = patch_length,\n",
    "            hidden_size    = hidden_size,\n",
    "            num_layers     = num_layers,\n",
    "            batch_first    = True,\n",
    "            bidirectional  = bidirectional,\n",
    "            dropout        = dropout if num_layers > 1 else 0.0,\n",
    "        )\n",
    "\n",
    "        if freeze_backbone:\n",
    "            for p in self.backbone.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        # 2) FC head\n",
    "        rnn_out_dim = hidden_size * (2 if bidirectional else 1)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(rnn_out_dim, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        x: (batch, seq_len, input_dim=64)\n",
    "        returns: (batch, out_dim)\n",
    "        \"\"\"\n",
    "        x_proj = self.input_proj(x)           # (batch, seq_len, 16)\n",
    "        out, _ = self.backbone(x_proj)        # (batch, seq_len, rnn_out_dim)\n",
    "        feat   = out[:, -1, :]                # take last time step\n",
    "        return self.head(feat)                # (batch, out_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b210558c-7f51-4e6b-ad3a-8efa5237a71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMWithHead(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTMWithHead (projected):\n",
    "      • Projects raw feature vectors from `input_dim` to a compact `patch_length`\n",
    "      • Feeds the projected sequence to an LSTM backbone\n",
    "      • Uses the last hidden state to drive an FC head for the downstream task\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int    = 64,   # raw feature dimension (e.g., 64)\n",
    "        patch_length: int = 16,   # dimension consumed by the LSTM backbone\n",
    "        hidden_size: int  = 64,   # LSTM hidden size\n",
    "        num_layers: int   = 12,   # number of stacked LSTM layers\n",
    "        bidirectional: bool = True,\n",
    "        dropout: float      = 0.1,\n",
    "        hidden_dim: int     = 256, # FC-head hidden size\n",
    "        out_dim: int        = 64,  # FC-head output size\n",
    "        freeze_backbone: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # 0) Raw 64-dim → 16-dim patch projection\n",
    "        self.input_proj = nn.Linear(input_dim, patch_length)\n",
    "\n",
    "        # 1) LSTM backbone that expects `patch_length` features\n",
    "        self.backbone = nn.LSTM(\n",
    "            input_size     = patch_length,\n",
    "            hidden_size    = hidden_size,\n",
    "            num_layers     = num_layers,\n",
    "            batch_first    = True,\n",
    "            bidirectional  = bidirectional,\n",
    "            dropout        = dropout if num_layers > 1 else 0.0,\n",
    "        )\n",
    "        if freeze_backbone:\n",
    "            for p in self.backbone.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        # 2) FC head\n",
    "        lstm_out_dim = hidden_size * (2 if bidirectional else 1)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(lstm_out_dim, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        x: (batch, seq_len, input_dim=64)\n",
    "        returns: (batch, out_dim)\n",
    "        \"\"\"\n",
    "        # project raw features to patch_length\n",
    "        x_proj = self.input_proj(x)             # (B, seq_len, 16)\n",
    "\n",
    "        # sequence modeling with LSTM\n",
    "        out, _ = self.backbone(x_proj)          # (B, seq_len, lstm_out_dim)\n",
    "\n",
    "        # take the last time-step representation\n",
    "        feat = out[:, -1, :]                    # (B, lstm_out_dim)\n",
    "\n",
    "        # downstream head\n",
    "        return self.head(feat)                  # (B, out_dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4766f28-d102-4ed0-8272-7d5098ad9f15",
   "metadata": {},
   "source": [
    "## fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e104da9-d8e8-42ea-a810-3567b9ae412c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────\n",
    "# Shared hyper-parameters\n",
    "# ──────────────────────────\n",
    "INPUT_DIM     = 64     # raw feature dimension\n",
    "PATCH_LENGTH  = 16     # dimension fed to every backbone\n",
    "D_MODEL       = 64     # internal hidden size (GRU/LSTM/Transformer)\n",
    "N_LAYERS      = 12     # stacked layers\n",
    "HIDDEN_DIM    = 256    # head hidden dimension\n",
    "OUT_DIM       = 64     # head output dimension\n",
    "DROPOUT       = 0.1    # dropout for recurrent / transformer blocks\n",
    "BIDIRECTIONAL = True   # use bidirectional RNNs\n",
    "DEVICE        = \"cuda\"\n",
    "\n",
    "# ──────────────────────────\n",
    "# Model class catalog\n",
    "# ──────────────────────────\n",
    "MODEL_CATALOG = {\n",
    "    \"LWM_freeze_backbone\"     : LWMWithHead,\n",
    "    \"LWM_pretrained_Fine_tune\": LWMWithHead,\n",
    "    \"LWM_Fine_tune\"           : LWMWithHead,\n",
    "    \"gru\"                     : GRUWithHead,\n",
    "    \"RNN\"                     : RNNWithHead,\n",
    "    \"LSTM\"                    : LSTMWithHead,\n",
    "    \"Transformer\"             : TransformerWithHead,\n",
    "}\n",
    "\n",
    "# ──────────────────────────\n",
    "# Per-model constructor kwargs\n",
    "# ──────────────────────────\n",
    "MODEL_PARAMS = {\n",
    "    # ── LWM variants ─────────────────────────────\n",
    "    \"LWM_freeze_backbone\": {\n",
    "        \"input_dim\"       : INPUT_DIM,\n",
    "        \"patch_length\"    : PATCH_LENGTH,\n",
    "        \"d_model\"         : D_MODEL,\n",
    "        \"max_len\"         : PATCH_LENGTH + 1,\n",
    "        \"n_layers\"        : N_LAYERS,\n",
    "        \"hidden_dim\"      : HIDDEN_DIM,\n",
    "        \"out_dim\"         : OUT_DIM,\n",
    "        \"freeze_backbone\" : True,\n",
    "        \"checkpoint_path\" : \"./model_weights.pth\",\n",
    "        \"device\"          : DEVICE,\n",
    "    },\n",
    "    \"LWM_pretrained_Fine_tune\": {\n",
    "        \"input_dim\"       : INPUT_DIM,\n",
    "        \"patch_length\"    : PATCH_LENGTH,\n",
    "        \"d_model\"         : D_MODEL,\n",
    "        \"max_len\"         : PATCH_LENGTH + 1,\n",
    "        \"n_layers\"        : N_LAYERS,\n",
    "        \"hidden_dim\"      : HIDDEN_DIM,\n",
    "        \"out_dim\"         : OUT_DIM,\n",
    "        \"freeze_backbone\" : False,\n",
    "        \"checkpoint_path\" : \"./model_weights.pth\",\n",
    "        \"device\"          : DEVICE,\n",
    "    },\n",
    "    \"LWM_Fine_tune\": {\n",
    "        \"input_dim\"       : INPUT_DIM,\n",
    "        \"patch_length\"    : PATCH_LENGTH,\n",
    "        \"d_model\"         : D_MODEL,\n",
    "        \"max_len\"         : PATCH_LENGTH + 1,\n",
    "        \"n_layers\"        : N_LAYERS,\n",
    "        \"hidden_dim\"      : HIDDEN_DIM,\n",
    "        \"out_dim\"         : OUT_DIM,\n",
    "        \"freeze_backbone\" : False,\n",
    "        \"checkpoint_path\" : None,\n",
    "        \"device\"          : DEVICE,\n",
    "    },\n",
    "\n",
    "    # ── GRU (projected) ──────────────────────────\n",
    "    \"gru\": {\n",
    "        \"input_dim\"       : INPUT_DIM,     # 64 → project → 16\n",
    "        \"patch_length\"    : PATCH_LENGTH,\n",
    "        \"d_model\"         : D_MODEL,\n",
    "        \"n_layers\"        : N_LAYERS,\n",
    "        \"bidirectional\"   : BIDIRECTIONAL,\n",
    "        \"dropout\"         : DROPOUT,\n",
    "        \"hidden_dim\"      : HIDDEN_DIM,\n",
    "        \"out_dim\"         : OUT_DIM,\n",
    "        \"freeze_backbone\" : False,\n",
    "    },\n",
    "\n",
    "    # ── Vanilla RNN (projected) ──────────────────\n",
    "    \"RNN\": {\n",
    "        \"input_dim\"       : INPUT_DIM,\n",
    "        \"patch_length\"    : PATCH_LENGTH,\n",
    "        \"hidden_size\"     : D_MODEL,\n",
    "        \"num_layers\"      : N_LAYERS,\n",
    "        \"bidirectional\"   : BIDIRECTIONAL,\n",
    "        \"dropout\"         : 0.0,\n",
    "        \"hidden_dim\"      : HIDDEN_DIM,\n",
    "        \"out_dim\"         : OUT_DIM,\n",
    "        \"freeze_backbone\" : False,\n",
    "    },\n",
    "\n",
    "    # ── LSTM (projected) ─────────────────────────\n",
    "    \"LSTM\": {\n",
    "        \"input_dim\"       : INPUT_DIM,\n",
    "        \"patch_length\"    : PATCH_LENGTH,\n",
    "        \"hidden_size\"     : D_MODEL,\n",
    "        \"num_layers\"      : N_LAYERS,\n",
    "        \"bidirectional\"   : BIDIRECTIONAL,\n",
    "        \"dropout\"         : DROPOUT,\n",
    "        \"hidden_dim\"      : HIDDEN_DIM,\n",
    "        \"out_dim\"         : OUT_DIM,\n",
    "        \"freeze_backbone\" : False,\n",
    "    },\n",
    "\n",
    "    # ── Transformer (projected) ──────────────────\n",
    "    \"Transformer\": {\n",
    "        \"input_dim\"       : INPUT_DIM,\n",
    "        \"patch_length\"    : PATCH_LENGTH,\n",
    "        \"d_model\"         : D_MODEL,\n",
    "        \"n_heads\"         : 4,\n",
    "        \"dim_ff\"          : 256,\n",
    "        \"n_layers\"        : N_LAYERS,\n",
    "        \"dropout\"         : DROPOUT,\n",
    "        \"hidden_dim\"      : HIDDEN_DIM,\n",
    "        \"out_dim\"         : OUT_DIM,\n",
    "        \"max_len\"         : PATCH_LENGTH + 1,\n",
    "        \"freeze_backbone\" : False,\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c37de2-4bc1-42aa-9a9e-cfa43bf0c3fd",
   "metadata": {},
   "source": [
    "## model evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e9e706d-4875-4ee2-93d9-f792571fe2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def rmse(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Root-Mean-Squared Error\n",
    "    \"\"\"\n",
    "    return torch.sqrt(F.mse_loss(pred, target, reduction=\"mean\"))   # √MSE\n",
    "\n",
    "def nmse(pred: torch.Tensor, target: torch.Tensor, eps : float = 1e-12) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Normalized MSE  =  E[‖ŷ − y‖²] / E[‖y‖²]\n",
    "    \"\"\"\n",
    "    # (B, …) → (B,)  \n",
    "    mse_per_sample   = ((pred - target)**2).view(pred.size(0), -1).sum(dim=1)\n",
    "    power_per_sample = (target**2).view(target.size(0), -1).sum(dim=1) + eps\n",
    "    return (mse_per_sample / power_per_sample).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3930b75e-0895-4fb1-8039-744c86730b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_evaluate(model, loader, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Validation loop for IterableDataset.\n",
    "    Returns average RMSE and NMSE over all samples.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_rmse, total_nmse, total_samples = 0.0, 0.0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_ids, masked_pos, target in loader:\n",
    "            # Move to device\n",
    "            input_ids, masked_pos, target = (\n",
    "                input_ids.to(device),\n",
    "                masked_pos.to(device),\n",
    "                target.to(device),\n",
    "            )\n",
    "            # Batch size\n",
    "            bs = input_ids.size(0)\n",
    "\n",
    "            # Forward\n",
    "            pred = model(input_ids, masked_pos)\n",
    "\n",
    "            # Accumulate batch metrics\n",
    "            total_rmse    += rmse(pred, target).item() * bs\n",
    "            total_nmse    += nmse(pred, target).item() * bs\n",
    "            total_samples += bs\n",
    "\n",
    "    # Compute averages\n",
    "    return {\n",
    "        \"RMSE\": total_rmse / total_samples,\n",
    "        \"NMSE\": total_nmse / total_samples\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92d4ceda-b090-4b01-91a4-698c319420f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "def unmasked_evaluate(model, loader, device, patch_length=4):\n",
    "    \"\"\"\n",
    "    Validation loop for IterableDataset.\n",
    "    Computes and returns the average RMSE and NMSE over the dataset.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_rmse, total_nmse, total_samples = 0.0, 0.0, 0\n",
    "\n",
    "    # Inspect the model's forward signature to determine if it requires a decoder input\n",
    "    sig = inspect.signature(model.forward)\n",
    "    needs_tgt = len(sig.parameters) >= 3  # True if forward(self, src, tgt, ...) exists\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_ids, target in loader:\n",
    "            # Move input and target tensors to the specified device\n",
    "            input_ids = input_ids.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            if needs_tgt:\n",
    "                # Transformer models: use the last `patch_length` time steps as decoder input\n",
    "                tgt = input_ids[:, -patch_length:, :]\n",
    "                pred = model(input_ids, tgt)\n",
    "            else:\n",
    "                # Single-input models (e.g., GRU, LSTM): only the source sequence is needed\n",
    "                pred = model(input_ids)\n",
    "\n",
    "            # Accumulate weighted metrics\n",
    "            batch_size = input_ids.size(0)\n",
    "            total_rmse += rmse(pred, target).item() * batch_size\n",
    "            total_nmse += nmse(pred, target).item() * batch_size\n",
    "            total_samples += batch_size\n",
    "\n",
    "    # Calculate average RMSE and NMSE over all samples\n",
    "    avg_rmse = total_rmse / total_samples\n",
    "    avg_nmse = total_nmse / total_samples\n",
    "\n",
    "    return {\n",
    "        \"RMSE\": avg_rmse,\n",
    "        \"NMSE\": avg_nmse\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105c0dcd-d4af-4d7b-87cd-154d81d210fb",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "317fde92-dd4d-4092-b93c-7b1b83674c52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training LWM_freeze_backbone ===\n",
      "Model loaded successfully from ./model_weights.pth to cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01/30] TrainLoss: 0.0316  Val RMSE: 0.0949  Val NMSE: 4.7118e-02  Val NMSE_dB: -13.3 dB  TrainTime: 236.23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/30] TrainLoss: 0.0108  Val RMSE: 0.0942  Val NMSE: 4.6189e-02  Val NMSE_dB: -13.4 dB  TrainTime: 217.15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/30] TrainLoss: 0.0101  Val RMSE: 0.0930  Val NMSE: 4.3690e-02  Val NMSE_dB: -13.6 dB  TrainTime: 232.83s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04/30] TrainLoss: 0.0093  Val RMSE: 0.0924  Val NMSE: 4.1746e-02  Val NMSE_dB: -13.8 dB  TrainTime: 228.35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/30] TrainLoss: 0.0087  Val RMSE: 0.0924  Val NMSE: 4.0927e-02  Val NMSE_dB: -13.9 dB  TrainTime: 231.57s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06/30] TrainLoss: 0.0084  Val RMSE: 0.0921  Val NMSE: 4.0398e-02  Val NMSE_dB: -13.9 dB  TrainTime: 240.19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07/30] TrainLoss: 0.0082  Val RMSE: 0.0915  Val NMSE: 3.9804e-02  Val NMSE_dB: -14.0 dB  TrainTime: 234.40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08/30] TrainLoss: 0.0080  Val RMSE: 0.0910  Val NMSE: 3.9175e-02  Val NMSE_dB: -14.1 dB  TrainTime: 251.06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09/30] TrainLoss: 0.0078  Val RMSE: 0.0903  Val NMSE: 3.8429e-02  Val NMSE_dB: -14.2 dB  TrainTime: 224.22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/30] TrainLoss: 0.0076  Val RMSE: 0.0901  Val NMSE: 3.7909e-02  Val NMSE_dB: -14.2 dB  TrainTime: 229.82s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/30] TrainLoss: 0.0075  Val RMSE: 0.0900  Val NMSE: 3.7614e-02  Val NMSE_dB: -14.2 dB  TrainTime: 223.63s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/30] TrainLoss: 0.0073  Val RMSE: 0.0899  Val NMSE: 3.7353e-02  Val NMSE_dB: -14.3 dB  TrainTime: 246.60s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/30] TrainLoss: 0.0072  Val RMSE: 0.0897  Val NMSE: 3.7068e-02  Val NMSE_dB: -14.3 dB  TrainTime: 232.60s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/30] TrainLoss: 0.0071  Val RMSE: 0.0897  Val NMSE: 3.6838e-02  Val NMSE_dB: -14.3 dB  TrainTime: 220.74s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/30] TrainLoss: 0.0070  Val RMSE: 0.0894  Val NMSE: 3.6498e-02  Val NMSE_dB: -14.4 dB  TrainTime: 232.46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16/30] TrainLoss: 0.0069  Val RMSE: 0.0890  Val NMSE: 3.6089e-02  Val NMSE_dB: -14.4 dB  TrainTime: 236.10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/30] TrainLoss: 0.0068  Val RMSE: 0.0885  Val NMSE: 3.5587e-02  Val NMSE_dB: -14.5 dB  TrainTime: 239.27s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18/30] TrainLoss: 0.0067  Val RMSE: 0.0883  Val NMSE: 3.5285e-02  Val NMSE_dB: -14.5 dB  TrainTime: 221.25s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19/30] TrainLoss: 0.0066  Val RMSE: 0.0882  Val NMSE: 3.5013e-02  Val NMSE_dB: -14.6 dB  TrainTime: 233.71s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/30] TrainLoss: 0.0065  Val RMSE: 0.0879  Val NMSE: 3.4686e-02  Val NMSE_dB: -14.6 dB  TrainTime: 236.49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21/30] TrainLoss: 0.0064  Val RMSE: 0.0877  Val NMSE: 3.4471e-02  Val NMSE_dB: -14.6 dB  TrainTime: 242.30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22/30] TrainLoss: 0.0063  Val RMSE: 0.0877  Val NMSE: 3.4349e-02  Val NMSE_dB: -14.6 dB  TrainTime: 235.58s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23/30] TrainLoss: 0.0063  Val RMSE: 0.0877  Val NMSE: 3.4286e-02  Val NMSE_dB: -14.6 dB  TrainTime: 250.63s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24/30] TrainLoss: 0.0062  Val RMSE: 0.0877  Val NMSE: 3.4181e-02  Val NMSE_dB: -14.7 dB  TrainTime: 213.68s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25/30] TrainLoss: 0.0062  Val RMSE: 0.0876  Val NMSE: 3.4086e-02  Val NMSE_dB: -14.7 dB  TrainTime: 231.88s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26/30] TrainLoss: 0.0062  Val RMSE: 0.0879  Val NMSE: 3.4191e-02  Val NMSE_dB: -14.7 dB  TrainTime: 238.18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27/30] TrainLoss: 0.0061  Val RMSE: 0.0877  Val NMSE: 3.4050e-02  Val NMSE_dB: -14.7 dB  TrainTime: 227.94s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28/30] TrainLoss: 0.0061  Val RMSE: 0.0875  Val NMSE: 3.3911e-02  Val NMSE_dB: -14.7 dB  TrainTime: 244.06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29/30] TrainLoss: 0.0061  Val RMSE: 0.0877  Val NMSE: 3.3977e-02  Val NMSE_dB: -14.7 dB  TrainTime: 230.28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30/30] TrainLoss: 0.0061  Val RMSE: 0.0877  Val NMSE: 3.3902e-02  Val NMSE_dB: -14.7 dB  TrainTime: 203.04s\n",
      "🕒 LWM_freeze_backbone – avg train time / epoch: 232.21s\n",
      "\n",
      "=== Training LWM_pretrained_Fine_tune ===\n",
      "Model loaded successfully from ./model_weights.pth to cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01/30] TrainLoss: 0.0136  Val RMSE: 0.0892  Val NMSE: 3.7810e-02  Val NMSE_dB: -14.2 dB  TrainTime: 256.43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/30] TrainLoss: 0.0063  Val RMSE: 0.0822  Val NMSE: 3.0419e-02  Val NMSE_dB: -15.2 dB  TrainTime: 256.55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/30] TrainLoss: 0.0045  Val RMSE: 0.0795  Val NMSE: 2.7570e-02  Val NMSE_dB: -15.6 dB  TrainTime: 259.31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04/30] TrainLoss: 0.0038  Val RMSE: 0.0756  Val NMSE: 2.5193e-02  Val NMSE_dB: -16.0 dB  TrainTime: 244.37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/30] TrainLoss: 0.0034  Val RMSE: 0.0733  Val NMSE: 2.3482e-02  Val NMSE_dB: -16.3 dB  TrainTime: 266.02s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06/30] TrainLoss: 0.0031  Val RMSE: 0.0711  Val NMSE: 2.2169e-02  Val NMSE_dB: -16.5 dB  TrainTime: 263.23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07/30] TrainLoss: 0.0029  Val RMSE: 0.0700  Val NMSE: 2.1516e-02  Val NMSE_dB: -16.7 dB  TrainTime: 265.99s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08/30] TrainLoss: 0.0027  Val RMSE: 0.0692  Val NMSE: 2.1066e-02  Val NMSE_dB: -16.8 dB  TrainTime: 260.52s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09/30] TrainLoss: 0.0026  Val RMSE: 0.0694  Val NMSE: 2.0979e-02  Val NMSE_dB: -16.8 dB  TrainTime: 292.97s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/30] TrainLoss: 0.0025  Val RMSE: 0.0698  Val NMSE: 2.1146e-02  Val NMSE_dB: -16.7 dB  TrainTime: 284.70s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/30] TrainLoss: 0.0024  Val RMSE: 0.0701  Val NMSE: 2.1239e-02  Val NMSE_dB: -16.7 dB  TrainTime: 272.52s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/30] TrainLoss: 0.0023  Val RMSE: 0.0708  Val NMSE: 2.1583e-02  Val NMSE_dB: -16.7 dB  TrainTime: 272.80s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/30] TrainLoss: 0.0023  Val RMSE: 0.0708  Val NMSE: 2.1596e-02  Val NMSE_dB: -16.7 dB  TrainTime: 263.85s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/30] TrainLoss: 0.0023  Val RMSE: 0.0709  Val NMSE: 2.1691e-02  Val NMSE_dB: -16.6 dB  TrainTime: 308.32s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/30] TrainLoss: 0.0022  Val RMSE: 0.0709  Val NMSE: 2.1625e-02  Val NMSE_dB: -16.7 dB  TrainTime: 279.18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16/30] TrainLoss: 0.0022  Val RMSE: 0.0706  Val NMSE: 2.1512e-02  Val NMSE_dB: -16.7 dB  TrainTime: 291.10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/30] TrainLoss: 0.0022  Val RMSE: 0.0706  Val NMSE: 2.1503e-02  Val NMSE_dB: -16.7 dB  TrainTime: 278.09s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18/30] TrainLoss: 0.0021  Val RMSE: 0.0705  Val NMSE: 2.1427e-02  Val NMSE_dB: -16.7 dB  TrainTime: 280.26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19/30] TrainLoss: 0.0021  Val RMSE: 0.0706  Val NMSE: 2.1418e-02  Val NMSE_dB: -16.7 dB  TrainTime: 281.71s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/30] TrainLoss: 0.0021  Val RMSE: 0.0705  Val NMSE: 2.1363e-02  Val NMSE_dB: -16.7 dB  TrainTime: 296.17s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21/30] TrainLoss: 0.0020  Val RMSE: 0.0708  Val NMSE: 2.1482e-02  Val NMSE_dB: -16.7 dB  TrainTime: 289.94s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22/30] TrainLoss: 0.0020  Val RMSE: 0.0699  Val NMSE: 2.1014e-02  Val NMSE_dB: -16.8 dB  TrainTime: 300.48s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23/30] TrainLoss: 0.0020  Val RMSE: 0.0695  Val NMSE: 2.0783e-02  Val NMSE_dB: -16.8 dB  TrainTime: 300.86s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24/30] TrainLoss: 0.0020  Val RMSE: 0.0693  Val NMSE: 2.0709e-02  Val NMSE_dB: -16.8 dB  TrainTime: 294.62s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25/30] TrainLoss: 0.0019  Val RMSE: 0.0691  Val NMSE: 2.0563e-02  Val NMSE_dB: -16.9 dB  TrainTime: 282.29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26/30] TrainLoss: 0.0019  Val RMSE: 0.0686  Val NMSE: 2.0342e-02  Val NMSE_dB: -16.9 dB  TrainTime: 301.50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27/30] TrainLoss: 0.0019  Val RMSE: 0.0684  Val NMSE: 2.0250e-02  Val NMSE_dB: -16.9 dB  TrainTime: 284.83s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28/30] TrainLoss: 0.0019  Val RMSE: 0.0679  Val NMSE: 1.9928e-02  Val NMSE_dB: -17.0 dB  TrainTime: 297.01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29/30] TrainLoss: 0.0019  Val RMSE: 0.0680  Val NMSE: 2.0049e-02  Val NMSE_dB: -17.0 dB  TrainTime: 284.04s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30/30] TrainLoss: 0.0018  Val RMSE: 0.0681  Val NMSE: 2.0069e-02  Val NMSE_dB: -17.0 dB  TrainTime: 295.26s\n",
      "🕒 LWM_pretrained_Fine_tune – avg train time / epoch: 280.16s\n",
      "\n",
      "=== Training LWM_Fine_tune ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01/30] TrainLoss: 0.0127  Val RMSE: 0.0882  Val NMSE: 3.2970e-02  Val NMSE_dB: -14.8 dB  TrainTime: 302.90s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/30] TrainLoss: 0.0049  Val RMSE: 0.0855  Val NMSE: 3.0469e-02  Val NMSE_dB: -15.2 dB  TrainTime: 284.49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/30] TrainLoss: 0.0038  Val RMSE: 0.0809  Val NMSE: 2.7534e-02  Val NMSE_dB: -15.6 dB  TrainTime: 294.50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04/30] TrainLoss: 0.0033  Val RMSE: 0.0785  Val NMSE: 2.5968e-02  Val NMSE_dB: -15.9 dB  TrainTime: 289.67s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/30] TrainLoss: 0.0030  Val RMSE: 0.0774  Val NMSE: 2.5300e-02  Val NMSE_dB: -16.0 dB  TrainTime: 313.31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06/30] TrainLoss: 0.0028  Val RMSE: 0.0761  Val NMSE: 2.4591e-02  Val NMSE_dB: -16.1 dB  TrainTime: 302.61s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07/30] TrainLoss: 0.0027  Val RMSE: 0.0747  Val NMSE: 2.3864e-02  Val NMSE_dB: -16.2 dB  TrainTime: 317.47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08/30] TrainLoss: 0.0026  Val RMSE: 0.0741  Val NMSE: 2.3512e-02  Val NMSE_dB: -16.3 dB  TrainTime: 310.15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09/30] TrainLoss: 0.0025  Val RMSE: 0.0728  Val NMSE: 2.2799e-02  Val NMSE_dB: -16.4 dB  TrainTime: 295.21s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/30] TrainLoss: 0.0024  Val RMSE: 0.0728  Val NMSE: 2.2766e-02  Val NMSE_dB: -16.4 dB  TrainTime: 307.69s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/30] TrainLoss: 0.0024  Val RMSE: 0.0719  Val NMSE: 2.2275e-02  Val NMSE_dB: -16.5 dB  TrainTime: 278.94s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/30] TrainLoss: 0.0023  Val RMSE: 0.0713  Val NMSE: 2.1861e-02  Val NMSE_dB: -16.6 dB  TrainTime: 311.29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/30] TrainLoss: 0.0023  Val RMSE: 0.0716  Val NMSE: 2.2031e-02  Val NMSE_dB: -16.6 dB  TrainTime: 298.65s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/30] TrainLoss: 0.0022  Val RMSE: 0.0711  Val NMSE: 2.1744e-02  Val NMSE_dB: -16.6 dB  TrainTime: 308.63s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/30] TrainLoss: 0.0022  Val RMSE: 0.0708  Val NMSE: 2.1606e-02  Val NMSE_dB: -16.7 dB  TrainTime: 325.99s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16/30] TrainLoss: 0.0022  Val RMSE: 0.0706  Val NMSE: 2.1511e-02  Val NMSE_dB: -16.7 dB  TrainTime: 311.37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/30] TrainLoss: 0.0021  Val RMSE: 0.0703  Val NMSE: 2.1337e-02  Val NMSE_dB: -16.7 dB  TrainTime: 290.10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18/30] TrainLoss: 0.0021  Val RMSE: 0.0698  Val NMSE: 2.1100e-02  Val NMSE_dB: -16.8 dB  TrainTime: 323.40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19/30] TrainLoss: 0.0020  Val RMSE: 0.0700  Val NMSE: 2.1153e-02  Val NMSE_dB: -16.7 dB  TrainTime: 313.52s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/30] TrainLoss: 0.0020  Val RMSE: 0.0696  Val NMSE: 2.0924e-02  Val NMSE_dB: -16.8 dB  TrainTime: 316.52s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21/30] TrainLoss: 0.0020  Val RMSE: 0.0694  Val NMSE: 2.0833e-02  Val NMSE_dB: -16.8 dB  TrainTime: 323.29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22/30] TrainLoss: 0.0019  Val RMSE: 0.0695  Val NMSE: 2.0902e-02  Val NMSE_dB: -16.8 dB  TrainTime: 292.67s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23/30] TrainLoss: 0.0019  Val RMSE: 0.0691  Val NMSE: 2.0681e-02  Val NMSE_dB: -16.8 dB  TrainTime: 296.25s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24/30] TrainLoss: 0.0019  Val RMSE: 0.0696  Val NMSE: 2.0920e-02  Val NMSE_dB: -16.8 dB  TrainTime: 311.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25/30] TrainLoss: 0.0018  Val RMSE: 0.0702  Val NMSE: 2.1239e-02  Val NMSE_dB: -16.7 dB  TrainTime: 308.22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26/30] TrainLoss: 0.0018  Val RMSE: 0.0696  Val NMSE: 2.0960e-02  Val NMSE_dB: -16.8 dB  TrainTime: 289.40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27/30] TrainLoss: 0.0017  Val RMSE: 0.0694  Val NMSE: 2.0828e-02  Val NMSE_dB: -16.8 dB  TrainTime: 303.59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28/30] TrainLoss: 0.0017  Val RMSE: 0.0694  Val NMSE: 2.0846e-02  Val NMSE_dB: -16.8 dB  TrainTime: 280.65s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29/30] TrainLoss: 0.0017  Val RMSE: 0.0698  Val NMSE: 2.1043e-02  Val NMSE_dB: -16.8 dB  TrainTime: 309.39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30/30] TrainLoss: 0.0016  Val RMSE: 0.0695  Val NMSE: 2.0870e-02  Val NMSE_dB: -16.8 dB  TrainTime: 304.45s\n",
      "🕒 LWM_Fine_tune – avg train time / epoch: 303.84s\n",
      "\n",
      "=== Training gru ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01/30] TrainLoss: 0.0132  Val RMSE: 0.0947  Val NMSE: 4.3859e-02  Val NMSE_dB: -13.6 dB  TrainTime: 127.85s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/30] TrainLoss: 0.0086  Val RMSE: 0.0946  Val NMSE: 3.9603e-02  Val NMSE_dB: -14.0 dB  TrainTime: 140.34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/30] TrainLoss: 0.0065  Val RMSE: 0.0872  Val NMSE: 3.3195e-02  Val NMSE_dB: -14.8 dB  TrainTime: 115.47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04/30] TrainLoss: 0.0050  Val RMSE: 0.0853  Val NMSE: 3.0914e-02  Val NMSE_dB: -15.1 dB  TrainTime: 111.16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/30] TrainLoss: 0.0043  Val RMSE: 0.0814  Val NMSE: 2.8461e-02  Val NMSE_dB: -15.5 dB  TrainTime: 101.71s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06/30] TrainLoss: 0.0038  Val RMSE: 0.0783  Val NMSE: 2.6523e-02  Val NMSE_dB: -15.8 dB  TrainTime: 118.46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07/30] TrainLoss: 0.0036  Val RMSE: 0.0773  Val NMSE: 2.5783e-02  Val NMSE_dB: -15.9 dB  TrainTime: 126.21s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08/30] TrainLoss: 0.0035  Val RMSE: 0.0760  Val NMSE: 2.4938e-02  Val NMSE_dB: -16.0 dB  TrainTime: 115.51s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09/30] TrainLoss: 0.0033  Val RMSE: 0.0752  Val NMSE: 2.4321e-02  Val NMSE_dB: -16.1 dB  TrainTime: 118.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/30] TrainLoss: 0.0031  Val RMSE: 0.0752  Val NMSE: 2.4169e-02  Val NMSE_dB: -16.2 dB  TrainTime: 111.55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/30] TrainLoss: 0.0030  Val RMSE: 0.0731  Val NMSE: 2.3168e-02  Val NMSE_dB: -16.4 dB  TrainTime: 127.22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/30] TrainLoss: 0.0029  Val RMSE: 0.0718  Val NMSE: 2.2507e-02  Val NMSE_dB: -16.5 dB  TrainTime: 116.23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/30] TrainLoss: 0.0029  Val RMSE: 0.0707  Val NMSE: 2.2131e-02  Val NMSE_dB: -16.5 dB  TrainTime: 136.11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/30] TrainLoss: 0.0028  Val RMSE: 0.0705  Val NMSE: 2.2147e-02  Val NMSE_dB: -16.5 dB  TrainTime: 122.17s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/30] TrainLoss: 0.0027  Val RMSE: 0.0705  Val NMSE: 2.2018e-02  Val NMSE_dB: -16.6 dB  TrainTime: 119.86s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16/30] TrainLoss: 0.0027  Val RMSE: 0.0704  Val NMSE: 2.2049e-02  Val NMSE_dB: -16.6 dB  TrainTime: 115.21s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/30] TrainLoss: 0.0027  Val RMSE: 0.0701  Val NMSE: 2.1976e-02  Val NMSE_dB: -16.6 dB  TrainTime: 115.95s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18/30] TrainLoss: 0.0026  Val RMSE: 0.0698  Val NMSE: 2.1723e-02  Val NMSE_dB: -16.6 dB  TrainTime: 121.77s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19/30] TrainLoss: 0.0026  Val RMSE: 0.0700  Val NMSE: 2.1783e-02  Val NMSE_dB: -16.6 dB  TrainTime: 119.88s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/30] TrainLoss: 0.0026  Val RMSE: 0.0699  Val NMSE: 2.1863e-02  Val NMSE_dB: -16.6 dB  TrainTime: 106.96s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21/30] TrainLoss: 0.0025  Val RMSE: 0.0693  Val NMSE: 2.1299e-02  Val NMSE_dB: -16.7 dB  TrainTime: 120.39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22/30] TrainLoss: 0.0025  Val RMSE: 0.0700  Val NMSE: 2.2024e-02  Val NMSE_dB: -16.6 dB  TrainTime: 129.21s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23/30] TrainLoss: 0.0025  Val RMSE: 0.0694  Val NMSE: 2.1415e-02  Val NMSE_dB: -16.7 dB  TrainTime: 118.87s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24/30] TrainLoss: 0.0025  Val RMSE: 0.0685  Val NMSE: 2.0826e-02  Val NMSE_dB: -16.8 dB  TrainTime: 116.10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25/30] TrainLoss: 0.0024  Val RMSE: 0.0675  Val NMSE: 2.0173e-02  Val NMSE_dB: -17.0 dB  TrainTime: 108.10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26/30] TrainLoss: 0.0024  Val RMSE: 0.0683  Val NMSE: 2.0865e-02  Val NMSE_dB: -16.8 dB  TrainTime: 117.75s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27/30] TrainLoss: 0.0024  Val RMSE: 0.0681  Val NMSE: 2.0706e-02  Val NMSE_dB: -16.8 dB  TrainTime: 115.41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28/30] TrainLoss: 0.0024  Val RMSE: 0.0669  Val NMSE: 1.9777e-02  Val NMSE_dB: -17.0 dB  TrainTime: 120.36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29/30] TrainLoss: 0.0024  Val RMSE: 0.0676  Val NMSE: 2.0295e-02  Val NMSE_dB: -16.9 dB  TrainTime: 107.55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30/30] TrainLoss: 0.0023  Val RMSE: 0.0679  Val NMSE: 2.0591e-02  Val NMSE_dB: -16.9 dB  TrainTime: 116.84s\n",
      "🕒 gru – avg train time / epoch: 118.61s\n",
      "\n",
      "=== Training RNN ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01/30] TrainLoss: 0.0082  Val RMSE: 0.0936  Val NMSE: 3.5454e-02  Val NMSE_dB: -14.5 dB  TrainTime: 98.21s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/30] TrainLoss: 0.0036  Val RMSE: 0.0866  Val NMSE: 3.0391e-02  Val NMSE_dB: -15.2 dB  TrainTime: 104.63s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/30] TrainLoss: 0.0030  Val RMSE: 0.0857  Val NMSE: 2.9636e-02  Val NMSE_dB: -15.3 dB  TrainTime: 105.60s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04/30] TrainLoss: 0.0028  Val RMSE: 0.0828  Val NMSE: 2.7922e-02  Val NMSE_dB: -15.5 dB  TrainTime: 106.15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/30] TrainLoss: 0.0027  Val RMSE: 0.0793  Val NMSE: 2.5947e-02  Val NMSE_dB: -15.9 dB  TrainTime: 93.59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06/30] TrainLoss: 0.0026  Val RMSE: 0.0774  Val NMSE: 2.4903e-02  Val NMSE_dB: -16.0 dB  TrainTime: 100.40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07/30] TrainLoss: 0.0025  Val RMSE: 0.0767  Val NMSE: 2.4524e-02  Val NMSE_dB: -16.1 dB  TrainTime: 104.22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08/30] TrainLoss: 0.0024  Val RMSE: 0.0766  Val NMSE: 2.4452e-02  Val NMSE_dB: -16.1 dB  TrainTime: 95.27s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09/30] TrainLoss: 0.0024  Val RMSE: 0.0770  Val NMSE: 2.4653e-02  Val NMSE_dB: -16.1 dB  TrainTime: 95.78s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/30] TrainLoss: 0.0023  Val RMSE: 0.0779  Val NMSE: 2.5080e-02  Val NMSE_dB: -16.0 dB  TrainTime: 97.16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/30] TrainLoss: 0.0023  Val RMSE: 0.0790  Val NMSE: 2.5633e-02  Val NMSE_dB: -15.9 dB  TrainTime: 98.90s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/30] TrainLoss: 0.0022  Val RMSE: 0.0800  Val NMSE: 2.6169e-02  Val NMSE_dB: -15.8 dB  TrainTime: 96.45s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/30] TrainLoss: 0.0022  Val RMSE: 0.0811  Val NMSE: 2.6763e-02  Val NMSE_dB: -15.7 dB  TrainTime: 93.44s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/30] TrainLoss: 0.0021  Val RMSE: 0.0822  Val NMSE: 2.7382e-02  Val NMSE_dB: -15.6 dB  TrainTime: 96.89s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/30] TrainLoss: 0.0021  Val RMSE: 0.0834  Val NMSE: 2.8048e-02  Val NMSE_dB: -15.5 dB  TrainTime: 97.01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16/30] TrainLoss: 0.0020  Val RMSE: 0.0846  Val NMSE: 2.8732e-02  Val NMSE_dB: -15.4 dB  TrainTime: 88.67s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/30] TrainLoss: 0.0020  Val RMSE: 0.0855  Val NMSE: 2.9267e-02  Val NMSE_dB: -15.3 dB  TrainTime: 113.19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18/30] TrainLoss: 0.0019  Val RMSE: 0.0860  Val NMSE: 2.9560e-02  Val NMSE_dB: -15.3 dB  TrainTime: 99.98s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19/30] TrainLoss: 0.0019  Val RMSE: 0.0861  Val NMSE: 2.9652e-02  Val NMSE_dB: -15.3 dB  TrainTime: 98.98s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/30] TrainLoss: 0.0018  Val RMSE: 0.0860  Val NMSE: 2.9576e-02  Val NMSE_dB: -15.3 dB  TrainTime: 101.07s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21/30] TrainLoss: 0.0018  Val RMSE: 0.0856  Val NMSE: 2.9314e-02  Val NMSE_dB: -15.3 dB  TrainTime: 104.36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22/30] TrainLoss: 0.0018  Val RMSE: 0.0850  Val NMSE: 2.8956e-02  Val NMSE_dB: -15.4 dB  TrainTime: 98.12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23/30] TrainLoss: 0.0017  Val RMSE: 0.0844  Val NMSE: 2.8628e-02  Val NMSE_dB: -15.4 dB  TrainTime: 98.81s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24/30] TrainLoss: 0.0017  Val RMSE: 0.0839  Val NMSE: 2.8269e-02  Val NMSE_dB: -15.5 dB  TrainTime: 96.46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25/30] TrainLoss: 0.0016  Val RMSE: 0.0831  Val NMSE: 2.7791e-02  Val NMSE_dB: -15.6 dB  TrainTime: 93.81s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26/30] TrainLoss: 0.0016  Val RMSE: 0.0821  Val NMSE: 2.7170e-02  Val NMSE_dB: -15.7 dB  TrainTime: 90.65s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27/30] TrainLoss: 0.0016  Val RMSE: 0.0808  Val NMSE: 2.6423e-02  Val NMSE_dB: -15.8 dB  TrainTime: 91.92s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28/30] TrainLoss: 0.0015  Val RMSE: 0.0795  Val NMSE: 2.5709e-02  Val NMSE_dB: -15.9 dB  TrainTime: 109.50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29/30] TrainLoss: 0.0015  Val RMSE: 0.0787  Val NMSE: 2.5253e-02  Val NMSE_dB: -16.0 dB  TrainTime: 93.87s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30/30] TrainLoss: 0.0015  Val RMSE: 0.0791  Val NMSE: 2.5488e-02  Val NMSE_dB: -15.9 dB  TrainTime: 99.62s\n",
      "🕒 RNN – avg train time / epoch: 98.76s\n",
      "\n",
      "=== Training LSTM ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01/30] TrainLoss: 0.0143  Val RMSE: 0.0962  Val NMSE: 4.5004e-02  Val NMSE_dB: -13.5 dB  TrainTime: 122.36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/30] TrainLoss: 0.0098  Val RMSE: 0.0962  Val NMSE: 4.4907e-02  Val NMSE_dB: -13.5 dB  TrainTime: 121.15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/30] TrainLoss: 0.0095  Val RMSE: 0.0932  Val NMSE: 4.2624e-02  Val NMSE_dB: -13.7 dB  TrainTime: 120.69s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04/30] TrainLoss: 0.0090  Val RMSE: 0.0901  Val NMSE: 4.1472e-02  Val NMSE_dB: -13.8 dB  TrainTime: 122.33s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/30] TrainLoss: 0.0086  Val RMSE: 0.0921  Val NMSE: 4.2339e-02  Val NMSE_dB: -13.7 dB  TrainTime: 130.19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06/30] TrainLoss: 0.0082  Val RMSE: 0.0917  Val NMSE: 3.8993e-02  Val NMSE_dB: -14.1 dB  TrainTime: 120.13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07/30] TrainLoss: 0.0078  Val RMSE: 0.0898  Val NMSE: 3.7545e-02  Val NMSE_dB: -14.3 dB  TrainTime: 119.79s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08/30] TrainLoss: 0.0076  Val RMSE: 0.0914  Val NMSE: 3.8012e-02  Val NMSE_dB: -14.2 dB  TrainTime: 113.73s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09/30] TrainLoss: 0.0073  Val RMSE: 0.0894  Val NMSE: 3.7084e-02  Val NMSE_dB: -14.3 dB  TrainTime: 117.27s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/30] TrainLoss: 0.0071  Val RMSE: 0.0842  Val NMSE: 3.4583e-02  Val NMSE_dB: -14.6 dB  TrainTime: 112.31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/30] TrainLoss: 0.0069  Val RMSE: 0.0882  Val NMSE: 3.6982e-02  Val NMSE_dB: -14.3 dB  TrainTime: 120.65s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/30] TrainLoss: 0.0067  Val RMSE: 0.0836  Val NMSE: 3.3353e-02  Val NMSE_dB: -14.8 dB  TrainTime: 118.31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/30] TrainLoss: 0.0065  Val RMSE: 0.0833  Val NMSE: 3.2735e-02  Val NMSE_dB: -14.8 dB  TrainTime: 122.12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/30] TrainLoss: 0.0064  Val RMSE: 0.0823  Val NMSE: 3.1990e-02  Val NMSE_dB: -14.9 dB  TrainTime: 118.81s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/30] TrainLoss: 0.0062  Val RMSE: 0.0826  Val NMSE: 3.2249e-02  Val NMSE_dB: -14.9 dB  TrainTime: 107.02s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16/30] TrainLoss: 0.0060  Val RMSE: 0.0816  Val NMSE: 3.1143e-02  Val NMSE_dB: -15.1 dB  TrainTime: 119.21s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/30] TrainLoss: 0.0058  Val RMSE: 0.0829  Val NMSE: 3.1250e-02  Val NMSE_dB: -15.1 dB  TrainTime: 118.56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18/30] TrainLoss: 0.0050  Val RMSE: 0.0837  Val NMSE: 3.0459e-02  Val NMSE_dB: -15.2 dB  TrainTime: 124.22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19/30] TrainLoss: 0.0047  Val RMSE: 0.0880  Val NMSE: 3.2649e-02  Val NMSE_dB: -14.9 dB  TrainTime: 117.65s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/30] TrainLoss: 0.0046  Val RMSE: 0.0874  Val NMSE: 3.2381e-02  Val NMSE_dB: -14.9 dB  TrainTime: 109.83s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21/30] TrainLoss: 0.0044  Val RMSE: 0.0874  Val NMSE: 3.2514e-02  Val NMSE_dB: -14.9 dB  TrainTime: 122.36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22/30] TrainLoss: 0.0044  Val RMSE: 0.0869  Val NMSE: 3.2210e-02  Val NMSE_dB: -14.9 dB  TrainTime: 122.47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23/30] TrainLoss: 0.0043  Val RMSE: 0.0872  Val NMSE: 3.2379e-02  Val NMSE_dB: -14.9 dB  TrainTime: 122.66s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24/30] TrainLoss: 0.0042  Val RMSE: 0.0868  Val NMSE: 3.1584e-02  Val NMSE_dB: -15.0 dB  TrainTime: 110.36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25/30] TrainLoss: 0.0041  Val RMSE: 0.0871  Val NMSE: 3.1679e-02  Val NMSE_dB: -15.0 dB  TrainTime: 105.58s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26/30] TrainLoss: 0.0040  Val RMSE: 0.0877  Val NMSE: 3.1734e-02  Val NMSE_dB: -15.0 dB  TrainTime: 117.71s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27/30] TrainLoss: 0.0038  Val RMSE: 0.0852  Val NMSE: 2.9890e-02  Val NMSE_dB: -15.2 dB  TrainTime: 127.73s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28/30] TrainLoss: 0.0036  Val RMSE: 0.0838  Val NMSE: 2.9041e-02  Val NMSE_dB: -15.4 dB  TrainTime: 125.46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29/30] TrainLoss: 0.0035  Val RMSE: 0.0801  Val NMSE: 2.6937e-02  Val NMSE_dB: -15.7 dB  TrainTime: 112.72s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30/30] TrainLoss: 0.0034  Val RMSE: 0.0792  Val NMSE: 2.6461e-02  Val NMSE_dB: -15.8 dB  TrainTime: 118.95s\n",
      "🕒 LSTM – avg train time / epoch: 118.74s\n",
      "\n",
      "=== Training Transformer ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01/30] TrainLoss: 0.0141  Val RMSE: 0.0843  Val NMSE: 3.3780e-02  Val NMSE_dB: -14.7 dB  TrainTime: 523.69s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02/30] TrainLoss: 0.0062  Val RMSE: 0.0801  Val NMSE: 2.8289e-02  Val NMSE_dB: -15.5 dB  TrainTime: 495.02s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03/30] TrainLoss: 0.0042  Val RMSE: 0.0751  Val NMSE: 2.5050e-02  Val NMSE_dB: -16.0 dB  TrainTime: 500.25s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04/30] TrainLoss: 0.0035  Val RMSE: 0.0751  Val NMSE: 2.4848e-02  Val NMSE_dB: -16.0 dB  TrainTime: 505.03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/30] TrainLoss: 0.0033  Val RMSE: 0.0685  Val NMSE: 2.1346e-02  Val NMSE_dB: -16.7 dB  TrainTime: 505.59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06/30] TrainLoss: 0.0030  Val RMSE: 0.0696  Val NMSE: 2.2047e-02  Val NMSE_dB: -16.6 dB  TrainTime: 502.32s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07/30] TrainLoss: 0.0028  Val RMSE: 0.0703  Val NMSE: 2.1871e-02  Val NMSE_dB: -16.6 dB  TrainTime: 500.30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08/30] TrainLoss: 0.0027  Val RMSE: 0.0724  Val NMSE: 2.2922e-02  Val NMSE_dB: -16.4 dB  TrainTime: 518.10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09/30] TrainLoss: 0.0026  Val RMSE: 0.0725  Val NMSE: 2.2748e-02  Val NMSE_dB: -16.4 dB  TrainTime: 506.76s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/30] TrainLoss: 0.0025  Val RMSE: 0.0718  Val NMSE: 2.2558e-02  Val NMSE_dB: -16.5 dB  TrainTime: 515.78s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/30] TrainLoss: 0.0024  Val RMSE: 0.0728  Val NMSE: 2.2881e-02  Val NMSE_dB: -16.4 dB  TrainTime: 517.65s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/30] TrainLoss: 0.0023  Val RMSE: 0.0709  Val NMSE: 2.1779e-02  Val NMSE_dB: -16.6 dB  TrainTime: 511.81s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/30] TrainLoss: 0.0022  Val RMSE: 0.0723  Val NMSE: 2.2343e-02  Val NMSE_dB: -16.5 dB  TrainTime: 495.60s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/30] TrainLoss: 0.0022  Val RMSE: 0.0724  Val NMSE: 2.2567e-02  Val NMSE_dB: -16.5 dB  TrainTime: 505.78s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/30] TrainLoss: 0.0021  Val RMSE: 0.0703  Val NMSE: 2.1391e-02  Val NMSE_dB: -16.7 dB  TrainTime: 516.79s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16/30] TrainLoss: 0.0021  Val RMSE: 0.0727  Val NMSE: 2.2628e-02  Val NMSE_dB: -16.5 dB  TrainTime: 542.24s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/30] TrainLoss: 0.0020  Val RMSE: 0.0700  Val NMSE: 2.1276e-02  Val NMSE_dB: -16.7 dB  TrainTime: 543.55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18/30] TrainLoss: 0.0020  Val RMSE: 0.0765  Val NMSE: 2.4510e-02  Val NMSE_dB: -16.1 dB  TrainTime: 527.80s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19/30] TrainLoss: 0.0019  Val RMSE: 0.0745  Val NMSE: 2.3472e-02  Val NMSE_dB: -16.3 dB  TrainTime: 535.83s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/30] TrainLoss: 0.0019  Val RMSE: 0.0747  Val NMSE: 2.3574e-02  Val NMSE_dB: -16.3 dB  TrainTime: 522.30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21/30] TrainLoss: 0.0019  Val RMSE: 0.0728  Val NMSE: 2.2404e-02  Val NMSE_dB: -16.5 dB  TrainTime: 487.03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22/30] TrainLoss: 0.0018  Val RMSE: 0.0733  Val NMSE: 2.2605e-02  Val NMSE_dB: -16.5 dB  TrainTime: 493.28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23/30] TrainLoss: 0.0018  Val RMSE: 0.0762  Val NMSE: 2.4082e-02  Val NMSE_dB: -16.2 dB  TrainTime: 484.06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24/30] TrainLoss: 0.0018  Val RMSE: 0.0782  Val NMSE: 2.5347e-02  Val NMSE_dB: -16.0 dB  TrainTime: 498.78s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25/30] TrainLoss: 0.0017  Val RMSE: 0.0824  Val NMSE: 2.7519e-02  Val NMSE_dB: -15.6 dB  TrainTime: 524.40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26/30] TrainLoss: 0.0017  Val RMSE: 0.0883  Val NMSE: 3.1099e-02  Val NMSE_dB: -15.1 dB  TrainTime: 489.90s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27/30] TrainLoss: 0.0017  Val RMSE: 0.0913  Val NMSE: 3.3079e-02  Val NMSE_dB: -14.8 dB  TrainTime: 497.36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28/30] TrainLoss: 0.0016  Val RMSE: 0.0833  Val NMSE: 2.7951e-02  Val NMSE_dB: -15.5 dB  TrainTime: 480.64s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29/30] TrainLoss: 0.0016  Val RMSE: 0.0898  Val NMSE: 3.2007e-02  Val NMSE_dB: -14.9 dB  TrainTime: 486.24s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30/30] TrainLoss: 0.0016  Val RMSE: 0.0921  Val NMSE: 3.3450e-02  Val NMSE_dB: -14.8 dB  TrainTime: 483.60s\n",
      "🕒 Transformer – avg train time / epoch: 507.25s\n",
      "\n",
      "=== Summary of best NMSE(dB) by model ===\n",
      "LWM_freeze_backbone      : -14.697749167793155\n",
      "LWM_pretrained_Fine_tune : -17.00533373768508\n",
      "LWM_Fine_tune            : -16.844334623282737\n",
      "gru                      : -17.038366743906938\n",
      "RNN                      : -16.11680499085308\n",
      "LSTM                     : -15.773973732054197\n",
      "Transformer              : -16.721100055124612\n",
      "\n",
      "Total training time for all models: 55973.64s\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Unified training / validation script\n",
    "------------------------------------\n",
    "* Trains every architecture listed in MODEL_CATALOG\n",
    "* Chooses masked / un-masked DataLoader automatically\n",
    "* Reports per-epoch speed & validation scores\n",
    "* Saves **best** and **last** checkpoints under ./checkpoints/\n",
    "\"\"\"\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# 0) Globals and hyper-parameters\n",
    "# ─────────────────────────────────────────────\n",
    "device      = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion   = nn.MSELoss().to(device)\n",
    "\n",
    "NUM_EPOCHS  = 30\n",
    "LR          = 1e-4                         # learning-rate\n",
    "CKPT_DIR    = Path(\"checkpoints\")          # where *.pth files will be stored\n",
    "CKPT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "total_start = time.time()                  # wall-clock timer for *all* models\n",
    "results     = {}                           # best-epoch NMSE(dB) for every model\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# 1) Train / validate each model\n",
    "# ─────────────────────────────────────────────\n",
    "for model_name, ModelCls in MODEL_CATALOG.items():\n",
    "\n",
    "    print(f\"\\n=== Training {model_name} ===\")\n",
    "    model_args = MODEL_PARAMS[model_name]\n",
    "    model      = ModelCls(**model_args).to(device)\n",
    "\n",
    "    # collect only trainable parameters\n",
    "    trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "    if len(trainable_params) == 0:\n",
    "        print(f\"⚠️  '{model_name}' has no trainable parameters — skipping.\")\n",
    "        results[model_name] = float(\"nan\")\n",
    "        continue\n",
    "\n",
    "    optimizer   = torch.optim.Adam(trainable_params, lr=LR)\n",
    "    epoch_times = []                       # per-epoch training duration\n",
    "    best_nmse   = float(\"inf\")             # track the best val-NMSE\n",
    "\n",
    "    # pick loaders / evaluation fn based on model family\n",
    "    uses_mask  = model_name.startswith(\"LWM_\") \n",
    "    tr_loader  = masked_train_loader if uses_mask else unmasked_train_loader\n",
    "    val_loader = masked_val_loader  if uses_mask else unmasked_val_loader\n",
    "    eval_fn    = masked_evaluate    if uses_mask else unmasked_evaluate\n",
    "\n",
    "    # ── EPOCH LOOP ──────────────────────────\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "\n",
    "        # ---------- TRAIN ----------\n",
    "        t0 = time.time()\n",
    "        model.train()\n",
    "        run_loss = 0.0\n",
    "\n",
    "        pbar = tqdm(tr_loader,\n",
    "                    desc=f\"[{model_name} {epoch:02d}/{NUM_EPOCHS}] train\",\n",
    "                    leave=False)\n",
    "\n",
    "        for b, batch in enumerate(pbar, 1):\n",
    "            if uses_mask:\n",
    "                xb, mpos, yb = [x.to(device) for x in batch]\n",
    "                pred = model(xb, mpos).squeeze(-1)\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                xb, yb = [x.to(device) for x in batch]\n",
    "                if model_name == \"Transformer\":\n",
    "                    tgt = xb[:,4:,:]\n",
    "                    pred = model(xb, tgt)\n",
    "                else:\n",
    "                    pred   = model(xb)\n",
    "                    \n",
    "                    \n",
    "\n",
    "            loss = criterion(pred, yb)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            run_loss += loss.item()\n",
    "            if b % 100 == 0:\n",
    "                pbar.set_postfix(train_loss=run_loss / b)\n",
    "\n",
    "        epoch_times.append(time.time() - t0)\n",
    "        avg_train_loss = run_loss / b\n",
    "\n",
    "        # ---------- VALID ----------\n",
    "        metrics   = eval_fn(model, val_loader, device)\n",
    "        val_rmse  = metrics[\"RMSE\"]\n",
    "        val_nmse  = metrics[\"NMSE\"]\n",
    "        val_nmse_db = 10 * torch.log10(torch.tensor(val_nmse)).item()\n",
    "\n",
    "        # save best checkpoint\n",
    "        if val_nmse < best_nmse:\n",
    "            best_nmse = val_nmse\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                CKPT_DIR / f\"{model_name}_best.pth\"\n",
    "            )\n",
    "\n",
    "        print(\n",
    "            f\"[{epoch:02d}/{NUM_EPOCHS}] \"\n",
    "            f\"TrainLoss: {avg_train_loss:.4f}  \"\n",
    "            f\"Val RMSE: {val_rmse:.4f}  \"\n",
    "            f\"Val NMSE: {val_nmse:.4e}  \"\n",
    "            f\"Val NMSE_dB: {val_nmse_db:.1f} dB  \"\n",
    "            f\"TrainTime: {epoch_times[-1]:.2f}s\"\n",
    "        )\n",
    "\n",
    "    # after all epochs – save *last* weights\n",
    "    torch.save(\n",
    "        model.state_dict(),\n",
    "        CKPT_DIR / f\"{model_name}_last.pth\"\n",
    "    )\n",
    "\n",
    "    avg_ep_time = sum(epoch_times) / len(epoch_times)\n",
    "    print(f\"🕒 {model_name} – avg train time / epoch: {avg_ep_time:.2f}s\")\n",
    "\n",
    "    # store best NMSE_dB for the summary\n",
    "    results[model_name] = 10 * math.log10(best_nmse)\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# 2) Summary\n",
    "# ─────────────────────────────────────────────\n",
    "print(\"\\n=== Summary of best NMSE(dB) by model ===\")\n",
    "for name, nmse_db in results.items():\n",
    "    print(f\"{name:25s}: {nmse_db if not math.isnan(nmse_db) else 'skipped':>6}\")\n",
    "\n",
    "print(f\"\\nTotal training time for all models: {time.time() - total_start:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e41b5c9-77dd-4300-ac44-925dd560ccfd",
   "metadata": {},
   "source": [
    "## inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac929b23-8f2c-4b46-b746-d450e45bbe3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from ./model_weights.pth to cuda\n",
      "Model loaded successfully from ./model_weights.pth to cuda\n",
      "⏱ LWM_freeze_backbone       | total  29.65s  | /batch  27.35 ms  | /sample   0.85 ms\n",
      "⏱ LWM_pretrained_Fine_tune  | total  31.95s  | /batch  29.47 ms  | /sample   0.92 ms\n",
      "⏱ LWM_Fine_tune             | total  31.32s  | /batch  28.89 ms  | /sample   0.90 ms\n",
      "⏱ gru                       | total  15.10s  | /batch  13.93 ms  | /sample   0.44 ms\n",
      "⏱ RNN                       | total  13.25s  | /batch  12.22 ms  | /sample   0.38 ms\n",
      "⏱ LSTM                      | total  16.28s  | /batch  15.02 ms  | /sample   0.47 ms\n",
      "⏱ Transformer               | total  40.31s  | /batch  37.18 ms  | /sample   1.16 ms\n",
      "\n",
      "=== Inference-time summary ===\n",
      "model                     | total [s] |  /batch [ms] |  /sample [ms]\n",
      "--------------------------------------------------------------------\n",
      "LWM_freeze_backbone       |     29.65 |        27.35 |          0.85\n",
      "LWM_pretrained_Fine_tune  |     31.95 |        29.47 |          0.92\n",
      "LWM_Fine_tune             |     31.32 |        28.89 |          0.90\n",
      "gru                       |     15.10 |        13.93 |          0.44\n",
      "RNN                       |     13.25 |        12.22 |          0.38\n",
      "LSTM                      |     16.28 |        15.02 |          0.47\n",
      "Transformer               |     40.31 |        37.18 |          1.16\n"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────\n",
    "# 0)  Load the *best* checkpoints into `trained_models`\n",
    "# ─────────────────────────────────────────────\n",
    "CKPT_DIR = Path(\"checkpoints\")                 # folder with *.pth files\n",
    "device   = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "trained_models = {}\n",
    "for name, ModelCls in MODEL_CATALOG.items():\n",
    "    ckpt_path = CKPT_DIR / f\"{name}_best.pth\"\n",
    "    if ckpt_path.exists():\n",
    "        model = ModelCls(**MODEL_PARAMS[name])     # init on CPU\n",
    "        model.load_state_dict(torch.load(ckpt_path, map_location=\"cpu\"))\n",
    "        trained_models[name] = model               # keep on CPU for now\n",
    "    else:\n",
    "        print(f\"⚠️  {ckpt_path} not found — skipping this model.\")\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# 1)  Pure-inference timing loop (no loss / labels)\n",
    "# ─────────────────────────────────────────────\n",
    "torch.backends.cudnn.benchmark = True           # let cuDNN pick fastest kernels\n",
    "INFER_TIME = {}                                 # {model: (total, per_batch, per_sample)}\n",
    "\n",
    "for name, model in trained_models.items():\n",
    "    uses_mask      = name.startswith(\"LWM_\")\n",
    "    is_transformer = name.startswith(\"Transformer\")   # covers Transformer & TransformerWithHead\n",
    "    v_loader       = masked_val_loader if uses_mask else unmasked_val_loader\n",
    "\n",
    "    model = model.to(device).eval()\n",
    "\n",
    "    # ― Warm-up (one batch) to ramp GPU clocks and cache kernels\n",
    "    with torch.no_grad():\n",
    "        batch = next(iter(v_loader))\n",
    "        if uses_mask:\n",
    "            seq, mpos, _ = [x.to(device) for x in batch]\n",
    "            _ = model(seq, mpos)\n",
    "        elif is_transformer:\n",
    "            seq, _ = [x.to(device) for x in batch]\n",
    "            tgt    = seq[:, 4:, :]                 # same slice used during training\n",
    "            _ = model(seq, tgt)\n",
    "        else:\n",
    "            seq, _ = [x.to(device) for x in batch]\n",
    "            _ = model(seq)\n",
    "\n",
    "    # ― Timed inference pass over the entire loader\n",
    "    torch.cuda.synchronize()\n",
    "    t0        = time.time()\n",
    "    n_batches = 0\n",
    "    n_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in v_loader:\n",
    "            if uses_mask:\n",
    "                seq, mpos, _ = [x.to(device) for x in batch]\n",
    "                _  = model(seq, mpos)\n",
    "                bs = seq.size(0)\n",
    "            elif is_transformer:\n",
    "                seq, _ = [x.to(device) for x in batch]\n",
    "                tgt    = seq[:, 4:, :]\n",
    "                _  = model(seq, tgt)\n",
    "                bs = seq.size(0)\n",
    "            else:\n",
    "                seq, _ = [x.to(device) for x in batch]\n",
    "                _  = model(seq)\n",
    "                bs = seq.size(0)\n",
    "\n",
    "            n_batches += 1\n",
    "            n_samples += bs\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    elapsed = time.time() - t0\n",
    "\n",
    "    INFER_TIME[name] = (\n",
    "        elapsed,                # total seconds\n",
    "        elapsed / n_batches,    # seconds per batch\n",
    "        elapsed / n_samples     # seconds per sample\n",
    "    )\n",
    "\n",
    "    print(f\"⏱ {name:25s} | total {elapsed:6.2f}s  \"\n",
    "          f\"| /batch {elapsed/n_batches*1e3:6.2f} ms  \"\n",
    "          f\"| /sample {elapsed/n_samples*1e3:6.2f} ms\")\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# 2)  Pretty summary table\n",
    "# ─────────────────────────────────────────────\n",
    "print(\"\\n=== Inference-time summary ===\")\n",
    "header = f\"{'model':25s} | {'total [s]':>9} | {'/batch [ms]':>12} | {'/sample [ms]':>13}\"\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "for n, (tot, pb, ps) in INFER_TIME.items():\n",
    "    print(f\"{n:25s} | {tot:9.2f} | {pb*1e3:12.2f} | {ps*1e3:13.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b547a829-25e4-446b-a962-6da55cc44176",
   "metadata": {},
   "source": [
    "## Compare trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13a90966-4bb9-40c9-a8a6-6d2435ceec06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Trainable parameters per model ===\n",
      "Model loaded successfully from ./model_weights.pth to cuda\n",
      "LWM_freeze_backbone      : 5,200\n",
      "Model loaded successfully from ./model_weights.pth to cuda\n",
      "LWM_pretrained_Fine_tune : 608,912\n",
      "LWM_Fine_tune            : 601,744\n",
      "gru                      : 860,240\n",
      "RNN                      : 292,944\n",
      "LSTM                     : 1,143,888\n",
      "Transformer              : 1,408,208\n"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────\n",
    "# Report trainable parameters for every model\n",
    "# ─────────────────────────────────────────────\n",
    "print(\"\\n=== Trainable parameters per model ===\")\n",
    "for name, ModelCls in MODEL_CATALOG.items():\n",
    "    # instantiate model with its params (on CPU is fine for counting)\n",
    "    model = ModelCls(**MODEL_PARAMS[name])\n",
    "    count = count_trainable_params(model)\n",
    "    print(f\"{name:25s}: {count:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff42f6d-3ed7-43b4-b35e-16e0d7345bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f748d3-0edc-4e77-bbf6-be96d7d8d99e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a224fa-03a3-4c41-989a-47e2327c5c45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bea2d4-1027-495f-a2e3-efbc703aff5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dd53c6-5322-4744-95d6-90cbe8da1d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9f299d-07db-4e49-aac5-ebddf12c7538",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
