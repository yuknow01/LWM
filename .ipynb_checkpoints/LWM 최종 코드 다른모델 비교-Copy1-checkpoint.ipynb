{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeacb7fd",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ec90d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "#LWM을 하기위한 라이브러리 가져오기\n",
    "import DeepMIMOv3\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "plt . rcParams [ 'figure.figsize' ]  =  [ 12 ,  8 ]  # 기본 플롯 크기 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e17e0b",
   "metadata": {},
   "source": [
    "## GPU설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47baa533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# GPU 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a6fcece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8\n",
      "90100\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)                   # 설치된 CUDA 버전 (예: '11.7')\n",
    "print(torch.backends.cudnn.version())       # cuDNN 버전 (예: 8200)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())  # True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9e064d",
   "metadata": {},
   "source": [
    "# DeepMIMOv3 다운"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23623e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install DeepMIMOv3 umap-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19540670",
   "metadata": {},
   "source": [
    "## 파라미터 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce5ac681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'OFDM': {'RX_filter': 0,\n",
      "          'bandwidth': 0.05,\n",
      "          'selected_subcarriers': array([0]),\n",
      "          'subcarriers': 512},\n",
      " 'OFDM_channels': 1,\n",
      " 'active_BS': array([1]),\n",
      " 'bs_antenna': {'FoV': array([360, 180]),\n",
      "                'radiation_pattern': 'isotropic',\n",
      "                'rotation': array([0, 0, 0]),\n",
      "                'shape': array([8, 4]),\n",
      "                'spacing': 0.5},\n",
      " 'dataset_folder': './Raytracing_scenarios',\n",
      " 'dynamic_scenario_scenes': array([1]),\n",
      " 'enable_BS2BS': 1,\n",
      " 'enable_doppler': 0,\n",
      " 'enable_dual_polar': 0,\n",
      " 'num_paths': 5,\n",
      " 'scenario': 'O1_60',\n",
      " 'ue_antenna': {'FoV': array([360, 180]),\n",
      "                'radiation_pattern': 'isotropic',\n",
      "                'rotation': array([0, 0, 0]),\n",
      "                'shape': array([4, 2]),\n",
      "                'spacing': 0.5},\n",
      " 'user_rows': array([1]),\n",
      " 'user_subsampling': 1}\n"
     ]
    }
   ],
   "source": [
    "## Load and print the default parameters\n",
    "# bandwith: 0.05GHz(50MHz 대역폭 사용)\n",
    "parameters = DeepMIMOv3.default_params()\n",
    "pprint(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f0642c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change parameters for the setup\n",
    "# Scenario O1_60 extracted at the dataset_folder\n",
    "#LWM 동적 시나리오 불러오기\n",
    "#자신의 LWM 파일 위치 경로 작성\n",
    "# parameters['dataset_folder'] = r'/content/drive/MyDrive/Colab Notebooks/LWM'\n",
    "scene = 15 # 장면 수\n",
    "parameters['dataset_folder'] = r'C:\\Users\\dlghd\\졸업프로젝트\\LWM'\n",
    "\n",
    "# scnario = 02_dyn_3p5 <- 다운받은 파일(동적시나리오)\n",
    "parameters['scenario'] = 'O2_dyn_3p5'\n",
    "parameters['dynamic_scenario_scenes'] = np.arange(scene) #scene 0~9\n",
    "\n",
    "# 각 사용자-기지국 채널에 대해 최대 10개 멀티패스 경로 사용\n",
    "parameters['num_paths'] = 10\n",
    "\n",
    "# User rows 1-100\n",
    "parameters['user_rows'] = np.arange(100)\n",
    "# User 축소하기\n",
    "parameters['user_subsampling'] = 0.01\n",
    "\n",
    "# Activate only the first basestation\n",
    "parameters['active_BS'] = np.array([1])\n",
    "\n",
    "parameters['activate_OFDM'] = 1\n",
    "\n",
    "parameters['OFDM']['bandwidth'] = 0.05 # 50 MHz\n",
    "parameters['OFDM']['subcarriers'] = 512 # OFDM with 512 subcarriers\n",
    "parameters['OFDM']['selected_subcarriers'] = np.arange(0, 64, 1)\n",
    "#parameters['OFDM']['subcarriers_limit'] = 64 # Keep only first 64 subcarriers\n",
    "\n",
    "parameters['ue_antenna']['shape'] = np.array([1, 1]) # Single antenna\n",
    "parameters['bs_antenna']['shape'] = np.array([1, 32]) # ULA of 32 elements\n",
    "#parameters['bs_antenna']['rotation'] = np.array([0, 30, 90]) # ULA of 32 elements\n",
    "#parameters['ue_antenna']['rotation'] = np.array([[0, 30], [30, 60], [60, 90]]) # ULA of 32 elements\n",
    "#parameters['ue_antenna']['radiation_pattern'] = 'isotropic'\n",
    "#parameters['bs_antenna']['radiation_pattern'] = 'halfwave-dipole'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30aa4ae2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_folder': 'C:\\\\Users\\\\dlghd\\\\졸업프로젝트\\\\LWM', 'scenario': 'O2_dyn_3p5', 'dynamic_scenario_scenes': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]), 'num_paths': 10, 'active_BS': array([1]), 'user_rows': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
      "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
      "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]), 'user_subsampling': 0.01, 'bs_antenna': {'shape': array([ 1, 32]), 'spacing': 0.5, 'rotation': array([0, 0, 0]), 'FoV': array([360, 180]), 'radiation_pattern': 'isotropic'}, 'ue_antenna': {'shape': array([1, 1]), 'spacing': 0.5, 'rotation': array([0, 0, 0]), 'FoV': array([360, 180]), 'radiation_pattern': 'isotropic'}, 'enable_doppler': 0, 'enable_dual_polar': 0, 'enable_BS2BS': 1, 'OFDM_channels': 1, 'OFDM': {'subcarriers': 512, 'selected_subcarriers': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]), 'bandwidth': 0.05, 'RX_filter': 0}, 'activate_OFDM': 1}\n"
     ]
    }
   ],
   "source": [
    "print(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3326b22d",
   "metadata": {},
   "source": [
    "## dataset 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b87a86e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following parameters seem unnecessary:\n",
      "{'activate_OFDM'}\n",
      "\n",
      "Scene 1/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                   | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  40%|████████████████████▎                              | 27455/69006 [00:00<00:00, 273373.81it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 264631.41it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                     | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 6028.21it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 497.72it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 2/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                   | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  37%|███████████████████                                | 25826/69006 [00:00<00:00, 257480.62it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 260941.74it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                     | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 6128.65it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 923.25it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 580.93it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 3/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                   | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  36%|██████████████████▍                                | 25014/69006 [00:00<00:00, 247622.86it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 253266.23it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                     | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 6033.47it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 477.66it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 4/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                   | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  40%|████████████████████▏                              | 27329/69006 [00:00<00:00, 273094.93it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 270006.77it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                     | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 5969.82it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 499.86it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 5/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                   | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  39%|███████████████████▉                               | 26918/69006 [00:00<00:00, 265922.09it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 267006.04it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                     | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 6134.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 498.97it/s]\u001b[A\n",
      " 33%|████████████████████████████                                                        | 1/3 [00:07<00:14,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenes 0–4 generation time: 7.06s\n",
      "The following parameters seem unnecessary:\n",
      "{'activate_OFDM'}\n",
      "\n",
      "Scene 1/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                   | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  39%|███████████████████▊                               | 26867/69006 [00:00<00:00, 266402.13it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 260447.46it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                     | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 5848.51it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 397.08it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 2/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                   | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  40%|████████████████████▌                              | 27789/69006 [00:00<00:00, 277865.09it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 274048.17it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                     | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 5947.67it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 376.95it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 3/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                   | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  39%|████████████████████                               | 27221/69006 [00:00<00:00, 272194.04it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 274691.12it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                     | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 6033.81it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 489.07it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 4/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                   | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  39%|████████████████████▏                              | 27249/69006 [00:00<00:00, 272395.44it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 272378.01it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                     | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 6064.03it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 395.91it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 5/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                   | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  40%|████████████████████▍                              | 27642/69006 [00:00<00:00, 274766.80it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 267241.73it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                     | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 5830.51it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 411.73it/s]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████████                            | 2/3 [00:14<00:07,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenes 5–9 generation time: 6.86s\n",
      "The following parameters seem unnecessary:\n",
      "{'activate_OFDM'}\n",
      "\n",
      "Scene 1/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                   | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  40%|████████████████████▏                              | 27386/69006 [00:00<00:00, 272703.60it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 273077.27it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                     | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 5760.64it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 489.99it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 2/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                   | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  38%|███████████████████▍                               | 26366/69006 [00:00<00:00, 263582.95it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 270482.16it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                     | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 6049.35it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 701.15it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 3/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                   | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  39%|███████████████████▉                               | 26985/69006 [00:00<00:00, 266564.52it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 270046.83it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                     | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 5714.84it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 407.06it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 4/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                   | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  32%|████████████████▎                                  | 21992/69006 [00:00<00:00, 219406.52it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 248214.40it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                     | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 5729.92it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 488.33it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scene 5/5\n",
      "\n",
      "Basestation 1\n",
      "\n",
      "UE-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing:   0%|                                                                   | 0/69006 [00:00<?, ?it/s]\u001b[A\n",
      "Reading ray-tracing:  39%|████████████████████                               | 27112/69006 [00:00<00:00, 267972.41it/s]\u001b[A\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████| 69006/69006 [00:00<00:00, 273608.28it/s]\u001b[A\n",
      "\n",
      "Generating channels:   0%|                                                                     | 0/727 [00:00<?, ?it/s]\u001b[A\n",
      "Generating channels: 100%|█████████████████████████████████████████████████████████| 727/727 [00:00<00:00, 5713.85it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BS-BS Channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading ray-tracing: 100%|███████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Generating channels: 100%|██████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 440.02it/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:21<00:00,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenes 10–14 generation time: 6.93s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## dataset 구축 (chunked on‑the‑fly generation)\n",
    "import time, gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 0~999 씬 인덱스, 한 번에 50개씩 처리\n",
    "scene_indices = np.arange(scene)\n",
    "chunk_size   = 5\n",
    "all_data     = []\n",
    "\n",
    "# 씬 묶음(chunk)마다 generate_data 호출\n",
    "for i in tqdm(range(0, len(scene_indices), chunk_size)):\n",
    "    chunk = scene_indices[i : i+chunk_size].tolist()\n",
    "    parameters['dynamic_scenario_scenes'] = chunk\n",
    "\n",
    "    start = time.time()\n",
    "    data_chunk = DeepMIMOv3.generate_data(parameters)\n",
    "    print(f\"Scenes {chunk[0]}–{chunk[-1]} generation time: {time.time() - start:.2f}s\")\n",
    "\n",
    "    # 바로 all_data에 합치거나, 디스크에 저장해도 OK\n",
    "    all_data.extend(data_chunk)\n",
    "\n",
    "    # 메모리 해제\n",
    "    del data_chunk\n",
    "    gc.collect()\n",
    "\n",
    "# 마지막에 하나의 리스트로 합친 데이터셋\n",
    "dataset = all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b6f3c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98 99]\n"
     ]
    }
   ],
   "source": [
    "print(parameters['user_rows'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ee486e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_folder': 'C:\\\\Users\\\\dlghd\\\\졸업프로젝트\\\\LWM', 'scenario': 'O2_dyn_3p5', 'dynamic_scenario_scenes': [10, 11, 12, 13, 14], 'num_paths': 10, 'active_BS': array([1]), 'user_rows': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
      "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
      "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]), 'user_subsampling': 0.01, 'bs_antenna': {'shape': array([ 1, 32]), 'spacing': 0.5, 'rotation': array([0, 0, 0]), 'FoV': array([360, 180]), 'radiation_pattern': 'isotropic'}, 'ue_antenna': {'shape': array([1, 1]), 'spacing': 0.5, 'rotation': array([0, 0, 0]), 'FoV': array([360, 180]), 'radiation_pattern': 'isotropic'}, 'enable_doppler': 0, 'enable_dual_polar': 0, 'enable_BS2BS': 1, 'OFDM_channels': 1, 'OFDM': {'subcarriers': 512, 'selected_subcarriers': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]), 'bandwidth': 0.05, 'RX_filter': 0}, 'activate_OFDM': 1}\n"
     ]
    }
   ],
   "source": [
    "print(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4e72d4",
   "metadata": {},
   "source": [
    "# 사용자 접근 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57828d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['paths', 'LoS', 'location', 'distance', 'pathloss', 'channel'])\n"
     ]
    }
   ],
   "source": [
    "user_data = dataset[0][0]['user']\n",
    "print(user_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5a3b0c",
   "metadata": {},
   "source": [
    "# 사용자 채널 정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23b2884b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(727, 1, 32, 64)\n"
     ]
    }
   ],
   "source": [
    "# subcarries = 나눈 각각의 주파수 채널\n",
    "# Channel = H <- 채널 벡터\n",
    "# 채널 형태\n",
    "# (user, UE antenna, Bs antenna, subcarrier)\n",
    "channel = dataset[0][0]['user']['channel']\n",
    "print(channel.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf443dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 8.57045598e-06+5.5781261e-06j  8.89099283e-06+5.0515800e-06j\n",
      "    9.17921989e-06+4.5066768e-06j ... -1.02173499e-05-4.1711201e-07j\n",
      "   -1.02239183e-05+1.9928974e-07j -1.01933329e-05+8.1496728e-07j]\n",
      "  [ 1.02161603e-05+4.4529790e-07j  1.02244285e-05-1.7108337e-07j\n",
      "    1.01955429e-05-7.8684292e-07j ... -9.00999748e-06+4.8361312e-06j\n",
      "   -8.70222630e-06+5.3702393e-06j -8.36283198e-06+5.8848323e-06j]\n",
      "  [ 9.02330430e-06-4.8112561e-06j  8.71700831e-06-5.3462113e-06j\n",
      "    8.37903553e-06-5.8617388e-06j ... -5.29921817e-06+8.7456565e-06j\n",
      "   -4.76262221e-06+9.0490685e-06j -4.20871947e-06+9.3195977e-06j]\n",
      "  ...\n",
      "  [-7.00710962e-06-7.4477266e-06j -7.44313866e-06-7.0119827e-06j\n",
      "   -7.85211978e-06-6.5507575e-06j ...  9.82847632e-06+2.8229874e-06j\n",
      "    9.98071755e-06+2.2256456e-06j  1.00966881e-05+1.6202162e-06j]\n",
      "  [-9.82065103e-06-2.8500913e-06j -9.97453935e-06-2.2531719e-06j\n",
      "   -1.00921798e-05-1.6480645e-06j ...  9.89848286e-06-2.5667589e-06j\n",
      "    9.72583803e-06-3.1585257e-06j  9.51785023e-06-3.7388147e-06j]\n",
      "  [-9.90552599e-06+2.5394413e-06j -9.73451461e-06+3.1316822e-06j\n",
      "   -9.52812843e-06+3.7125428e-06j ...  7.21819652e-06-7.2433313e-06j\n",
      "    6.76863647e-06-7.6651013e-06j  6.29447914e-06-8.0590162e-06j]]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][0]['user']['channel'][100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b079846",
   "metadata": {},
   "source": [
    "# 사용자 위치 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84337e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(727, 3)\n",
      "[[-71.03330231 -15.57629967   1.        ]\n",
      " [-68.63330078 -15.57629967   1.        ]\n",
      " [-52.83330154 -15.57629967   1.        ]\n",
      " [-31.23329926 -15.57629967   1.        ]]\n"
     ]
    }
   ],
   "source": [
    "location = dataset[0][0]['user']['location']\n",
    "print(location.shape)      # (사용자 수, 3)\n",
    "print(location[0:4])         # 첫 번째 사용자의 (x, y, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e9a9b6",
   "metadata": {},
   "source": [
    "# 경로정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79cde8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "727\n",
      "{'num_paths': 2, 'DoD_phi': array([-160.941, -160.941], dtype=float32), 'DoD_theta': array([93.6525, 94.7439], dtype=float32), 'DoA_phi': array([19.0585, 19.0585], dtype=float32), 'DoA_theta': array([86.3475, 94.7439], dtype=float32), 'phase': array([ 143.357, -137.611], dtype=float32), 'ToA': array([2.61886e-07, 2.62253e-07], dtype=float32), 'LoS': array([1., 0.], dtype=float32), 'power': array([7.5363324e-09, 3.2098095e-09], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "paths = dataset[0][0]['user']['paths']\n",
    "#사용자 수\n",
    "print(len(paths))\n",
    "# 첫 번째 사용자 경로 정보\n",
    "print(paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2242869",
   "metadata": {},
   "source": [
    "# 기지국 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2900e481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['paths', 'LoS', 'location', 'distance', 'pathloss', 'channel'])\n"
     ]
    }
   ],
   "source": [
    "bs_data = dataset[0][0]['basestation']\n",
    "print(bs_data.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c063ea95",
   "metadata": {},
   "source": [
    "# Scene 및 사용자 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a20df92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scene 0: 727 users\n"
     ]
    }
   ],
   "source": [
    "for i, scene in enumerate(dataset[0]):\n",
    "    user_locs = scene['user']['location']\n",
    "    print(f\"Scene {i}: {len(user_locs)} users\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38f71e1",
   "metadata": {},
   "source": [
    "# 채널 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbbee52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "727"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[0][0]['user']['channel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d474195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_paths': 2, 'DoD_phi': array([-160.941, -160.941], dtype=float32), 'DoD_theta': array([93.6525, 94.7439], dtype=float32), 'DoA_phi': array([19.0585, 19.0585], dtype=float32), 'DoA_theta': array([86.3475, 94.7439], dtype=float32), 'phase': array([ 143.357, -137.611], dtype=float32), 'ToA': array([2.61886e-07, 2.62253e-07], dtype=float32), 'LoS': array([1., 0.], dtype=float32), 'power': array([7.5363324e-09, 3.2098095e-09], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][0]['user']['paths'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73df9912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 64)\n"
     ]
    }
   ],
   "source": [
    "scene = dataset[0][0] # scene 0\n",
    "ue_idx = 0 # 첫 번째 사용자\n",
    "channel = scene['user']['channel'][ue_idx]\n",
    "print(channel.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373ffb59",
   "metadata": {},
   "source": [
    "# channel CIR mat 정보 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec4461cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'CIR_array_full'])\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "\n",
    "file_path = r'C:\\Users\\dlghd\\졸업프로젝트\\LWM\\O2_dyn_3p5\\scene_0\\O2_dyn_3p5.1.CIR.mat'\n",
    "mat_data = sio.loadmat(file_path)\n",
    "\n",
    "# 파일 안의 key 확인\n",
    "print(mat_data.keys())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "662cb441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'MATLAB 5.0 MAT-file, Platform: PCWIN64, Created on: Wed Jun 30 11:33:01 2021'\n"
     ]
    }
   ],
   "source": [
    "# 일반적으로 CIR key는 'CIR' 또는 'cir' 같은 이름일 가능성 높음\n",
    "H_cir = mat_data['__header__']  \n",
    "print(H_cir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f3d7c7",
   "metadata": {},
   "source": [
    "# Time-Prediction 시작\n",
    "## Time Series 형태로 변환\n",
    "### 단일사용자 채널 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f36971f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0이 존재하는 채널 개수 0\n"
     ]
    }
   ],
   "source": [
    "# print(dataset[0][0]['user']['channel'][150][0][3])\n",
    "\n",
    "count = 0\n",
    "for h in dataset[0][0]['user']['channel'][100][0]:\n",
    "#     h = h.squeeze(0)\n",
    "    h_real = h.real\n",
    "    h_imag = h.imag\n",
    "    if np.sum(np.abs(h_real)) ==0:\n",
    "        count+=1\n",
    "    elif np.sum(np.abs(h_imag)) == 0:\n",
    "        count+=1\n",
    "\n",
    "print(\"0이 존재하는 채널 개수\",count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7575de2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antenna #3 subcarriers: [ 5.3233252e-06-8.73100362e-06j  4.7875683e-06-9.03589535e-06j\n",
      "  4.2344141e-06-9.30795068e-06j  3.6658719e-06-9.54618190e-06j\n",
      "  3.0840083e-06-9.74972318e-06j  2.4909377e-06-9.91783418e-06j\n",
      "  1.8888149e-06-1.00499046e-05j  1.2798286e-06-1.01454543e-05j\n",
      "  6.6619128e-07-1.02041367e-05j  5.0133124e-08-1.02257372e-05j\n",
      " -5.6610725e-07-1.02101776e-05j -1.1802904e-06-1.01575160e-05j\n",
      " -1.7901845e-06-1.00679417e-05j -2.3935731e-06-9.94178117e-06j\n",
      " -2.9882635e-06-9.77949367e-06j -3.5720950e-06-9.58166765e-06j\n",
      " -4.1429457e-06-9.34902255e-06j -4.6987411e-06-9.08240327e-06j\n",
      " -5.2374617e-06-8.78277933e-06j -5.7571492e-06-8.45123941e-06j\n",
      " -6.2559161e-06-8.08898767e-06j -6.7319493e-06-7.69734197e-06j\n",
      " -7.1835188e-06-7.27772431e-06j -7.6089841e-06-6.83165945e-06j\n",
      " -8.0067985e-06-6.36076902e-06j -8.3755176e-06-5.86676424e-06j\n",
      " -8.7137996e-06-5.35144000e-06j -9.0204167e-06-4.81666848e-06j\n",
      " -9.2942537e-06-4.26439374e-06j -9.5343166e-06-3.69662257e-06j\n",
      " -9.7397324e-06-3.11541817e-06j -9.9097542e-06-2.52289237e-06j\n",
      " -1.0043765e-05-1.92119842e-06j -1.0141277e-05-1.31252318e-06j\n",
      " -1.0201937e-05-6.99078271e-07j -1.0225523e-05-8.30929494e-08j\n",
      " -1.0211949e-05+5.33194338e-07j -1.0161268e-05+1.14754403e-06j\n",
      " -1.0073660e-05+1.75772368e-06j -9.9494455e-06+2.36151573e-06j\n",
      " -9.7890743e-06+2.95672635e-06j -9.5931318e-06+3.54119220e-06j\n",
      " -9.3623275e-06+4.11278961e-06j -9.0975009e-06+4.66944175e-06j\n",
      " -8.7996150e-06+5.20912499e-06j -8.4697522e-06+5.72987892e-06j\n",
      " -8.1091102e-06+6.22981088e-06j -7.7190007e-06+6.70710369e-06j\n",
      " -7.3008405e-06+7.16002387e-06j -6.8561499e-06+7.58692431e-06j\n",
      " -6.3865441e-06+7.98625479e-06j -5.8937303e-06+8.35656374e-06j\n",
      " -5.3794988e-06+8.69650557e-06j -4.8457186e-06+9.00484429e-06j\n",
      " -4.2943293e-06+9.28046029e-06j -3.7273348e-06+9.52235223e-06j\n",
      " -3.1467955e-06+9.72963971e-06j -2.5548209e-06+9.90157059e-06j\n",
      " -1.9535621e-06+1.00375200e-05j -1.3452043e-06+1.01369933e-05j\n",
      " -7.3195804e-07+1.01996302e-05j -1.1605191e-07+1.02252015e-05j\n",
      "  5.0027592e-07+1.02136155e-05j  1.1147858e-06+1.01649139e-05j]\n",
      "0+0j인 서브캐리어 개수: 0\n",
      "완전 0+0j 안테나 포트 개수: 0\n",
      "0이 아닌 서브캐리어 개수: 2048\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1) (user, ue_port, bs_ant, subc) → (bs_ant, subc) 로 squeeze\n",
    "H = dataset[0][0]['user']['channel'][100, 0]   # shape: (32, 64), complex\n",
    "\n",
    "# 2) BS 안테나 인덱스 3의 서브캐리어 벡터 (64,)\n",
    "print(\"Antenna #3 subcarriers:\", H[3])\n",
    "\n",
    "# 3) 전체 서브캐리어(32×64) 중 값이 정확히 0인 요소 개수\n",
    "zero_elements = np.sum(H == 0)\n",
    "print(\"0+0j인 서브캐리어 개수:\", zero_elements)\n",
    "\n",
    "# 4) 서브캐리어 전부가 0인 안테나 포트(행) 개수\n",
    "zero_ports = np.sum(np.all(H == 0, axis=1))\n",
    "print(\"완전 0+0j 안테나 포트 개수:\", zero_ports)\n",
    "\n",
    "# 5) 만약 “값이 하나도 0이 아닌” 서브캐리어 요소 개수를 보고 싶다면\n",
    "nonzero_elements = np.sum(np.abs(H) > 0)\n",
    "print(\"0이 아닌 서브캐리어 개수:\", nonzero_elements)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20a73af",
   "metadata": {},
   "source": [
    "## 결측치 제거 및 dataload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94309077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────\n",
    "# ❶ IterableDataset: 모든 유저·서브캐리어를 스트리밍\n",
    "import torch\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class ChannelSeqDataset(IterableDataset):\n",
    "    \"\"\"\n",
    "    • seq_len 개의 과거 채널 벡터(real 64 + imag 64 → 128) → 다음 시점 벡터 예측\n",
    "    • 벡터는 평균전력 1 로 power‑normalize 후 반환\n",
    "    \"\"\"\n",
    "    def __init__(self, scenes, seq_len: int = 5, eps: float = 1e-9):\n",
    "        super().__init__()\n",
    "        self.scenes   = scenes\n",
    "        self.seq_len  = seq_len\n",
    "        self.eps      = eps                        # 0 division 방지용 신호세기의 크기 \n",
    "        ch0           = scenes[0][0]['user']['channel']\n",
    "        self.U        = ch0.shape[0]               # 사용자 수\n",
    "        self.A        = ch0.shape[2]               # 안테나 32\n",
    "        self.S        = ch0.shape[3]               # 서브캐리어 64\n",
    "        self.vec_len  = 2 * self.A                 # 64 real + imag\n",
    "        0\n",
    "    def _vec(self, scene, u: int, sc: int) -> torch.Tensor:\n",
    "        \"\"\"(32,) complex → (64,) float32  +  power norm\"\"\"\n",
    "        h = scene[0]['user']['channel'][u, 0, :, sc]          # (32,)\n",
    "        v = np.concatenate([h.real, h.imag]).astype(np.float32)\n",
    "        p = np.mean(v * v) + self.eps                         # 평균 전력: 채널 벡터 h의 각 성분의 진폭 제곱을 합산\n",
    "        v /= np.sqrt(p)                                       # 정규화\n",
    "        return torch.from_numpy(v)                            # (64,)\n",
    "\n",
    "    def __iter__(self):\n",
    "        T = len(self.scenes)\n",
    "        for t in range(self.seq_len, T):                      # 타깃 시점\n",
    "            past_scenes = self.scenes[t - self.seq_len : t]\n",
    "            tgt_scene   = self.scenes[t]\n",
    "            for u in range(self.U):\n",
    "                for s in range(self.S):\n",
    "                    seq = torch.stack([self._vec(ps, u, s) for ps in past_scenes])\n",
    "                    if not torch.any(seq):                    # 전부 0 이면 skip\n",
    "                        continue\n",
    "                    target     = self._vec(tgt_scene, u, s)\n",
    "                    if not torch.any(target): # target이 0이면 스킵\n",
    "                        continue\n",
    "                    masked_pos = torch.tensor([self.seq_len - 2], dtype=torch.long)\n",
    "                    yield seq, masked_pos, target             # shapes: (5,64) / (1,) / (64,)\n",
    "    \n",
    "    def __len__(self):\n",
    "         return (len(self.scenes) - self.seq_len) * self.U * self.S\n",
    "# ─────────────────────────────────────────────\n",
    "# ❷ 학습·검증 DataLoader train : val = 6 : 4\n",
    "seq_len      = 5\n",
    "split_ratio  = 0.6\n",
    "split_idx    = int(len(dataset) * split_ratio)\n",
    "\n",
    "train_ds = ChannelSeqDataset(dataset[:split_idx], seq_len=seq_len)\n",
    "val_ds   = ChannelSeqDataset(dataset[split_idx:], seq_len=seq_len)\n",
    "\n",
    "batch_size   = 32\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False)\n",
    "# ─────────────────────────────────────────────\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0aaadd66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186112"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds) #4x727x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90f5b39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46528"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_ds) #1x727x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe8a8a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x00000218BAE83980>\n",
      "batch_size: 32\n",
      "dataset: <__main__.ChannelSeqDataset object at 0x00000218BACF0EF0>\n",
      "total samples: 186112\n",
      "total batches: 5816\n",
      "seqs.shape: torch.Size([32, 5, 64])\n",
      "mposes.shape: torch.Size([32, 1])\n",
      "tgts.shape: torch.Size([32, 64])\n"
     ]
    }
   ],
   "source": [
    "# 1) DataLoader 설정 확인\n",
    "print(train_loader)                # DataLoader 정보 전체\n",
    "print(\"batch_size:\", train_loader.batch_size)\n",
    "print(\"dataset:\",   train_loader.dataset)\n",
    "\n",
    "# 총 샘플 수\n",
    "print(\"total samples:\", len(train_loader.dataset))\n",
    "# → (len(scenes) - seq_len) * U * S 와 동일한 값\n",
    "\n",
    "# 총 배치 수\n",
    "print(\"total batches:\", len(train_loader))\n",
    "# → ceil(total_samples / batch_size)\n",
    "\n",
    "\n",
    "# 3) 첫 번째 배치 내용 확인\n",
    "first_batch = next(iter(train_loader))\n",
    "seqs, mposes, tgts = first_batch\n",
    "print(\"seqs.shape:\",   seqs.shape)    # (B, seq_len, vec_len)\n",
    "print(\"mposes.shape:\", mposes.shape)  # (B, 1)\n",
    "print(\"tgts.shape:\",   tgts.shape)    # (B, vec_len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3348886",
   "metadata": {},
   "source": [
    "## 이론적 input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff85e07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ total samples (input_size): 465280\n",
      "→ batch size: 32\n",
      "→ total batches: 14540\n"
     ]
    }
   ],
   "source": [
    "# ──────────────────────────────────────────────────\n",
    "# input_size 계산 및 출력\n",
    "# ──────────────────────────────────────────────────\n",
    "\n",
    "# 1) 시퀀스 길이\n",
    "seq_len = train_ds.seq_len      # 보통 5 ->9\n",
    "\n",
    "# 2) 씬 개수(T), 사용자 수(U), 서브캐리어 수(S)\n",
    "T = len(dataset)               # 전체 씬 개수, 여기선 10\n",
    "U = train_ds.U                 # 한 씬당 사용자 수\n",
    "S = train_ds.S                 # 한 사용자당 서브캐리어 수\n",
    "\n",
    "# 3) 총 샘플 수 = (T - seq_len) × U × S\n",
    "input_size = (T - seq_len) * U * S\n",
    "\n",
    "# 4) 배치 수\n",
    "batch_size = 32  # 이미 설정한 값\n",
    "n_batches = input_size // batch_size + int(input_size % batch_size != 0)\n",
    "\n",
    "print(f\"→ total samples (input_size): {input_size}\")\n",
    "print(f\"→ batch size: {batch_size}\")\n",
    "print(f\"→ total batches: {n_batches}\")\n",
    "\n",
    "# train val 구분\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf6bac8",
   "metadata": {},
   "source": [
    "# 아래 코드 구조\n",
    "┌──────────────────────────────────────────────────────────────┐\n",
    "│ input_ids  (B, seq_len, element_length)  ─┐                 │\n",
    "│ masked_pos (B, num_mask)                  ├─>  LWM backbone │\n",
    "│                                           │    (12-층 트랜스포머)  \n",
    "└────────────────────────────────────────────┘         │\n",
    "            logits_lm  (B, num_mask, element_length)  │   enc_output (B, seq_len, d_model)\n",
    "                                                      ▼\n",
    "                        ┌─[풀링]───────────────┐      ←── feat (B, d_model)\n",
    "                        │ 첫 토큰(0번) 선택    │\n",
    "                        │   or 평균/최대 풀링 │\n",
    "                        └──────────────────────┘\n",
    "                                      ▼\n",
    "                       FC 헤드  (d_model → hidden_dim → out_dim)\n",
    "                                      ▼\n",
    "                                out (B, out_dim)\n",
    "\n",
    "# 시각적비유\n",
    "\n",
    "[패치 프로젝터]──▶[Transformer ×12]──▶[LayerNorm]──┐\n",
    "                                                  ├─▶ 64-차 벡터 (CLS 또는 풀링) ─▶ MLP ─▶ out                                                \n",
    "[Positional Embedding]─────────────────────────────┘\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5df5e7f5-6a8b-4076-8e6b-23a226f1f3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelSeqDatasetHorizon(IterableDataset):\n",
    "    def __init__(self, scenes, seq_len=5, horizon=1, eps=1e-9):\n",
    "        super().__init__()\n",
    "        self.scenes   = scenes\n",
    "        self.seq_len  = seq_len\n",
    "        self.horizon  = horizon\n",
    "        self.eps      = eps\n",
    "        ch0 = scenes[0][0]['user']['channel']\n",
    "        self.U  = ch0.shape[0]\n",
    "        self.S  = ch0.shape[3]\n",
    "\n",
    "    def _vec(self, scene, u, sc):\n",
    "        h = scene[0]['user']['channel'][u,0,:,sc]\n",
    "        v = np.concatenate([h.real, h.imag]).astype(np.float32)\n",
    "        p = np.mean(v*v) + self.eps\n",
    "        return torch.from_numpy(v / np.sqrt(p))\n",
    "\n",
    "    def __iter__(self):\n",
    "        T = len(self.scenes)\n",
    "        # t: target 시점 index = seq_len + (horizon-1) ... T-1\n",
    "        for t in range(self.seq_len + (self.horizon-1), T):\n",
    "            past = self.scenes[t-self.seq_len-(self.horizon-1) : t-self.horizon+1]\n",
    "            tgt  = self.scenes[t]\n",
    "            for u in range(self.U):\n",
    "                for s in range(self.S):\n",
    "                    seq = torch.stack([self._vec(ps, u, s) for ps in past])\n",
    "                    if not torch.any(seq): continue\n",
    "                    target = self._vec(tgt, u, s)\n",
    "                    if not torch.any(target): continue\n",
    "                    yield seq, target\n",
    "    def __len__(self):\n",
    "        return (len(self.scenes) - self.seq_len - (self.horizon-1)) * self.U * self.S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d882a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LWMWithHead: 사전학습된 LWM(Transformer encoder)을 ‘백본(backbone)’으로 사용하고,\n",
    "그 뒤에 새로운 완전연결(FC) 헤드(head)를 붙여 다운스트림 작업(회귀·분류 등)에\n",
    "사용할 수 있도록 만든 래퍼(wrapper) 클래스입니다.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from lwm_model import lwm   # 기존 LWM 모델 클래스 (import 경로는 프로젝트 구조에 맞게 조정)\n",
    "\n",
    "class LWMWithHead(nn.Module):\n",
    "    \"\"\"\n",
    "    Args\n",
    "    ----\n",
    "    element_length : int\n",
    "        LWM 입력 패치의 길이. 예) 64*64 = 4096 (H_real + H_imag)\n",
    "    d_model        : int\n",
    "        Transformer 모델 차원(=LWM hidden size).\n",
    "    max_len        : int\n",
    "        포지셔널 임베딩 최대 길이(시퀀스 길이).\n",
    "    n_layers       : int\n",
    "        Transformer 인코더 층 수.\n",
    "    hidden_dim     : int\n",
    "        새 FC 헤드의 중간 차원.\n",
    "    out_dim        : int\n",
    "        최종 출력 차원. 1 → 회귀/이진분류, k → k-클래스 분류.\n",
    "    freeze_backbone: bool\n",
    "        True면 백본을 동결(freeze)하여 헤드만 학습.\n",
    "    ckpt_path      : str | None\n",
    "        사전학습 가중치(.pth) 경로. None이면 랜덤 초기화.\n",
    "    device         : str\n",
    "        'cuda' / 'cpu' 등 모델을 올릴 장치.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        element_length: int,\n",
    "        d_model: int = 64,\n",
    "        max_len: int = 129,\n",
    "        n_layers: int = 12,\n",
    "        hidden_dim: int = 256,\n",
    "        out_dim: int = 64, \n",
    "        freeze_backbone: bool = False,\n",
    "        ckpt_path: str | None = \"./model_weights.pth\",# path 지정해주기\n",
    "        device: str = \"cuda\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # ────────────────────────────\n",
    "        # 1) 백본(backbone) 초기화\n",
    "        # ────────────────────────────\n",
    "        if ckpt_path is None:\n",
    "            # 가중치 없이 새로 생성\n",
    "            self.backbone = lwm(\n",
    "                element_length=element_length,\n",
    "                d_model=d_model,\n",
    "                max_len=max_len,\n",
    "                n_layers=n_layers\n",
    "            ).to(device)\n",
    "        else:\n",
    "            # 사전학습 가중치 로드\n",
    "            self.backbone = lwm.from_pretrained(\n",
    "                ckpt_name=ckpt_path,\n",
    "                device=device\n",
    "            )\n",
    "\n",
    "        # 백본 동결(선택)\n",
    "        if freeze_backbone:\n",
    "            for p in self.backbone.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        # ────────────────────────────\n",
    "        # 2) 헤드(head) 정의\n",
    "        # ────────────────────────────\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(d_model, 64),  # 첫 FC\n",
    "            nn.ReLU(),                       # 활성화\n",
    "            nn.Linear(64, out_dim)   # 최종 FC\n",
    "        )\n",
    "\n",
    "    # ────────────────────────────\n",
    "    # forward\n",
    "    # ────────────────────────────\n",
    "    def forward(self, input_ids, masked_pos):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_ids : Tensor  (B, seq_len, element_length)\n",
    "            LWM 입력 시퀀스 (패치/토큰 단위 실수·복소수 채널값 등).\n",
    "        masked_pos : Tensor  (B, num_mask)\n",
    "            LWM의 마스크드 채널 모델링용 인덱스 (백본 규격 유지용).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out : Tensor  (B, out_dim)\n",
    "            헤드에서 계산된 다운스트림 작업용 로짓/예측값.\n",
    "        \"\"\"\n",
    "\n",
    "        # 기존 LWM forward:\n",
    "        #   logits_lm : (B, num_mask, element_length)  ← 사용 안 함\n",
    "        #   enc_output: (B, seq_len, d_model)\n",
    "        _, enc_output = self.backbone(input_ids, masked_pos)\n",
    "\n",
    "        # 특징 추출(feat)\n",
    "        # ① 첫 토큰 벡터 사용 (CLS 개념) ─────────────\n",
    "        feat = enc_output[:, 0, :]           # (B, d_model)\n",
    "\n",
    "        # ② 평균 풀링 예시 (필요 시 주석 해제) ─────\n",
    "        # feat = enc_output.mean(dim=1)       # (B, d_model)\n",
    "\n",
    "        # ③ Max 풀링 예시 (필요 시 주석 해제) ─────\n",
    "        # feat, _ = enc_output.max(dim=1)     # (B, d_model)\n",
    "\n",
    "        # 헤드 통과 → 최종 출력\n",
    "        out = self.head(feat)                # (B, out_dim)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5beb3297-472f-45b8-a464-1650fca7c8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ────────────────────────────────────────────────\n",
    "# 1) LSTMWithHead — LSTM 백본 + FC-헤드\n",
    "# ────────────────────────────────────────────────\n",
    "class LSTMWithHead(nn.Module):\n",
    "    def __init__(self,\n",
    "                 feat_dim: int,            # = element_length\n",
    "                 hidden_size: int = 256,\n",
    "                 num_layers: int = 2,\n",
    "                 bidirectional: bool = False,\n",
    "                 dropout: float = 0.2,\n",
    "                 hidden_dim: int = 256,\n",
    "                 out_dim: int    = 64,\n",
    "                 freeze_backbone: bool = False):\n",
    "        super().__init__()\n",
    "        self.backbone = nn.LSTM(\n",
    "            input_size   = feat_dim,\n",
    "            hidden_size  = hidden_size,\n",
    "            num_layers   = num_layers,\n",
    "            batch_first  = True,\n",
    "            bidirectional= bidirectional,\n",
    "            dropout      = dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "        if freeze_backbone:\n",
    "            for p in self.backbone.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        lstm_out_dim = hidden_size * (2 if bidirectional else 1)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(lstm_out_dim, hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, masked_pos=None):     # masked_pos는 무시\n",
    "        out, _ = self.backbone(x)              # (B, seq_len, H)\n",
    "        feat = out[:, -1, :]                   # 마지막 타임스텝\n",
    "        return self.head(feat)                 # (B, out_dim)\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 2) GRUWithHead — GRU 백본 + FC-헤드\n",
    "# ────────────────────────────────────────────────\n",
    "class GRUWithHead(nn.Module):\n",
    "    def __init__(self,\n",
    "                 feat_dim: int,\n",
    "                 hidden_size: int = 256,\n",
    "                 num_layers: int = 2,\n",
    "                 bidirectional: bool = False,\n",
    "                 dropout: float = 0.2,\n",
    "                 hidden_dim: int = 256,\n",
    "                 out_dim: int    = 64,\n",
    "                 freeze_backbone: bool = False):\n",
    "        super().__init__()\n",
    "        self.backbone = nn.GRU(\n",
    "            input_size   = feat_dim,\n",
    "            hidden_size  = hidden_size,\n",
    "            num_layers   = num_layers,\n",
    "            batch_first  = True,\n",
    "            bidirectional= bidirectional,\n",
    "            dropout      = dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "        if freeze_backbone:\n",
    "            for p in self.backbone.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        gru_out_dim = hidden_size * (2 if bidirectional else 1)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(gru_out_dim, hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, masked_pos=None):     # masked_pos는 무시\n",
    "        out, _ = self.backbone(x)\n",
    "        feat = out[:, -1, :]\n",
    "        return self.head(feat)\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# 3) TransformerWithHead — 소형 Transformer 백본 + FC-헤드\n",
    "# ────────────────────────────────────────────────\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "class TransformerWithHead(nn.Module):\n",
    "    def __init__(self,\n",
    "                 feat_dim: int,\n",
    "                 n_heads: int   = 4,\n",
    "                 dim_ff: int    = 256,\n",
    "                 n_layers: int  = 2,\n",
    "                 dropout: float = 0.1,\n",
    "                 hidden_dim: int = 256,\n",
    "                 out_dim: int    = 64,\n",
    "                 freeze_backbone: bool = False):\n",
    "        super().__init__()\n",
    "        layer = TransformerEncoderLayer(\n",
    "            d_model = feat_dim,\n",
    "            nhead   = n_heads,\n",
    "            dim_feedforward = dim_ff,\n",
    "            dropout = dropout\n",
    "        )\n",
    "        self.backbone = TransformerEncoder(layer, num_layers=n_layers)\n",
    "        if freeze_backbone:\n",
    "            for p in self.backbone.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(feat_dim, hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, masked_pos=None):     # masked_pos는 무시\n",
    "        z = self.backbone(x.transpose(0,1))    # (T,B,F)\n",
    "        feat = z[-1]                           # 마지막 토큰\n",
    "        return self.head(feat)                 # (B, out_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3484a8be-5197-4ccc-9144-65b31a84cdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) No prediction\n",
    "class NoPrediction(nn.Module):\n",
    "    def forward(self, x):          # x: (B, T, F)\n",
    "        return x[:, -1, :]        # (B, F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ead96c3b-2a4d-4132-bb17-e94591f88af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) Sequential PAD\n",
    "class SequentialPAD(nn.Module):\n",
    "    def forward(self, x):\n",
    "        xt, xtm1 = x[:,1:], x[:,:-1]\n",
    "        num = (xt * xtm1).sum(dim=(1,2))\n",
    "        den = (xtm1*xtm1).sum(dim=(1,2)) + 1e-6\n",
    "        phi = (num/den).view(-1,1,1)\n",
    "        return (phi * x[:, -1:]).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9b2e5089-2e7a-45f3-a557-0bdb83da54fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) Sequential PVEC\n",
    "class SequentialPVEC(nn.Module):\n",
    "    def forward(self, x):\n",
    "        B,T,F = x.shape\n",
    "        X = x.reshape(-1, F)\n",
    "        C = (X.t() @ X) / (B*T - 1)\n",
    "        eigvals, eigvecs = torch.linalg.eigh(C)\n",
    "        v1 = eigvecs[:, -1].view(1,1,F).to(x.device)\n",
    "        coeff = (x[:, -1:] * v1).sum(dim=2, keepdim=True)\n",
    "        return (coeff * v1).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd805f88-7818-4ee3-9c5b-af05c776be57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4) Sequential RNN\n",
    "class SequentialRNN(nn.Module):\n",
    "    def __init__(self, feat_dim, hidden=128):\n",
    "        super().__init__()\n",
    "        self.rnn  = nn.RNN(feat_dim, hidden, batch_first=True)\n",
    "        self.head = nn.Linear(hidden, feat_dim)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        return self.head(out[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7b3434bd-716e-44a9-8ce2-61432e691200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (5) Sequential LSTM\n",
    "class SequentialLSTM(nn.Module):\n",
    "    def __init__(self, feat_dim, hidden=128):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(feat_dim, hidden, batch_first=True)\n",
    "        self.head = nn.Linear(hidden, feat_dim)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.head(out[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e0d78b66-1c59-4860-b2a1-267eb30c7629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (6) Parallel Transformer\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "class ParallelTransformer(nn.Module):\n",
    "    def __init__(self, feat_dim, heads=4, dim_ff=256, layers=2):\n",
    "        super().__init__()\n",
    "        layer = TransformerEncoderLayer(feat_dim, heads, dim_ff)\n",
    "        self.enc = TransformerEncoder(layer, layers)\n",
    "        self.head = nn.Linear(feat_dim, feat_dim)\n",
    "    def forward(self, x):\n",
    "        z = self.enc(x.transpose(0,1))  # (T,B,F)\n",
    "        return self.head(z[-1])         # (B,F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "20681a30-79dc-4453-b453-3a9118095f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CATALOG = {\n",
    "    \"lwm\":         LWMWithHead,        # masked_pos 필수\n",
    "    \"lstm\":        LSTMWithHead,       # masked_pos 무시\n",
    "    \"gru\":         GRUWithHead,        # masked_pos 무시\n",
    "    \"transformer\": TransformerWithHead # masked_pos 무시\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5ae88b6b-6d9d-4922-9358-b6e407e2978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model: LWMWithHead 인스턴스\n",
    "# print(\"Backbone requires_grad flags:\")\n",
    "# for name, param in model.backbone.named_parameters():\n",
    "#     print(f\"  {name:40s}: {param.requires_grad}\")\n",
    "\n",
    "# # 또한 전체가 동결됐는지 한 줄로 요약하려면:\n",
    "# all_frozen = all(not p.requires_gㅁrad for p in model.backbone.parameters())\n",
    "# print(f\"\\n→ Is backbone fully frozen? {all_frozen}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bd8b8d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "727\n"
     ]
    }
   ],
   "source": [
    "print(train_ds.U)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3cec5b",
   "metadata": {},
   "source": [
    "## input_size\n",
    "-input_size = (scene - seq_len) * U * S -> (10-5)+69040*64 = 22092800  \n",
    "-batch_size = 32  \n",
    "-배치 수 = input_size / batch_size = 690400배치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "71886e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ total samples (input_size): 465280\n",
      "→ batch size: 32\n",
      "→ total batches: 14540\n"
     ]
    }
   ],
   "source": [
    "# ──────────────────────────────────────────────────\n",
    "# input_size 계산 및 출력\n",
    "# ──────────────────────────────────────────────────\n",
    "\n",
    "# 1) 시퀀스 길이\n",
    "seq_len = train_ds.seq_len      # 보통 5\n",
    "\n",
    "# 2) 씬 개수(T), 사용자 수(U), 서브캐리어 수(S)\n",
    "T = len(dataset)               # 전체 씬 개수, 여기선 10\n",
    "U = train_ds.U                 # 한 씬당 사용자 수\n",
    "S = train_ds.S                 # 한 사용자당 서브캐리어 수\n",
    "\n",
    "# 3) 총 샘플 수 = (T - seq_len) × U × S\n",
    "input_size = (T - seq_len) * U * S\n",
    "\n",
    "# 4) 배치 수\n",
    "batch_size = 32  # 이미 설정한 값\n",
    "n_batches = input_size // batch_size + int(input_size % batch_size != 0)\n",
    "\n",
    "print(f\"→ total samples (input_size): {input_size}\")\n",
    "print(f\"→ batch size: {batch_size}\")\n",
    "print(f\"→ total batches: {n_batches}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b37383cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cuda\n",
      "🟢 lwm initialized with\n",
      " {'element_length': 64, 'd_model': 64, 'max_len': 5, 'n_layers': 12, 'hidden_dim': 256, 'out_dim': 64, 'freeze_backbone': False, 'ckpt_path': None}\n"
     ]
    }
   ],
   "source": [
    "import torch, math\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "# ── 0) 디바이스 ──────────────────────────────\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device =\", device)\n",
    "\n",
    "# ── 1) 모델 카탈로그 ─────────────────────────\n",
    "MODEL_CATALOG = {\n",
    "    \"lwm\":         LWMWithHead,\n",
    "    \"lstm\":        LSTMWithHead,\n",
    "    \"gru\":         GRUWithHead,\n",
    "    \"transformer\": TransformerWithHead,\n",
    "}\n",
    "\n",
    "# ── 2) 공통 스펙 계산 ────────────────────────\n",
    "seq_len        = 5\n",
    "element_length = train_ds.A * 2     # (안테나 × real/imag)\n",
    "hidden_dim     = 256\n",
    "out_dim        = element_length\n",
    "\n",
    "# ── 3) 모델 이름만 바꿔 가며 실험 ────────────\n",
    "model_name = \"lwm\"      # \"lstm\" | \"gru\" | \"transformer\"\n",
    "ModelCls   = MODEL_CATALOG[model_name]\n",
    "\n",
    "# ── 4) 모델별 인자 조립 ──────────────────────\n",
    "if model_name == \"lwm\":\n",
    "    args = dict(\n",
    "        element_length = element_length,\n",
    "        d_model        = 64,\n",
    "        max_len        = seq_len,\n",
    "        n_layers       = 12,\n",
    "        hidden_dim     = hidden_dim,\n",
    "        out_dim        = out_dim,\n",
    "        freeze_backbone= False,\n",
    "        ckpt_path      = None,\n",
    "    )\n",
    "elif model_name == \"lstm\":\n",
    "    args = dict(\n",
    "        feat_dim       = element_length,\n",
    "        hidden_size    = 128,\n",
    "        num_layers     = 2,\n",
    "        bidirectional  = False,\n",
    "        dropout        = 0.2,\n",
    "        hidden_dim     = hidden_dim,\n",
    "        out_dim        = out_dim,\n",
    "    )\n",
    "elif model_name == \"gru\":\n",
    "    args = dict(\n",
    "        feat_dim       = element_length,\n",
    "        hidden_size    = 128,\n",
    "        num_layers     = 2,\n",
    "        bidirectional  = False,\n",
    "        dropout        = 0.2,\n",
    "        hidden_dim     = hidden_dim,\n",
    "        out_dim        = out_dim,\n",
    "    )\n",
    "elif model_name == \"transformer\":\n",
    "    args = dict(\n",
    "        feat_dim       = element_length,\n",
    "        n_heads        = 4,\n",
    "        dim_ff         = 256,\n",
    "        n_layers       = 2,\n",
    "        dropout        = 0.1,\n",
    "        hidden_dim     = hidden_dim,\n",
    "        out_dim        = out_dim,\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"unknown model: {model_name}\")\n",
    "\n",
    "# ── 5) 인스턴스화 & 옵티마이저 ───────────────\n",
    "model = ModelCls(**args).to(device)\n",
    "print(f\"🟢 {model_name} initialized with\\n\", args)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "625b128d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "# import sys\n",
    "\n",
    "# #  ❶ quick sanity checks\n",
    "# #    If train_loader is empty, this will print 0 or raise\n",
    "# try:\n",
    "#     n_batches = len(train_loader)\n",
    "# except TypeError:\n",
    "#     # IterableDataset → no __len__\n",
    "#     n_batches = sum(1 for _ in train_loader)\n",
    "# print(f\"→ training batches: {n_batches}\")\n",
    "\n",
    "# # ❷ actual training loop with per-epoch print\n",
    "# start = time.time()\n",
    "# num_epochs = 10\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "\n",
    "#     # loop over batches\n",
    "#     for i, (input_ids, masked_pos, target) in enumerate(train_loader, 1):\n",
    "#         input_ids   = input_ids.to(device)\n",
    "#         masked_pos  = masked_pos.to(device)\n",
    "#         target      = target.to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         pred = model(input_ids, masked_pos).squeeze(-1)\n",
    "#         loss = criterion(pred, target)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         running_loss += loss.item()\n",
    "\n",
    "#     # ❸ now we know at least one epoch happened\n",
    "#     avg_loss = running_loss / i if i>0 else float('nan')\n",
    "#     print(f\"Epoch {epoch+1}/{num_epochs},  avg loss: {avg_loss:.6f}\", flush=True)\n",
    "\n",
    "# end = time.time()\n",
    "# print(f\"Total training time: {end - start:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1496a0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델 평가 방법\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# def rmse(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "#     \"\"\"\n",
    "#     RMSE = Root MSE\n",
    "#     RMSE = {1/n*sum((y^-y)**2)}**1/2\n",
    "#     \"\"\"\n",
    "#     return torch.sqrt(F.mse_loss(pred, target, reduction=\"mean\"))   # √MSE\n",
    "\n",
    "# def nmse(pred: torch.Tensor, target: torch.Tensor, eps : float = 1e-12) -> torch.Tensor:\n",
    "#     \"\"\"\n",
    "#     Normalized MSE  =  E[‖ŷ − y‖²] / E[‖y‖²]\n",
    "#     returns: 스칼라 (배치 평균)\n",
    "#     \"\"\"\n",
    "#     # (B, …) → (B,)  : 각 샘플별 제곱합\n",
    "#     mse_per_sample   = ((pred - target)**2).view(pred.size(0), -1).sum(dim=1)\n",
    "#     power_per_sample = (target**2).view(target.size(0), -1).sum(dim=1) + eps\n",
    "#     return (mse_per_sample / power_per_sample).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7f7e4ba2-a72d-48fc-89c8-acb7a92f984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────\n",
    "# call_model: LWM이면 dummy masked_pos 생성\n",
    "# ──────────────────────────────────────────\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def call_model(model: nn.Module, x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    모든 모델을 한 줄로 호출하기 위한 헬퍼.\n",
    "    · LWMWithHead → masked_pos(dummy) 만들어 두 인자로 호출\n",
    "    · 그 외 모델   → x 한 인자만 넘김\n",
    "    \"\"\"\n",
    "    from __main__ import LWMWithHead       # LWM 클래스가 같은 노트북에 있으므로\n",
    "\n",
    "    if isinstance(model, LWMWithHead):\n",
    "        dummy_mask = torch.zeros(x.size(0), 1,\n",
    "                                 dtype=torch.long,\n",
    "                                 device=x.device)         # (B,1)\n",
    "        return model(x, dummy_mask)\n",
    "    else:\n",
    "        return model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3e8931ae-5238-415b-bea6-26c65ab15b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting umap-learn\n",
      "  Downloading umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dlghd\\anaconda3\\lib\\site-packages (from umap-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.3.1 in c:\\users\\dlghd\\anaconda3\\lib\\site-packages (from umap-learn) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in c:\\users\\dlghd\\anaconda3\\lib\\site-packages (from umap-learn) (1.5.1)\n",
      "Requirement already satisfied: numba>=0.51.2 in c:\\users\\dlghd\\anaconda3\\lib\\site-packages (from umap-learn) (0.60.0)\n",
      "Collecting pynndescent>=0.5 (from umap-learn)\n",
      "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dlghd\\anaconda3\\lib\\site-packages (from umap-learn) (4.66.5)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\dlghd\\anaconda3\\lib\\site-packages (from numba>=0.51.2->umap-learn) (0.43.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\dlghd\\anaconda3\\lib\\site-packages (from pynndescent>=0.5->umap-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dlghd\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22->umap-learn) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dlghd\\anaconda3\\lib\\site-packages (from tqdm->umap-learn) (0.4.6)\n",
      "Downloading umap_learn-0.5.7-py3-none-any.whl (88 kB)\n",
      "Downloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
      "Installing collected packages: pynndescent, umap-learn\n",
      "Successfully installed pynndescent-0.5.13 umap-learn-0.5.7\n",
      "Requirement already satisfied: umap-learn in c:\\users\\dlghd\\anaconda3\\lib\\site-packages (0.5.7)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dlghd\\anaconda3\\lib\\site-packages (from umap-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.3.1 in c:\\users\\dlghd\\anaconda3\\lib\\site-packages (from umap-learn) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in c:\\users\\dlghd\\anaconda3\\lib\\site-packages (from umap-learn) (1.5.1)\n",
      "Requirement already satisfied: numba>=0.51.2 in c:\\users\\dlghd\\anaconda3\\lib\\site-packages (from umap-learn) (0.60.0)\n",
      "Requirement already satisfied: pynndescent>=0.5 in c:\\users\\dlghd\\anaconda3\\lib\\site-packages (from umap-learn) (0.5.13)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dlghd\\anaconda3\\lib\\site-packages (from umap-learn) (4.66.5)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\dlghd\\anaconda3\\lib\\site-packages (from numba>=0.51.2->umap-learn) (0.43.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\dlghd\\anaconda3\\lib\\site-packages (from pynndescent>=0.5->umap-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dlghd\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22->umap-learn) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dlghd\\anaconda3\\lib\\site-packages (from tqdm->umap-learn) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install umap-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a6a78d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────\n",
    "def train_one_epoch(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "    for xb, yb in loader:                 # 또는 (xb, _, yb)  ← 옵션B일 때\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = call_model(model, xb)      # ⭐ 변경 핵심 한 줄 ⭐\n",
    "        loss = criterion(pred, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running += loss.item() * xb.size(0)\n",
    "    return running / len(loader.dataset)\n",
    "\n",
    "# ──────────────────────────────────────────\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    tot_rmse = tot_nmse = tot_n = 0.0\n",
    "    for xb, yb in loader:                 # 또는 (xb, _, yb)\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        pred   = call_model(model, xb)    # ⭐ 동일하게 한 줄 ⭐\n",
    "        bs     = xb.size(0)\n",
    "        tot_rmse += rmse(pred, yb).item() * bs\n",
    "        tot_nmse += nmse(pred, yb).item() * bs\n",
    "        tot_n    += bs\n",
    "    return tot_rmse / tot_n, tot_nmse / tot_n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a06b20a",
   "metadata": {},
   "source": [
    "# model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1f7ce629",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶▶▶ Training lwm ◀◀◀\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rmse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 55\u001b[0m\n\u001b[0;32m     52\u001b[0m     pred \u001b[38;5;241m=\u001b[39m model(xb)\n\u001b[0;32m     54\u001b[0m bs \u001b[38;5;241m=\u001b[39m xb\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 55\u001b[0m tot_rmse \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m rmse(pred, yb)\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m bs\n\u001b[0;32m     56\u001b[0m tot_nmse \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m nmse(pred, yb)\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m bs\n\u001b[0;32m     57\u001b[0m tot_n    \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m bs\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rmse' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import math, torch\n",
    "from torch.optim import Adam\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "LR         = 1e-4\n",
    "results    = []\n",
    "\n",
    "for name in [\"lwm\", \"lstm\", \"gru\", \"transformer\"]:\n",
    "    # ── (args 조립 부분 생략) ───────────────────────────\n",
    "    ModelCls = MODEL_CATALOG[name]\n",
    "    model    = ModelCls(**args).to(device)\n",
    "    optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=LR)\n",
    "\n",
    "    print(f\"\\n▶▶▶ Training {name} ◀◀◀\")\n",
    "    for epoch in range(1, NUM_EPOCHS+1):\n",
    "        # ---- Train ----\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        # tqdm으로 배치 진행바 추가\n",
    "        train_bar = tqdm(train_loader, desc=f\"[{name}] Ep{epoch} Train\", leave=False)\n",
    "        for xb, mpos, yb in train_bar:\n",
    "            xb, mpos, yb = xb.to(device), mpos.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if name == \"lwm\":\n",
    "                pred = model(xb, mpos)\n",
    "            else:\n",
    "                pred = model(xb)\n",
    "\n",
    "            loss = criterion(pred, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * xb.size(0)\n",
    "            # 진행바에 현재 배치 평균 손실 표시\n",
    "            train_bar.set_postfix(loss=running_loss / ((train_bar.n+1)*xb.size(0)))\n",
    "\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        # ---- Validate ----\n",
    "        model.eval()\n",
    "        tot_rmse = tot_nmse = tot_n = 0.0\n",
    "        val_bar = tqdm(val_loader, desc=f\"[{name}] Ep{epoch} Val  \", leave=False)\n",
    "        with torch.no_grad():\n",
    "            for xb, mpos, yb in val_bar:\n",
    "                xb, mpos, yb = xb.to(device), mpos.to(device), yb.to(device)\n",
    "\n",
    "                if name == \"lwm\":\n",
    "                    pred = model(xb, mpos)\n",
    "                else:\n",
    "                    pred = model(xb)\n",
    "\n",
    "                bs = xb.size(0)\n",
    "                tot_rmse += rmse(pred, yb).item() * bs\n",
    "                tot_nmse += nmse(pred, yb).item() * bs\n",
    "                tot_n    += bs\n",
    "                # 진행바에 현재 검증 RMSE 표시\n",
    "                val_bar.set_postfix(rmse=tot_rmse/tot_n)\n",
    "\n",
    "        val_rmse    = tot_rmse / tot_n\n",
    "        val_nmse    = tot_nmse / tot_n\n",
    "        val_nmse_db = 10 * math.log10(val_nmse)\n",
    "\n",
    "        # ---- 로그 & 결과 기록 ----\n",
    "        print(\n",
    "            f\"[{name:12s} | Ep{epoch:02d}] \"\n",
    "            f\"Train Loss: {train_loss:.4f}  \"\n",
    "            f\"Val RMSE: {val_rmse:.4f}  \"\n",
    "            f\"Val NMSE(dB): {val_nmse_db:+.2f}\"\n",
    "        )\n",
    "        results.append({\n",
    "            \"model\": name,\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"val_rmse\": val_rmse,\n",
    "            \"val_nmse\": val_nmse,\n",
    "            \"val_nmse_db\": val_nmse_db\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7b169d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6932b03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a9fbc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
